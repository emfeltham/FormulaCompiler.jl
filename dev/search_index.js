var documenterSearchIndex = {"docs":
[{"location":"mathematical_foundation/#Mathematical-and-Statistical-Foundation","page":"Mathematical Foundation","title":"Mathematical and Statistical Foundation","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"This document provides a comprehensive walkthrough of the mathematical and statistical concepts underlying FormulaCompiler.jl, from basic formula representation to advanced derivative computations and variance estimation.","category":"page"},{"location":"mathematical_foundation/#Table-of-Contents","page":"Mathematical Foundation","title":"Table of Contents","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Statistical Model Representation\nFormula Compilation Mathematics\nPosition Mapping Theory\nDerivative Computation\nMarginal Effects Theory\nVariance Estimation and Standard Errors\nComputational Efficiency Theory","category":"page"},{"location":"mathematical_foundation/#Statistical-Model-Representation","page":"Mathematical Foundation","title":"Statistical Model Representation","text":"","category":"section"},{"location":"mathematical_foundation/#Linear-Models","page":"Mathematical Foundation","title":"Linear Models","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"FormulaCompiler.jl operates on statistical models of the form:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbbEy_i = mathbfx_i^T boldsymbolbeta","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"y_i\nis the response for observation i\nmathbfx_i in mathbbR^p\nis the model matrix row (predictor vector)\nboldsymbolbeta in mathbbR^p\nis the parameter vector","category":"page"},{"location":"mathematical_foundation/#Generalized-Linear-Models","page":"Mathematical Foundation","title":"Generalized Linear Models","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For GLMs, we have:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbbEy_i = mu_i = g^-1(eta_i)","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"eta_i = mathbfx_i^T boldsymbolbeta","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"eta_i\nis the linear predictor\ng(cdot)\nis the link function\nmu_i\nis the expected response","category":"page"},{"location":"mathematical_foundation/#Mixed-Effects-Models","page":"Mathematical Foundation","title":"Mixed Effects Models","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For linear mixed models:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbbEy_i = mathbfx_i^T boldsymbolbeta + mathbfz_i^T mathbfb","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where FormulaCompiler extracts only the fixed effects component mathbfx_i^T boldsymbolbeta.","category":"page"},{"location":"mathematical_foundation/#Formula-Compilation-Mathematics","page":"Mathematical Foundation","title":"Formula Compilation Mathematics","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"FormulaCompiler.jl transforms statistical formulas through a systematic compilation process:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"(Image: Compilation Pipeline)","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Figure 1: The compilation pipeline transforms statistical formulas into position-mapped, type-specialized evaluators through systematic decomposition and analysis.","category":"page"},{"location":"mathematical_foundation/#Term-Decomposition","page":"Mathematical Foundation","title":"Term Decomposition","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"A statistical formula like y ~ x + z + x*group is decomposed into atomic operations:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfx_i = beginbmatrix\n1 \nx_i \nz_i \nx_i cdot mathbf1(textgroup_i = textB) \nx_i cdot mathbf1(textgroup_i = textC)\nendbmatrix","category":"page"},{"location":"mathematical_foundation/#Categorical-Variables","page":"Mathematical Foundation","title":"Categorical Variables","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For a categorical variable with K levels using treatment contrast:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textContrastMatrix = beginbmatrix\n0  0  cdots  0 \n1  0  cdots  0 \n0  1  cdots  0 \nvdots  vdots  ddots  vdots \n0  0  cdots  1\nendbmatrix in mathbbR^K times (K-1)","category":"page"},{"location":"mathematical_foundation/#Function-Application","page":"Mathematical Foundation","title":"Function Application","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For transformed variables like log(x):","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textFunctionOp x_i mapsto f(x_i)","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where f is applied element-wise with appropriate domain checking.","category":"page"},{"location":"mathematical_foundation/#Position-Mapping","page":"Mathematical Foundation","title":"Position Mapping","text":"","category":"section"},{"location":"mathematical_foundation/#Core-Concept","page":"Mathematical Foundation","title":"Core Concept","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"The key innovation is mapping each formula term to a fixed position in the output vector at compile time:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textTerm_j rightarrow textPosition_j in 1 2 ldots p","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"This provides:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfx_ij = textEvaluate(textTerm_j textdata i)","category":"page"},{"location":"mathematical_foundation/#Type-Specialization","page":"Mathematical Foundation","title":"Type Specialization","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Each operation is embedded in Julia's type system:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"struct LoadOp{Col} end           # Load column Col\nstruct FunctionOp{Col, F} end    # Apply function F to column Col\nstruct InteractionOp{A, B} end   # Multiply terms A and B","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"The compiler generates specialized code for each specific formula.","category":"page"},{"location":"mathematical_foundation/#Scratch-Space-Management","page":"Mathematical Foundation","title":"Scratch Space Management","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Intermediate results use a compile-time allocated scratch space:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textScratch in mathbbR^s quad textwhere  s = textmax intermediate width","category":"page"},{"location":"mathematical_foundation/#Derivative-Computation","page":"Mathematical Foundation","title":"Derivative Computation","text":"","category":"section"},{"location":"mathematical_foundation/#Jacobian-Matrix","page":"Mathematical Foundation","title":"Jacobian Matrix","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For derivatives with respect to variables mathbfv = v_1 ldots v_k^T:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfJ = fracpartial mathbfxpartial mathbfv^T = beginbmatrix\nfracpartial x_1partial v_1  fracpartial x_1partial v_2  cdots  fracpartial x_1partial v_k \nfracpartial x_2partial v_1  fracpartial x_2partial v_2  cdots  fracpartial x_2partial v_k \nvdots  vdots  ddots  vdots \nfracpartial x_ppartial v_1  fracpartial x_ppartial v_2  cdots  fracpartial x_ppartial v_k\nendbmatrix in mathbbR^p times k","category":"page"},{"location":"mathematical_foundation/#Automatic-Differentiation","page":"Mathematical Foundation","title":"Automatic Differentiation","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"FormulaCompiler uses ForwardDiff.jl for automatic differentiation:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"x_j = f_j(v_1 ldots v_k) Rightarrow fracpartial x_jpartial v_i = f_j(v_i)","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Dual numbers compute derivatives exactly:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"f(a + bvarepsilon) = f(a) + bf(a)varepsilon","category":"page"},{"location":"mathematical_foundation/#Low-Allocation-Automatic-Differentiation","page":"Mathematical Foundation","title":"Low-Allocation Automatic Differentiation","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"A fundamental challenge in statistical automatic differentiation is the type conversion bottleneck between statistical data (typically Float64) and dual numbers required for AD computation. Traditional approaches convert Float64 to Dual on every data access, creating allocation overhead that scales with formula complexity.","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"FormulaCompiler implements a pre-conversion strategy that minimizes runtime allocations:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Phase 1: Construction-Time Pre-Conversion","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"During evaluator construction, all relevant data columns are pre-converted from Float64 to the target dual type:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textdata_textFloat64 xrightarrowtextconstruction textdata_textDual quad text(amortized cost)","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For k differentiation variables, data is converted to Dual{Tag,Float64,k} carrying the original value plus space for k partial derivatives.","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Phase 2: Type-Homogeneous Evaluation","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"During derivative computation, the evaluation chain maintains type homogeneity throughout:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"beginalign\ntextSeed quad v_i leftarrow textDual(v_i mathbfe_i) quad textwhere  mathbfe_i text is unit vector\ntextEvaluate quad mathbfx = f(mathbfv_textdual) quad text(no conversions)\ntextExtract quad J_ji = textpartials(mathbfx_j)_i\nendalign","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Manual Dual Path","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Rather than using ForwardDiff's jacobian! and gradient! drivers (which contain allocation overhead for generality), FormulaCompiler implements a manual dual evaluation path:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Direct seeding: Identity partials injected without driver overhead\nIn-place updates: Cached dual data structures modified without rebuilding  \nSingle evaluation: Compiled formula executed once on dual-typed data\nDirect extraction: Partial derivatives read from dual results via simple loops","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"This achieves the mathematical correctness of ForwardDiff with custom zero-allocation orchestration.","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Computational Complexity and Allocations","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"The pre-conversion strategy transforms the memory allocation pattern:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Traditional AD: O(textaccesses times textconversions) runtime allocations\nLow-allocation AD: O(textdata size) construction cost; runtime allocations are typically small and environment‑dependent","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For typical statistical formulas accessing data 10–20 times per evaluation, this approach removes repeated conversion costs and reduces runtime allocations to small, bounded overheads while providing practical speedups.","category":"page"},{"location":"mathematical_foundation/#Finite-Differences","page":"Mathematical Foundation","title":"Finite Differences","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For the finite difference backend (central differences):","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"fracpartial x_jpartial v_i approx fracf_j(v_i + h) - f_j(v_i - h)2h","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Step size:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"h = epsilon^13 cdot max(1 v_i)","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Justification: The central-difference truncation error is O(h^2) while floating-point rounding contributes O(epsilon  h). Balancing these terms yields an h proportional to epsilon^13 (scaled by the variable magnitude), which is a standard, robust choice in double precision.","category":"page"},{"location":"mathematical_foundation/#Single-Column-Extraction","page":"Mathematical Foundation","title":"Single-Column Extraction","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For computational efficiency, we can compute individual Jacobian columns:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfJ_cdotk = fracpartial mathbfxpartial v_k in mathbbR^p","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"This avoids computing the full Jacobian when only one column is needed.","category":"page"},{"location":"mathematical_foundation/#Marginal-Effects","page":"Mathematical Foundation","title":"Marginal Effects","text":"","category":"section"},{"location":"mathematical_foundation/#Definition","page":"Mathematical Foundation","title":"Definition","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"A marginal effect measures the change in the expected response due to a small change in a predictor:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textME_v_k = fracpartial mathbbEypartial v_k","category":"page"},{"location":"mathematical_foundation/#Linear-Predictor-Case-(η)","page":"Mathematical Foundation","title":"Linear Predictor Case (η)","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For the linear predictor eta = mathbfx^T boldsymbolbeta:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"fracpartial etapartial v_k = fracpartial (mathbfx^T boldsymbolbeta)partial v_k = left(fracpartial mathbfxpartial v_kright)^T boldsymbolbeta = mathbfJ_cdotk^T boldsymbolbeta","category":"page"},{"location":"mathematical_foundation/#Mean-Response-Case-(μ)","page":"Mathematical Foundation","title":"Mean Response Case (μ)","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For GLMs where mu = g^-1(eta):","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"fracpartial mupartial v_k = fracdmudeta fracpartial etapartial v_k = g(eta) cdot mathbfJ_cdotk^T boldsymbolbeta","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where g(eta) = fracdmudeta is the derivative of the inverse link function.","category":"page"},{"location":"mathematical_foundation/#Average-Marginal-Effects","page":"Mathematical Foundation","title":"Average Marginal Effects","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Average marginal effects (AME) average the marginal effect across observations:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textAME_v_k = frac1n sum_i=1^n fracpartial mathbbEy_ipartial v_k","category":"page"},{"location":"mathematical_foundation/#Variance-Estimation-and-Standard-Errors","page":"Mathematical Foundation","title":"Variance Estimation and Standard Errors","text":"","category":"section"},{"location":"mathematical_foundation/#Delta-Method","page":"Mathematical Foundation","title":"Delta Method","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"The delta method provides standard errors for smooth functions of estimated parameters. For a function m(boldsymbolbeta):","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textVar(m(hatboldsymbolbeta)) approx mathbfg^T boldsymbolSigma mathbfg","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfg = fracpartial mpartial boldsymbolbeta\nis the gradient\nboldsymbolSigma = textVar(hatboldsymbolbeta)\nis the parameter covariance matrix","category":"page"},{"location":"mathematical_foundation/#Standard-Error-Computation","page":"Mathematical Foundation","title":"Standard Error Computation","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textSE(m(hatboldsymbolbeta)) = sqrtmathbfg^T boldsymbolSigma mathbfg","category":"page"},{"location":"mathematical_foundation/#Marginal-Effect-Standard-Errors","page":"Mathematical Foundation","title":"Marginal Effect Standard Errors","text":"","category":"section"},{"location":"mathematical_foundation/#Linear-Predictor-Case","page":"Mathematical Foundation","title":"Linear Predictor Case","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For marginal effects on eta:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"m = mathbfJ_cdotk^T boldsymbolbeta Rightarrow mathbfg = fracpartial mpartial boldsymbolbeta = mathbfJ_cdotk","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Therefore:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textSE(textME_etak) = sqrtmathbfJ_cdotk^T boldsymbolSigma mathbfJ_cdotk","category":"page"},{"location":"mathematical_foundation/#Mean-Response-Case","page":"Mathematical Foundation","title":"Mean Response Case","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For marginal effects on mu with link function g:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"m = g(eta) cdot mathbfJ_cdotk^T boldsymbolbeta","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"The gradient is:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfg = fracpartial mpartial boldsymbolbeta = g(eta) mathbfJ_cdotk + (mathbfJ_cdotk^T boldsymbolbeta) g(eta) mathbfx","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"where mathbfx is the model matrix row and g(eta) is the second derivative.","category":"page"},{"location":"mathematical_foundation/#Average-Marginal-Effects-2","page":"Mathematical Foundation","title":"Average Marginal Effects","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For AME, the gradient is the average of individual gradients:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"mathbfg_textAME = frac1n sum_i=1^n mathbfg_i","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"By linearity of expectation:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"textVar(textAME) = mathbfg_textAME^T boldsymbolSigma mathbfg_textAME","category":"page"},{"location":"mathematical_foundation/#Link-Function-Derivatives","page":"Mathematical Foundation","title":"Link Function Derivatives","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Common link functions and their derivatives:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Link g(mu) g^-1(eta) fracdmudeta fracd^2mudeta^2\nIdentity mu eta 1 0\nLog log(mu) exp(eta) exp(eta) exp(eta)\nLogit logleft(tfracmu1-muright) mu = sigma(eta) mu(1-mu) mu(1-mu)(1-2mu)\nProbit Phi^-1(mu) mu = Phi(eta) phi(eta) -etaphi(eta)\nCloglog log(-log(1-mu)) mu = 1 - e^-e^eta e^eta - e^eta e^eta - e^eta(1 - e^eta)\nCauchit tan(pi(mu - 12)) mu = tfrac12 + tfrac1pi arctan(eta) tfrac1pi cdot tfrac11+eta^2 -tfrac2etapi cdot tfrac1(1+eta^2)^2\nInverse mu^-1 mu = eta^-1 -eta^-2 2eta^-3\nSqrt 2sqrtmu mu = (tfraceta2)^2 tfraceta2 tfrac12\nInverseSquare mu^-2 mu = eta^-12 -tfrac12 eta^-32 tfrac34 eta^-52","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Notes:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"For Logit, mu = sigma(eta) = 1(1+e^-eta) and phi Phi denote standard Normal PDF/CDF for Probit.\nCarefully handle domain constraints when evaluating links (e.g., mu in (01) for binary GLMs).","category":"page"},{"location":"mathematical_foundation/#Computational-Efficiency","page":"Mathematical Foundation","title":"Computational Efficiency","text":"","category":"section"},{"location":"mathematical_foundation/#Zero-Allocation-Design","page":"Mathematical Foundation","title":"Zero-Allocation Design","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"The key to zero-allocation performance is eliminating runtime memory allocation:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Compile-time type specialization: All operations encoded in types\nFixed memory layout: Pre-allocated buffers reused across calls\nStack allocation: Small temporary values on the stack\nIn-place operations: Modify existing arrays rather than creating new ones","category":"page"},{"location":"mathematical_foundation/#Position-Mapping-Efficiency","page":"Mathematical Foundation","title":"Position Mapping Efficiency","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Traditional approach:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"O(p cdot textcomplexity(textformula))","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Position mapping approach:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"O(p) text with compile-time  O(textcomplexity(textformula))","category":"page"},{"location":"mathematical_foundation/#Memory-Complexity","page":"Mathematical Foundation","title":"Memory Complexity","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Traditional: O(np) for full model matrix\nFormulaCompiler: O(p) per row evaluation\nScenarios: O(1) via CounterfactualVector regardless of n","category":"page"},{"location":"mathematical_foundation/#Derivative-Efficiency","page":"Mathematical Foundation","title":"Derivative Efficiency","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Full Jacobian: O(pk) computation and storage\nSingle column: O(p) computation and storage  \nAME accumulation: O(np) time, O(p) space","category":"page"},{"location":"mathematical_foundation/#Backend-Selection","page":"Mathematical Foundation","title":"Backend Selection","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Backend Speed Memory Accuracy Recommendation\n:ad (Automatic Differentiation) Faster 0 bytes Machine precision Strongly preferred - always use this\n:fd (Finite Differences) Slower (~22% slower) 0 bytes ≈1e-8 Legacy support only","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"warning: Use Automatic Differentiation\nAlways use :ad backend (derivativeevaluator(:ad, ...) or backend=:ad).Advantages of :ad:Faster: ~22% faster than finite differences\nMore accurate: Machine precision vs ~1e-8 for FD\nZero allocations: Same as FDThe :fd backend exists only for legacy compatibility. There are no practical advantages to using it.","category":"page"},{"location":"mathematical_foundation/#Implementation-Notes","page":"Mathematical Foundation","title":"Implementation Notes","text":"","category":"section"},{"location":"mathematical_foundation/#Type-Stability","page":"Mathematical Foundation","title":"Type Stability","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"All functions maintain type stability:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"f(x::Float64)::Float64  # Compiler can optimize aggressively","category":"page"},{"location":"mathematical_foundation/#Generated-Functions","page":"Mathematical Foundation","title":"Generated Functions","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Critical paths use @generated functions to move computation to compile time:","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"@generated function evaluate(compiled::UnifiedCompiled{T,Ops}, ...)\n    # Generate specialized code based on Ops type parameter\n    return quote\n        # Unrolled, type-stable operations\n    end\nend","category":"page"},{"location":"mathematical_foundation/#Numerical-Stability","page":"Mathematical Foundation","title":"Numerical Stability","text":"","category":"section"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"Finite differences: Adaptive step size based on magnitude\nLink functions: Numerical safeguards for extreme values  \nMatrix operations: Use stable BLAS routines","category":"page"},{"location":"mathematical_foundation/","page":"Mathematical Foundation","title":"Mathematical Foundation","text":"This mathematical foundation enables FormulaCompiler.jl to achieve both computational efficiency and statistical accuracy, making it suitable as a foundation for advanced statistical computing applications.","category":"page"},{"location":"guide/scenarios/#Counterfactual-Analysis","page":"Scenario Analysis","title":"Counterfactual Analysis","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"FormulaCompiler.jl provides efficient counterfactual analysis through simple, direct data manipulation and loop patterns.","category":"page"},{"location":"guide/scenarios/#Overview","page":"Scenario Analysis","title":"Overview","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"FormulaCompiler enables counterfactual analysis through three straightforward approaches:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Direct data modification - Use merge() for simple scenarios (1-10 comparisons)\nBatch contrast evaluation - Use contrastevaluator() for categorical contrasts (100+ comparisons)\nPopulation analysis - Use simple loops over rows for aggregated effects","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"All approaches maintain zero-allocation performance and scale efficiently with dataset size.","category":"page"},{"location":"guide/scenarios/#Approach-1:-Direct-Data-Modification","page":"Scenario Analysis","title":"Approach 1: Direct Data Modification","text":"","category":"section"},{"location":"guide/scenarios/#Basic-Treatment-Effect-Analysis","page":"Scenario Analysis","title":"Basic Treatment Effect Analysis","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"The simplest approach for counterfactual analysis is to create modified versions of your data and compare outcomes:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"using FormulaCompiler, GLM, DataFrames, Tables, Statistics\n\n# Setup data and model\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    treatment = rand(Bool, 1000),\n    age = rand(18:80, 1000)\n)\n\nmodel = lm(@formula(y ~ x * treatment + age), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\nβ = coef(model)\n\n# Create counterfactual scenarios\nn_rows = length(data.treatment)\ndata_treated = merge(data, (treatment = fill(true, n_rows),))\ndata_control = merge(data, (treatment = fill(false, n_rows),))\n\n# Compare individual outcomes under different treatments\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Individual 1: treated vs control\ncompiled(row_vec, data_treated, 1)\neffect_treated = dot(β, row_vec)\n\ncompiled(row_vec, data_control, 1)\neffect_control = dot(β, row_vec)\n\nindividual_effect = effect_treated - effect_control\nprintln(\"Individual 1 treatment effect: $(round(individual_effect, digits=3))\")","category":"page"},{"location":"guide/scenarios/#Population-Average-Treatment-Effects","page":"Scenario Analysis","title":"Population Average Treatment Effects","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Calculate average treatment effects across the population:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Population analysis: loop over all individuals\nn_individuals = nrow(df)\ntreatment_effects = Vector{Float64}(undef, n_individuals)\n\nfor i in 1:n_individuals\n    # Effect if treated\n    compiled(row_vec, data_treated, i)\n    outcome_treated = dot(β, row_vec)\n\n    # Effect if control\n    compiled(row_vec, data_control, i)\n    outcome_control = dot(β, row_vec)\n\n    treatment_effects[i] = outcome_treated - outcome_control\nend\n\n# Summary statistics\navg_effect = mean(treatment_effects)\nstd_effect = std(treatment_effects)\nprintln(\"Average treatment effect: $(round(avg_effect, digits=3)) ± $(round(std_effect, digits=3))\")","category":"page"},{"location":"guide/scenarios/#Multi-Variable-Counterfactuals","page":"Scenario Analysis","title":"Multi-Variable Counterfactuals","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Modify multiple variables simultaneously:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Policy scenario: everyone gets treatment + standardized age\nstandard_age = 40\ndata_policy = merge(data, (\n    treatment = fill(true, n_rows),\n    age = fill(standard_age, n_rows)\n))\n\n# Compare baseline vs policy for each individual\npolicy_effects = Vector{Float64}(undef, n_individuals)\n\nfor i in 1:n_individuals\n    # Baseline outcome\n    compiled(row_vec, data, i)\n    baseline = dot(β, row_vec)\n\n    # Policy outcome\n    compiled(row_vec, data_policy, i)\n    policy = dot(β, row_vec)\n\n    policy_effects[i] = policy - baseline\nend\n\navg_policy_effect = mean(policy_effects)\nprintln(\"Average policy effect: $(round(avg_policy_effect, digits=3))\")","category":"page"},{"location":"guide/scenarios/#Multiple-Scenario-Comparison","page":"Scenario Analysis","title":"Multiple Scenario Comparison","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Compare several policy scenarios:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Define scenarios to compare\nscenarios = [\n    (\"baseline\", data),\n    (\"universal_treatment\", merge(data, (treatment = fill(true, n_rows),))),\n    (\"universal_control\", merge(data, (treatment = fill(false, n_rows),))),\n    (\"young_treated\", merge(data, (treatment = fill(true, n_rows), age = fill(30, n_rows)))),\n    (\"old_treated\", merge(data, (treatment = fill(true, n_rows), age = fill(60, n_rows))))\n]\n\n# Evaluate all scenarios\nresults = Dict{String, Vector{Float64}}()\n\nfor (name, scenario_data) in scenarios\n    outcomes = Vector{Float64}(undef, n_individuals)\n\n    for i in 1:n_individuals\n        compiled(row_vec, scenario_data, i)\n        outcomes[i] = dot(β, row_vec)\n    end\n\n    results[name] = outcomes\nend\n\n# Compare scenario means\nprintln(\"\\nScenario comparison:\")\nfor (name, outcomes) in results\n    println(\"  $(name): mean = $(round(mean(outcomes), digits=3))\")\nend","category":"page"},{"location":"guide/scenarios/#Approach-2:-Categorical-Contrasts-with-ContrastEvaluator","page":"Scenario Analysis","title":"Approach 2: Categorical Contrasts with ContrastEvaluator","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"For repeated categorical variable comparisons, use the zero-allocation contrast evaluator:","category":"page"},{"location":"guide/scenarios/#Basic-Contrast-Evaluation","page":"Scenario Analysis","title":"Basic Contrast Evaluation","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"using CategoricalArrays\n\n# Data with categorical variable\ndf_cat = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    region = categorical(rand([\"North\", \"South\", \"East\", \"West\"], 1000))\n)\n\nmodel_cat = lm(@formula(y ~ x * region), df_cat)\ndata_cat = Tables.columntable(df_cat)\ncompiled_cat = compile_formula(model_cat, data_cat)\n\n# Create contrast evaluator for zero-allocation batch processing\nevaluator = contrastevaluator(compiled_cat, data_cat, [:region])\ncontrast_buf = Vector{Float64}(undef, length(compiled_cat))\n\n# Single contrast: North vs South for individual 1\ncontrast_modelrow!(contrast_buf, evaluator, 1, :region, \"North\", \"South\")\nregional_difference = dot(coef(model_cat), contrast_buf)\nprintln(\"North vs South effect: $(round(regional_difference, digits=3))\")","category":"page"},{"location":"guide/scenarios/#Batch-Contrast-Processing","page":"Scenario Analysis","title":"Batch Contrast Processing","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Process many contrasts with zero allocations:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Compare all individuals: North vs South\nn_rows = nrow(df_cat)\nregional_effects = Vector{Float64}(undef, n_rows)\n\nfor i in 1:n_rows\n    contrast_modelrow!(contrast_buf, evaluator, i, :region, \"North\", \"South\")\n    regional_effects[i] = dot(coef(model_cat), contrast_buf)\nend\n\nprintln(\"Average North vs South effect: $(round(mean(regional_effects), digits=3))\")","category":"page"},{"location":"guide/scenarios/#Gradient-Computation-for-Uncertainty","page":"Scenario Analysis","title":"Gradient Computation for Uncertainty","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Compute parameter gradients for standard errors:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Parameter gradient for delta method (FormulaCompiler computational primitive)\n∇β = Vector{Float64}(undef, length(compiled_cat))\ncontrast_gradient!(∇β, evaluator, 1, :region, \"North\", \"South\", coef(model_cat))\n\n# Standard error using delta method (requires Margins.jl)\nusing Margins\nvcov_matrix = vcov(model_cat)\nse = delta_method_se(∇β, vcov_matrix)\nprintln(\"Standard error: $(round(se, digits=3))\")","category":"page"},{"location":"guide/scenarios/#Approach-3:-Grid-Analysis-Patterns","page":"Scenario Analysis","title":"Approach 3: Grid Analysis Patterns","text":"","category":"section"},{"location":"guide/scenarios/#Systematic-Parameter-Exploration","page":"Scenario Analysis","title":"Systematic Parameter Exploration","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Explore multiple parameter combinations:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Define parameter grid\ntreatment_values = [false, true]\nage_values = [30, 40, 50, 60]\nx_values = [-1.0, 0.0, 1.0]\n\n# Create all combinations\nn_scenarios = length(treatment_values) * length(age_values) * length(x_values)\nscenario_results = Matrix{Float64}(undef, n_scenarios, n_individuals)\n\nscenario_idx = 1\nfor treat in treatment_values\n    for age_val in age_values\n        for x_val in x_values\n            # Create scenario data\n            scenario_data = merge(data, (\n                treatment = fill(treat, n_rows),\n                age = fill(age_val, n_rows),\n                x = fill(x_val, n_rows)\n            ))\n\n            # Evaluate for all individuals\n            for i in 1:n_individuals\n                compiled(row_vec, scenario_data, i)\n                scenario_results[scenario_idx, i] = dot(β, row_vec)\n            end\n\n            scenario_idx += 1\n        end\n    end\nend\n\n# Analyze results\nscenario_means = [mean(scenario_results[i, :]) for i in 1:n_scenarios]\nbest_scenario = argmax(scenario_means)\nprintln(\"Best scenario index: $best_scenario with mean outcome: $(round(scenario_means[best_scenario], digits=3))\")","category":"page"},{"location":"guide/scenarios/#Efficient-Batched-Evaluation","page":"Scenario Analysis","title":"Efficient Batched Evaluation","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"For very large grids, batch the evaluation:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"function evaluate_scenario_grid(compiled, base_data, param_values, β)\n    \"\"\"Efficiently evaluate parameter grid\"\"\"\n    n_rows = length(first(base_data))\n    row_vec = Vector{Float64}(undef, length(compiled))\n\n    results = Dict()\n\n    for (name, values) in param_values\n        # Create scenario\n        scenario_data = merge(base_data, Dict(name => fill(values, n_rows)))\n\n        # Evaluate population\n        outcomes = Vector{Float64}(undef, n_rows)\n        for i in 1:n_rows\n            compiled(row_vec, scenario_data, i)\n            outcomes[i] = dot(β, row_vec)\n        end\n\n        results[name => values] = mean(outcomes)\n    end\n\n    return results\nend\n\n# Usage\nparam_grid = Dict(\n    :treatment => [true, false],\n    :age => [30, 40, 50, 60]\n)\n\ngrid_results = evaluate_scenario_grid(compiled, data, param_grid, β)","category":"page"},{"location":"guide/scenarios/#Advanced-Patterns","page":"Scenario Analysis","title":"Advanced Patterns","text":"","category":"section"},{"location":"guide/scenarios/#Sensitivity-Analysis","page":"Scenario Analysis","title":"Sensitivity Analysis","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Test model sensitivity to parameter changes:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Vary age systematically\nage_range = 20:10:70\nsensitivity_results = Vector{Float64}(undef, length(age_range))\n\nfor (idx, age_val) in enumerate(age_range)\n    scenario_data = merge(data, (age = fill(age_val, n_rows),))\n\n    outcomes = Vector{Float64}(undef, n_individuals)\n    for i in 1:n_individuals\n        compiled(row_vec, scenario_data, i)\n        outcomes[i] = dot(β, row_vec)\n    end\n\n    sensitivity_results[idx] = mean(outcomes)\nend\n\n# Plot or analyze sensitivity\nprintln(\"Age sensitivity:\")\nfor (age_val, result) in zip(age_range, sensitivity_results)\n    println(\"  Age $age_val: $(round(result, digits=3))\")\nend","category":"page"},{"location":"guide/scenarios/#Bootstrap-Confidence-Intervals","page":"Scenario Analysis","title":"Bootstrap Confidence Intervals","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Compute uncertainty via bootstrap:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"using Random\n\nfunction bootstrap_treatment_effect(df, model_formula, n_boot=1000)\n    Random.seed!(123)\n    n_obs = nrow(df)\n\n    boot_effects = Vector{Float64}(undef, n_boot)\n\n    for b in 1:n_boot\n        # Bootstrap sample\n        boot_indices = rand(1:n_obs, n_obs)\n        boot_df = df[boot_indices, :]\n\n        # Fit model\n        boot_model = lm(model_formula, boot_df)\n        boot_data = Tables.columntable(boot_df)\n        boot_compiled = compile_formula(boot_model, boot_data)\n        boot_β = coef(boot_model)\n\n        # Create treatment scenarios\n        n_boot_rows = nrow(boot_df)\n        treated_data = merge(boot_data, (treatment = fill(true, n_boot_rows),))\n        control_data = merge(boot_data, (treatment = fill(false, n_boot_rows),))\n\n        # Compute average effect\n        row_vec = Vector{Float64}(undef, length(boot_compiled))\n        effects = Vector{Float64}(undef, n_boot_rows)\n\n        for i in 1:n_boot_rows\n            boot_compiled(row_vec, treated_data, i)\n            treated = dot(boot_β, row_vec)\n\n            boot_compiled(row_vec, control_data, i)\n            control = dot(boot_β, row_vec)\n\n            effects[i] = treated - control\n        end\n\n        boot_effects[b] = mean(effects)\n    end\n\n    return boot_effects\nend\n\n# Compute bootstrap CI\nboot_results = bootstrap_treatment_effect(df, @formula(y ~ x * treatment + age), 500)\nci_lower = quantile(boot_results, 0.025)\nci_upper = quantile(boot_results, 0.975)\nprintln(\"95% CI: [$(round(ci_lower, digits=3)), $(round(ci_upper, digits=3))]\")","category":"page"},{"location":"guide/scenarios/#Best-Practices","page":"Scenario Analysis","title":"Best Practices","text":"","category":"section"},{"location":"guide/scenarios/#When-to-Use-Each-Approach","page":"Scenario Analysis","title":"When to Use Each Approach","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Direct data modification (merge()):","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Simple scenarios (1-10 comparisons)\nExploratory analysis\nQuick prototyping\nSmall to medium datasets","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Contrast evaluator (contrastevaluator()):","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Categorical variable comparisons\nBatch processing (100+ contrasts)\nNeed for uncertainty quantification\nProduction pipelines","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Simple loops:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Population-level analysis\nAny scenario type\nMaximum flexibility\nLarge-scale analysis","category":"page"},{"location":"guide/scenarios/#Performance-Tips","page":"Scenario Analysis","title":"Performance Tips","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Pre-allocate buffers: Reuse row_vec and result vectors\nCompile once: Cache compiled formulas across scenarios\nBatch operations: Group related evaluations\nUse views: Avoid unnecessary copies with view()","category":"page"},{"location":"guide/scenarios/#Memory-Efficiency","page":"Scenario Analysis","title":"Memory Efficiency","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Good: Pre-allocate and reuse\nrow_vec = Vector{Float64}(undef, length(compiled))\nresults = Vector{Float64}(undef, n_individuals)\n\nfor i in 1:n_individuals\n    compiled(row_vec, scenario_data, i)\n    results[i] = dot(β, row_vec)\nend\n\n# Avoid: Allocating each iteration\nfor i in 1:n_individuals\n    row_vec = modelrow(compiled, scenario_data, i)  # Allocates!\n    results[i] = dot(β, row_vec)\nend","category":"page"},{"location":"guide/scenarios/#Statistical-Considerations","page":"Scenario Analysis","title":"Statistical Considerations","text":"","category":"section"},{"location":"guide/scenarios/#Causal-Interpretation","page":"Scenario Analysis","title":"Causal Interpretation","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Remember that counterfactual estimates depend on modeling assumptions:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Unconfoundedness: No unmeasured confounders\nPositivity: All individuals have positive probability of each treatment\nConsistency: Treatment definition is well-specified\nModel specification: Correct functional form","category":"page"},{"location":"guide/scenarios/#Uncertainty-Quantification","page":"Scenario Analysis","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Account for parameter uncertainty:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Use bootstrap for confidence intervals\nApply delta method for analytic standard errors\nConsider robust/clustered standard errors when appropriate","category":"page"},{"location":"guide/scenarios/#Sensitivity-Analysis-2","page":"Scenario Analysis","title":"Sensitivity Analysis","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Test robustness:","category":"page"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Vary model specifications\nCheck sensitivity to parameter ranges\nExamine heterogeneous effects across subgroups","category":"page"},{"location":"guide/scenarios/#Integration-with-Statistical-Workflows","page":"Scenario Analysis","title":"Integration with Statistical Workflows","text":"","category":"section"},{"location":"guide/scenarios/#Model-Comparison","page":"Scenario Analysis","title":"Model Comparison","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"# Compare models under fixed counterfactual\nmodels = [\n    lm(@formula(y ~ x + treatment), df),\n    lm(@formula(y ~ x * treatment), df),\n    lm(@formula(y ~ x * treatment + age), df)\n]\n\nscenario_data = merge(data, (treatment = fill(true, n_rows),))\n\nfor (i, model) in enumerate(models)\n    compiled = compile_formula(model, data)\n    β = coef(model)\n    row_vec = Vector{Float64}(undef, length(compiled))\n\n    predictions = Vector{Float64}(undef, n_individuals)\n    for j in 1:n_individuals\n        compiled(row_vec, scenario_data, j)\n        predictions[j] = dot(β, row_vec)\n    end\n\n    println(\"Model $i mean prediction: $(round(mean(predictions), digits=3))\")\nend","category":"page"},{"location":"guide/scenarios/#Further-Reading","page":"Scenario Analysis","title":"Further Reading","text":"","category":"section"},{"location":"guide/scenarios/","page":"Scenario Analysis","title":"Scenario Analysis","text":"Advanced Features - Additional computational patterns\nCategorical Mixtures - Profile-based marginal effects\nExamples - Real-world applications\nAPI Reference - Complete function documentation","category":"page"},{"location":"benchmarks/#Benchmark-Protocol","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Purpose","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Provide a reproducible method to validate performance and allocation claims.\nReport results with context and conservative interpretation.","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Environment","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Julia: record VERSION (e.g., 1.10.x or 1.11.x)\nCPU: model, frequency, cores; Sys.CPU_NAME if available\nOS: name and version\nThreads: Threads.nthreads() and BLAS threads (BLAS.get_num_threads())\nPackages: Pkg.status() for FormulaCompiler, GLM, MixedModels, ForwardDiff, Tables, DataFrames","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Runner Script","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"A convenience runner is provided at scripts/benchmarks.jl.\nExamples:\njulia --project=. scripts/benchmarks.jl (default subset)\njulia --project=. scripts/benchmarks.jl core deriv margins se (select tasks)\nPrints per-benchmark median/min time and minimum memory; include this output with your Environment section.","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Minimal runner","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Edit options at the top of scripts/benchmarks_simple.jl and run:\njulia --project=. scripts/benchmarks_simple.jl\nSet selected, fast, out, file, tag in the script; no CLI flags needed.","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Setup","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Activate project: Pkg.activate(\"..\"); Pkg.instantiate()\nUsing: using BenchmarkTools, FormulaCompiler, GLM, MixedModels, Tables, DataFrames, CategoricalArrays, Random\nFor marginal effects benchmarks (sections 5-6): using Margins  # See https://github.com/emfeltham/Margins.jl\nData format: Prefer Tables.columntable(df) for evaluation\nWarmup: run each function once before benchmarking","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Conventions","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Use @benchmark with concrete arguments; avoid globals\nRecord: minimum(time), median(time), minimum(memory)\nTarget allocations: FD paths 0 bytes; AD paths ≤512 bytes (ForwardDiff overhead)\nPresent ranges, not single points; note environment details","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Benchmarks","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Core Row Evaluation (Compiled)","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Model: small GLM (e.g., y ~ x * group + log1p(abs(z)) with categorical group)\nSteps:\nFit model with GLM; build data = Tables.columntable(df)\ncompiled = compile_formula(model, data)\nrow = Vector{Float64}(undef, length(compiled))\nSingle row: @benchmark $compiled($row, $data, 25)\nTight loop (amortized): call inside a loop over indices; check stability\nTargets: ≈O(10^1–10^2) ns; minimum(memory) == 0","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Allocating vs In-place Interfaces","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"modelrow(model, data, i) vs modelrow! with preallocated buffer\nTargets: In-place 0 bytes; allocating shows expected vector/matrix allocations","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Counterfactual Overhead","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Build counterfactual data: data_cf = merge(data, (x = fill(2.0, length(data.x)),))\nCompare evaluation: @benchmark $compiled($row, $data, 25) vs @benchmark $compiled($row, $data_cf, 25)\nTarget: identical times within noise; 0 allocations for both","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Derivative Jacobian (AD and FD)","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Build evaluators: de_ad = derivativeevaluator(:ad, compiled, data, [:x, :z]); de_fd = derivativeevaluator(:fd, compiled, data, [:x, :z])\nAD Jacobian: J = similar(rand(length(compiled), 2)); @benchmark derivative_modelrow!($J, $de_ad, 25)\nFD Jacobian: @benchmark derivative_modelrow!($J, $de_fd, 25)\nFD single-column: col = similar(rand(length(compiled))); @benchmark fd_jacobian_column!($col, $de_fd, 1, 1)\nTargets: AD ≤512 bytes; FD 0 bytes","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Marginal Effects (η and μ) [Requires Margins.jl]","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"using Margins\nβ = coef(model); g = similar(rand(2))  # Assuming 2 continuous variables\nη-scale AD: @benchmark marginal_effects_eta!($g, $de_ad, $β, 25)\nη-scale FD: @benchmark marginal_effects_eta!($g, $de_fd, $β, 25)\nμ-scale with link (e.g., Logit): @benchmark marginal_effects_mu!($g, $de_ad, $β, 25, LogitLink()) and @benchmark marginal_effects_mu!($g, $de_fd, $β, 25, LogitLink())\nTargets: FD 0 bytes; AD ≤512 bytes","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Delta Method SE [Requires Margins.jl]","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"using Margins\ngβ = similar(rand(length(β))); Σ = I*1.0 (or vcov(model))\n@benchmark delta_method_se($gβ, $Σ)\nTarget: 0 bytes, O(10^1) ns for dense small Σ","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"MixedModels Fixed Effects","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Fit a small LMM/GLMM; compile with fixed-effects extraction\nBenchmark compiled row evaluation as in (1)\nTarget: Same guarantees (0 bytes; similar timing)","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Scaling and Complexity","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Simple vs complex formulas; small vs larger OutputSize\nReport time growth and allocation behavior (should remain 0 for core paths)","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Size Invariance (Per-Row)","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Use scale_n to run the same per-row evaluation on increasing data sizes (e.g., 10k, 100k, 1M)\nExpectation: per-row latency and allocations remain effectively constant (0 B) as n increases","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Reporting Template","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Environment summary\nFor each benchmark: code snippet, median/min time, allocations, brief interpretation\nDeviations: note and investigate; check warmup, data format, thread counts","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Edge Cases","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Integer columns: verify automatic Float64 conversion in evaluator paths\nLarge tuples: ensure hybrid dispatch preserves 0 allocations\nCategorical mixtures: include a case if used (see mixtures guide)","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Interpretation","category":"page"},{"location":"benchmarks/","page":"Benchmark Protocol","title":"Benchmark Protocol","text":"Treat numbers as indicative; absolute values vary by system\nPrioritize allocation guarantees and scaling trends over exact nanoseconds","category":"page"},{"location":"benchmarks/#End","page":"Benchmark Protocol","title":"End","text":"","category":"section"},{"location":"guide/population_analysis/#Population-Analysis-Using-Row-Wise-Functions","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"This guide shows how to perform population-level analysis using row-wise marginal effects functions. The key insight is that population effects are simply averages over individual effects - simple loops over rows are all you need.","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Note: Marginal effects functions (marginal_effects_eta!, marginal_effects_mu!, etc.) are provided by Margins.jl. FormulaCompiler provides the computational primitives (derivative_modelrow!) that Margins.jl builds upon. Install Margins.jl to use the examples in this guide: using Pkg; Pkg.add(url=\"https://github.com/emfeltham/Margins.jl\")","category":"page"},{"location":"guide/population_analysis/#Core-Principle","page":"Population Analysis Using Row-Wise Functions","title":"Core Principle","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# Population Average Marginal Effect (AME)\nAME = (1/n) × Σᵢ ∂f(xᵢ)/∂x\n\n# Implementation: Individual effects + averaging\npopulation_effects = Vector{Float64}(undef, n_rows)\nfor (i, row) in enumerate(rows)\n    marginal_effects_eta!(temp_buffer, de, β, row)  # Existing row-wise function\n    population_effects[i] = temp_buffer[var_index]\nend\npopulation_ame = mean(population_effects)  # Simple arithmetic","category":"page"},{"location":"guide/population_analysis/#Computing-Population-Marginal-Effects","page":"Population Analysis Using Row-Wise Functions","title":"Computing Population Marginal Effects","text":"","category":"section"},{"location":"guide/population_analysis/#Basic-Pattern","page":"Population Analysis Using Row-Wise Functions","title":"Basic Pattern","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Use marginal_effects_eta!() in a loop to compute Average Marginal Effects (AME):","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"using FormulaCompiler, Margins, GLM, DataFrames, Tables\n\n# Setup: Fit model and compile\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    age = rand(18:80, 1000),\n    income = exp.(randn(1000))\n)\nmodel = lm(@formula(y ~ x + age + log(income)), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Build derivative evaluator for variables of interest\nde = derivativeevaluator(:fd, compiled, data, [:x, :age])\nβ = coef(model)\n\n# Compute population marginal effects\nn_rows = length(df.y)\ntemp_buffer = Vector{Float64}(undef, length(de.vars))\name_results = zeros(length(de.vars))\n\nfor row in 1:n_rows\n    # Compute marginal effects for this individual\n    marginal_effects_eta!(temp_buffer, de, β, row)\n\n    # Accumulate for population average\n    ame_results .+= temp_buffer\nend\n\n# Population AME = average over individuals\name_results ./= n_rows\n\nprintln(\"Population Average Marginal Effects:\")\nfor (i, var) in enumerate(de.vars)\n    println(\"  $var: $(ame_results[i])\")\nend","category":"page"},{"location":"guide/population_analysis/#Weighted-Population-Effects","page":"Population Analysis Using Row-Wise Functions","title":"Weighted Population Effects","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"For survey data or other weighted analyses:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# Assume we have survey weights\nweights = rand(0.5:0.1:2.0, n_rows)  # Example weights\ntotal_weight = sum(weights)\n\n# Weighted population marginal effects\nweighted_ame = zeros(length(de.vars))\n\nfor row in 1:n_rows\n    marginal_effects_eta!(temp_buffer, de, β, row)\n\n    # Weight each individual's contribution\n    weighted_ame .+= weights[row] .* temp_buffer\nend\n\n# Weighted average\nweighted_ame ./= total_weight\n\nprintln(\"Weighted Population AME:\")\nfor (i, var) in enumerate(de.vars)\n    println(\"  $var: $(weighted_ame[i])\")\nend","category":"page"},{"location":"guide/population_analysis/#Scenario-Analysis-Using-Data-Modification","page":"Population Analysis Using Row-Wise Functions","title":"Scenario Analysis Using Data Modification","text":"","category":"section"},{"location":"guide/population_analysis/#Single-Variable-Scenario","page":"Population Analysis Using Row-Wise Functions","title":"Single Variable Scenario","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Evaluate \"what if all individuals had a specific value for a variable\":","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# Scenario: What if everyone had income = 50,000?\nscenario_var = :income\nscenario_value = log(50000)  # Model uses log(income)\n\n# Create counterfactual data with modified variable\ncf_data = merge(data, (income = fill(scenario_value, n_rows),))\n\n# Evaluate scenario for each individual\nscenario_predictions = Vector{Float64}(undef, n_rows)\noutput_buffer = Vector{Float64}(undef, length(compiled))\n\nfor row in 1:n_rows\n    # Evaluate model with counterfactual data\n    compiled(output_buffer, cf_data, row)\n\n    # Extract prediction (assuming single outcome)\n    scenario_predictions[row] = dot(β, output_buffer)\nend\n\n# Population-level scenario results\npopulation_scenario_mean = mean(scenario_predictions)\nprintln(\"Population mean under scenario: $population_scenario_mean\")\n\n# Compare with baseline\nbaseline_predictions = Vector{Float64}(undef, n_rows)\nfor row in 1:n_rows\n    compiled(output_buffer, data, row)\n    baseline_predictions[row] = dot(β, output_buffer)\nend\n\nbaseline_mean = mean(baseline_predictions)\nscenario_effect = population_scenario_mean - baseline_mean\nprintln(\"Population scenario effect: $scenario_effect\")","category":"page"},{"location":"guide/population_analysis/#Multiple-Variable-Scenarios","page":"Population Analysis Using Row-Wise Functions","title":"Multiple Variable Scenarios","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Policy analysis with multiple variables changed simultaneously:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# Policy scenario: Universal basic income + education investment\npolicy_vars = [:income, :education_years]\npolicy_values = [log(30000), 16.0]  # $30k income, 16 years education\n\n# Create counterfactual data with multiple modified variables\ncf_data = merge(data, (\n    income = fill(policy_values[1], n_rows),\n    education_years = fill(policy_values[2], n_rows)\n))\n\n# Evaluate policy for each individual\npolicy_predictions = Vector{Float64}(undef, n_rows)\n\nfor row in 1:n_rows\n    # Evaluate under policy\n    compiled(output_buffer, cf_data, row)\n    policy_predictions[row] = dot(β, output_buffer)\nend\n\n# Policy impact analysis\npolicy_effect = mean(policy_predictions) - baseline_mean\nprintln(\"Policy effect: $policy_effect\")\n\n# Distribution analysis\nprintln(\"Policy effect distribution:\")\nprintln(\"  Min: $(minimum(policy_predictions - baseline_predictions))\")\nprintln(\"  Max: $(maximum(policy_predictions - baseline_predictions))\")\nprintln(\"  Std: $(std(policy_predictions - baseline_predictions))\")","category":"page"},{"location":"guide/population_analysis/#Comparing-Multiple-Scenarios","page":"Population Analysis Using Row-Wise Functions","title":"Comparing Multiple Scenarios","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Systematic policy comparison:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# Define scenarios to compare\nscenarios = [\n    (name=\"Baseline\", vars=Symbol[], values=Float64[]),\n    (name=\"Income +20%\", vars=[:income], values=[log(1.2)]),  # Relative increase\n    (name=\"Education +2yr\", vars=[:education_years], values=[2.0]),  # Absolute increase\n    (name=\"Combined\", vars=[:income, :education_years], values=[log(1.2), 2.0])\n]\n\nscenario_results = Dict{String, Vector{Float64}}()\n\nfor scenario in scenarios\n    if isempty(scenario.vars)\n        # Baseline: use original data\n        predictions = Vector{Float64}(undef, n_rows)\n        for row in 1:n_rows\n            compiled(output_buffer, data, row)\n            predictions[row] = dot(β, output_buffer)\n        end\n        scenario_results[scenario.name] = predictions\n    else\n        # Counterfactual scenario - build modified data\n        # Handle relative vs absolute changes\n        modified_cols = Dict{Symbol, Vector{Float64}}()\n\n        for (i, (var, value)) in enumerate(zip(scenario.vars, scenario.values))\n            if var == :income  # Relative change\n                # Add log(1.2) to each individual's log(income)\n                modified_cols[var] = getproperty(data, var) .+ value\n            else  # Absolute change\n                # Add fixed value to each individual's value\n                modified_cols[var] = getproperty(data, var) .+ value\n            end\n        end\n\n        cf_data = merge(data, NamedTuple(modified_cols))\n\n        predictions = Vector{Float64}(undef, n_rows)\n        for row in 1:n_rows\n            compiled(output_buffer, cf_data, row)\n            predictions[row] = dot(β, output_buffer)\n        end\n        scenario_results[scenario.name] = predictions\n    end\nend\n\n# Compare scenarios\nprintln(\"Scenario Comparison:\")\nbaseline = scenario_results[\"Baseline\"]\nfor (name, predictions) in scenario_results\n    if name != \"Baseline\"\n        effect = mean(predictions) - mean(baseline)\n        println(\"  $name: $(round(effect, digits=4))\")\n    end\nend","category":"page"},{"location":"guide/population_analysis/#Performance-Tips-for-Large-Datasets","page":"Population Analysis Using Row-Wise Functions","title":"Performance Tips for Large Datasets","text":"","category":"section"},{"location":"guide/population_analysis/#Buffer-Reuse","page":"Population Analysis Using Row-Wise Functions","title":"Buffer Reuse","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"For large datasets, reuse buffers to minimize allocations:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# Pre-allocate all buffers\nn_rows = length(df.y)\nn_vars = length(de.vars)\ntemp_buffer = Vector{Float64}(undef, n_vars)\noutput_buffer = Vector{Float64}(undef, length(compiled))\name_accumulator = zeros(n_vars)\n\n# Efficient loop with buffer reuse\nfor row in 1:n_rows\n    # Reuse temp_buffer for each row\n    marginal_effects_eta!(temp_buffer, de, β, row)\n    ame_accumulator .+= temp_buffer\nend\n\name_results = ame_accumulator ./ n_rows","category":"page"},{"location":"guide/population_analysis/#Batch-Processing","page":"Population Analysis Using Row-Wise Functions","title":"Batch Processing","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"For very large datasets, process in batches:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"function compute_population_ame_batched(de, β, batch_size=1000)\n    n_rows = length(getproperty(de.base_data, first(de.vars)))\n    n_vars = length(de.vars)\n\n    ame_accumulator = zeros(n_vars)\n    temp_buffer = Vector{Float64}(undef, n_vars)\n\n    for batch_start in 1:batch_size:n_rows\n        batch_end = min(batch_start + batch_size - 1, n_rows)\n\n        for row in batch_start:batch_end\n            marginal_effects_eta!(temp_buffer, de, β, row)\n            ame_accumulator .+= temp_buffer\n        end\n\n        # Optional: progress reporting\n        if batch_end % (10 * batch_size) == 0\n            println(\"Processed $(batch_end)/$(n_rows) observations\")\n        end\n    end\n\n    return ame_accumulator ./ n_rows\nend\n\n# Usage\name_results = compute_population_ame_batched(de, β, 5000)","category":"page"},{"location":"guide/population_analysis/#Parallel-Processing","page":"Population Analysis Using Row-Wise Functions","title":"Parallel Processing","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"For massive datasets, use threading:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"using Base.Threads\n\nfunction compute_population_ame_parallel(de, β)\n    n_rows = length(getproperty(de.base_data, first(de.vars)))\n    n_vars = length(de.vars)\n\n    # Thread-local accumulators\n    thread_accumulators = [zeros(n_vars) for _ in 1:nthreads()]\n\n    @threads for row in 1:n_rows\n        tid = threadid()\n        temp_buffer = Vector{Float64}(undef, n_vars)\n\n        marginal_effects_eta!(temp_buffer, de, β, row)\n        thread_accumulators[tid] .+= temp_buffer\n    end\n\n    # Combine thread results\n    total_accumulator = zeros(n_vars)\n    for acc in thread_accumulators\n        total_accumulator .+= acc\n    end\n\n    return total_accumulator ./ n_rows\nend\n\n# Usage (requires Julia started with multiple threads)\name_results = compute_population_ame_parallel(de, β)","category":"page"},{"location":"guide/population_analysis/#Implementation-Properties","page":"Population Analysis Using Row-Wise Functions","title":"Implementation Properties","text":"","category":"section"},{"location":"guide/population_analysis/#Memory-Efficiency","page":"Population Analysis Using Row-Wise Functions","title":"Memory Efficiency","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"O(1) memory usage: Independent of dataset size\nNo data copying: CounterfactualVector provides transparent value substitution\nBuffer reuse: Same temporary arrays used across all rows","category":"page"},{"location":"guide/population_analysis/#Performance-Characteristics","page":"Population Analysis Using Row-Wise Functions","title":"Performance Characteristics","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Zero allocations: After warmup, row-wise functions allocate 0 bytes\nCache efficiency: Sequential row processing optimizes memory access\nCompiler optimization: Simple loops enable aggressive optimization","category":"page"},{"location":"guide/population_analysis/#Simplicity","page":"Population Analysis Using Row-Wise Functions","title":"Simplicity","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"No special API: Uses existing, well-tested row-wise functions\nClear semantics: Population = individual + averaging (mathematically obvious)\nEasy debugging: Can inspect individual-level results before averaging","category":"page"},{"location":"guide/population_analysis/#Extensibility","page":"Population Analysis Using Row-Wise Functions","title":"Extensibility","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Custom aggregation: Not limited to simple averages (can use quantiles, weighted averages, etc.)\nConditional analysis: Easy to subset rows or apply complex filters\nScenario combinations: Natural composition of multiple counterfactual changes","category":"page"},{"location":"guide/population_analysis/#Migration-from-Population-Functions","page":"Population Analysis Using Row-Wise Functions","title":"Migration from Population Functions","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"If you were previously using population-specific functions:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"# OLD: Population-specific API (removed in v1.1.0)\nscenario = create_scenario(\"policy\", data; income = 50000)  # REMOVED\ncompiled_scenario = compile_formula(model, scenario.data)\npopulation_effect = compute_population_effect(compiled_scenario, ...)\n\n# CURRENT: Simple data modification + loops\ncf_data = merge(data, (income = fill(log(50000), n_rows),))\n\neffects = Vector{Float64}(undef, n_rows)\nfor row in 1:n_rows\n    compiled(output_buffer, cf_data, row)\n    effects[row] = dot(β, output_buffer)\nend\npopulation_effect = mean(effects)","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"The row-wise approach is:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Faster: Simple loops with minimal overhead\nExtensible aggregation: Supports custom aggregation functions beyond simple averaging\nMore transparent: Can examine individual-level results\nMemory efficient: O(1) usage vs O(n) for data copying approaches","category":"page"},{"location":"guide/population_analysis/#Summary","page":"Population Analysis Using Row-Wise Functions","title":"Summary","text":"","category":"section"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Population analysis in FormulaCompiler is achieved through:","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"Individual-level computation: Use existing row-wise functions (marginal_effects_eta!, etc.)\nCounterfactual scenarios: Use CounterfactualVector system for single-observation perturbations\nSimple aggregation: Apply standard arithmetic (mean, weighted average, etc.)","category":"page"},{"location":"guide/population_analysis/","page":"Population Analysis Using Row-Wise Functions","title":"Population Analysis Using Row-Wise Functions","text":"This simple loop-based approach provides superior performance, flexibility, and clarity.","category":"page"},{"location":"architecture/#Architecture","page":"Architecture","title":"Architecture","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Technical overview of FormulaCompiler.jl’s unified, zero‑allocation compilation and execution model.","category":"page"},{"location":"architecture/#Design-Philosophy","page":"Architecture","title":"Design Philosophy","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Move expensive work to compile time; keep runtime simple and type‑stable.","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Compile‑time specialization: All positions and operations are baked into types\nType stability: No dynamic dispatch in hot paths\nMemory reuse: Preallocate once; reuse across evaluations\nPosition mapping: Address everything by compile‑time positions, not names","category":"page"},{"location":"architecture/#System-Overview","page":"Architecture","title":"System Overview","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"(Image: Diagram)","category":"page"},{"location":"architecture/#Unified-Compilation-Pipeline","page":"Architecture","title":"Unified Compilation Pipeline","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"The compilation process transforms statistical formulas into optimized evaluators:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"(Image: Diagram)","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Compilation produces a single position‑mapped evaluator (UnifiedCompiled) in four steps:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Decompose terms → operations","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Parse the schema‑applied formula and convert into primitive ops:\nLoadOp, ConstantOp, UnaryOp, BinaryOp, ContrastOp, CopyOp","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Allocate positions","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Assign scratch positions for intermediates and indices for final outputs\nCache term → position mapping to reuse computed intermediates","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Specialize operation types","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Embed positions and keys as type parameters (e.g., LoadOp{:x, 3})\nConvert op vector to a tuple for type‑stable execution","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Package into UnifiedCompiled","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Store op tuple and a preallocated scratch buffer sized to maximum position\nProvide a callable that writes directly into a user‑supplied output vector","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Result: compiled(row_vec, data, row) runs in tens of nanoseconds with 0 allocations after warmup (typical; see Benchmark Protocol).","category":"page"},{"location":"architecture/#Operation-Set","page":"Architecture","title":"Operation Set","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Primitive operations form an acyclic execution plan:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"LoadOp{Column, OutPos}: data[column][row] → scratch[OutPos]\nConstantOp{Value, OutPos}: literal → scratch[OutPos]\nUnaryOp{Func, InPos, OutPos}: f(scratch[InPos]) → scratch[OutPos]\nBinaryOp{Func, In1, In2, OutPos}: f(scratch[In1], scratch[In2]) → scratch[OutPos]\nContrastOp{Column, OutPositions}: categorical expansion → scratch[each(OutPositions)]\nCopyOp{InPos, OutIdx}: scratch[InPos] → output[OutIdx]","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"All operation ordering respects dependencies to ensure each input is ready when used.","category":"page"},{"location":"architecture/#Zero‑Allocation-Execution","page":"Architecture","title":"Zero‑Allocation Execution","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Runtime evaluation is pure array indexing with concrete types:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Scratch: Vector{Float64}(undef, ScratchSize) allocated once inside UnifiedCompiled\nOutput: Provided by the caller; must have length length(compiled)\nExecution: Iterate the typed op tuple and update scratch/output in place","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Path to zero allocations:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Preallocate scratch once per compiled formula\nNo temporary arrays or dynamic dispatch during execution\nColumn access uses direct field lookup from a NamedTuple (column table)","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"For complex formulas (>10 operations) and derivative computation, the system uses targeted metaprogramming to maintain zero-allocation performance. See Metaprogramming for implementation details.","category":"page"},{"location":"architecture/#CounterfactualVector-System","page":"Architecture","title":"CounterfactualVector System","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Unified Row-Wise Architecture: Population analysis = individual analysis + averaging","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"CounterfactualVector hierarchy: Type-stable single-row perturbations for all data types\nNumericCounterfactualVector{T}: Numeric variables with automatic type conversion\nBoolCounterfactualVector: Boolean variables\nCategoricalCounterfactualVector{T,R}: Categorical variables with contrast support\nCategoricalMixtureCounterfactualVector{T}: Categorical mixtures for profile effects\nTypedCounterfactualVector{T,V}: Generic fallback for other types\nMemory Efficiency: O(1) memory usage vs O(n) for data copying approaches\nPerformance: Simple loops achieve 10-100x speedup over data copying\nType Stability: Concrete types throughout, no Any types on hot paths","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Population Analysis Pattern:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"# Simple loop pattern for efficient population analysis\npopulation_effects = Vector{Float64}(undef, n_rows)\nfor row in 1:n_rows\n    # Use existing row-wise functions with CounterfactualVector perturbations\n    population_effects[row] = compute_individual_effect(row)\nend\npopulation_ame = mean(population_effects)","category":"page"},{"location":"architecture/#Integration","page":"Architecture","title":"Integration","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"GLM.jl: Works with all linear and generalized linear models\nMixedModels.jl: Automatically extracts fixed‑effects formula via fixed_effects_form\nStandardizedPredictors.jl: ZScore standardization supported at compile time","category":"page"},{"location":"architecture/#Extensibility","page":"Architecture","title":"Extensibility","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Add an operation or transformation by composing existing ops during decomposition, or extend model support via dispatch that extracts a StatsModels @formula and delegates to the unified compiler.","category":"page"},{"location":"architecture/#Performance-Monitoring","page":"Architecture","title":"Performance Monitoring","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Check allocations and timings with BenchmarkTools:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"@allocated compiled(row_vec, data, 1)  # Expect 0\n@benchmark $compiled($row_vec, $data, 1)","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Figure generation","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"During docs builds, diagrams under docs/src/assets/*.mmd are automatically regenerated to SVG if the Mermaid CLI (mmdc) is available (see docs/make.jl).","category":"page"},{"location":"architecture/#Unified-Row-Wise-Architecture","page":"Architecture","title":"Unified Row-Wise Architecture","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Design Philosophy: Population analysis = individual analysis + averaging","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Key Features:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Population system eliminated: Clean, simplified architecture\nCounterfactualVector system: All data types supported including mixtures\nType-stable throughout: Concrete types for zero-allocation performance\nAPI simplified: Clean exports focused on row-wise operations only","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Performance Characteristics:","category":"page"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Zero allocations: 0 bytes for core evaluation, derivatives, and marginal effects\nFast per-row: Timings vary by system, but typically <100ns per row\nMemory efficient: O(1) memory for counterfactual analysis vs O(n) for data copying","category":"page"},{"location":"architecture/#Future-Directions","page":"Architecture","title":"Future Directions","text":"","category":"section"},{"location":"architecture/","page":"Architecture","title":"Architecture","text":"Parallel row evaluation for batches\nExpanded function library and transformations\nStreaming and distributed execution patterns\nEnhanced categorical mixture support","category":"page"},{"location":"metaprogramming/#Metaprogramming-in-FormulaCompiler.jl","page":"Metaprogramming","title":"Metaprogramming in FormulaCompiler.jl","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"NOT UP TO CURRENT SPEC","category":"page"},{"location":"metaprogramming/#Overview","page":"Metaprogramming","title":"Overview","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"FormulaCompiler.jl uses targeted metaprogramming to achieve zero-allocation evaluation for statistical formulas of arbitrary complexity. This document explains when, why, and how metaprogramming is employed to bypass Julia's inherent limitations while maintaining type stability and performance.","category":"page"},{"location":"metaprogramming/#Design-Philosophy","page":"Metaprogramming","title":"Design Philosophy","text":"","category":"section"},{"location":"metaprogramming/#Metaprogramming-as-a-Precision-Tool","page":"Metaprogramming","title":"Metaprogramming as a Precision Tool","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"The package follows a \"metaprogramming as last resort\" philosophy:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Prefer natural Julia: Use recursion, tuples, and type parameters when possible\nMetaprogramming only when necessary: Apply when Julia's built-in mechanisms hit limits\nTargeted solutions: Use the minimal metaprogramming needed to solve specific problems\nMaintain simplicity: Avoid complex code generation that's hard to understand or maintain","category":"page"},{"location":"metaprogramming/#Core-Principle:-Compile-Time-Specialization","page":"Metaprogramming","title":"Core Principle: Compile-Time Specialization","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"All metaprogramming serves a single goal: embed runtime decisions into compile-time type specialization to eliminate allocations and dynamic dispatch.","category":"page"},{"location":"metaprogramming/#Metaprogramming-Use-Cases","page":"Metaprogramming","title":"Metaprogramming Use Cases","text":"","category":"section"},{"location":"metaprogramming/#1.-Large-Formula-Execution","page":"Metaprogramming","title":"1. Large Formula Execution","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Problem: Julia's tuple specialization is heuristic-based and can fail for large operation tuples, causing performance degradation for complex statistical formulas.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Location: src/compilation/execution.jl","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Solution: Hybrid dispatch strategy with @generated fallback.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@inline function execute_ops(ops::Tuple, scratch, data, row_idx)\n    if length(ops) <= RECURSION_LIMIT  # 10 operations\n        # Natural Julia recursion (preferred)\n        execute_ops_recursive(ops, scratch, data, row_idx)\n    else\n        # Metaprogramming fallback (forced specialization)\n        execute_ops_generated(ops, scratch, data, row_idx)\n    end\nend","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"The @generated function forces complete unrolling:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function execute_ops_generated(\n    ops::Tuple{Vararg{Any,N}}, \n    scratch::AbstractVector{T}, \n    data::NamedTuple, \n    row_idx::Int\n) where {N, T}\n    # Build expressions for each operation at compile time\n    exprs = Expr[]\n    for i in 1:N\n        push!(exprs, :(execute_op(ops[$i], scratch, data, row_idx)))\n    end\n    \n    return quote\n        $(exprs...)\n        nothing\n    end\nend","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Result: Zero allocations for formulas with 100+ terms, identical performance to small formulas.","category":"page"},{"location":"metaprogramming/#2.-Zero-Allocation-Finite-Differences","page":"Metaprogramming","title":"2. Zero-Allocation Finite Differences","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Problem: Computing derivatives via finite differences requires loops over variables, creating allocation pressure and dispatch overhead.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Location: src/evaluation/derivatives/finite_diff.jl","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Solution: Complete loop unrolling at compile time using type-level variable count.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function _derivative_modelrow_fd_auto!(\n    J::AbstractMatrix{Float64},\n    de::derivativeevaluator{T, Ops, S, O, NTBase, NTMerged, NV, ColsT, G, JC, GS, GC},\n    row::Int,\n) where {T, Ops, S, O, NTBase, NTMerged, NV, ColsT, G, JC, GS, GC}\n    N = NV  # Extract number of variables from type parameter\n    stmts = Expr[]\n    \n    # Initialize buffers\n    push!(stmts, :(yplus = de.y_plus))\n    push!(stmts, :(yminus = de.yminus)) \n    push!(stmts, :(xbase = de.xbase))\n    push!(stmts, :(nterms = length(de)))\n    \n    # Unroll variable extraction loop\n    for j in 1:N\n        push!(stmts, :(@inbounds xbase[$j] = de.fd_columns[$j][row]))\n    end\n    \n    # Unroll override setup loop\n    for i in 1:N\n        push!(stmts, :(@inbounds de.overrides[$i].row = row))\n    end\n    \n    # Unroll main finite difference computation\n    for j in 1:N\n        push!(stmts, :(x = xbase[$j]))\n        \n        # Reset all overrides to base values\n        for k in 1:N\n            push!(stmts, :(@inbounds de.overrides[$k].replacement = xbase[$k]))\n        end\n        \n        # Compute step size\n        push!(stmts, :(h = cbrt(eps(Float64)) * max(abs(x), 1.0)))\n        \n        # Forward perturbation\n        push!(stmts, :(@inbounds de.overrides[$j].replacement = x + h))\n        push!(stmts, :(de.compiled_dual(yplus, de.data_over_dual, row)))\n        \n        # Backward perturbation  \n        push!(stmts, :(@inbounds de.overrides[$j].replacement = x - h))\n        push!(stmts, :(de.compiled_dual(yminus, de.data_over_dual, row)))\n        \n        # Central difference computation\n        push!(stmts, :(inv_2h = 1.0 / (2.0 * h)))\n        push!(stmts, quote\n            @fastmath for i in 1:nterms\n                @inbounds J[i, $j] = (yplus[i] - yminus[i]) * inv_2h\n            end\n        end)\n    end\n    \n    return quote\n        $(stmts...)\n        nothing\n    end\nend","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Key Benefits:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Zero allocations: No dynamic arrays or temporary storage\nNo dispatch overhead: All variable access patterns embedded at compile time  \nOptimal step sizing: Mathematical step size computed once per variable\nType stability: All array accesses use compile-time indices","category":"page"},{"location":"metaprogramming/#3.-Output-Buffer-Management","page":"Metaprogramming","title":"3. Output Buffer Management","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Problem: Copying results from scratch buffers to output vectors can allocate if done generically.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Location: src/compilation/execution.jl","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Solution: Generate copy operations with fixed indices.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function copy_outputs_generated!(\n    ops::Tuple{Vararg{Any,N}}, \n    output::AbstractVector{T}, \n    scratch::AbstractVector{T}\n) where {N, T}\n    exprs = Expr[]\n    for i in 1:N\n        # Extract output position from operation type\n        if hasfield(typeof(ops.parameters[i]), :output_pos)\n            pos = ops.parameters[i].output_pos\n            push!(exprs, :(@inbounds output[$pos] = scratch[$pos]))\n        end\n    end\n    \n    return quote\n        $(exprs...)\n        nothing\n    end\nend","category":"page"},{"location":"metaprogramming/#Performance-Impact","page":"Metaprogramming","title":"Performance Impact","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"The figures below are illustrative and hardware-dependent. See the Benchmark Protocol for environment setup and reproduction guidance.","category":"page"},{"location":"metaprogramming/#Metaprogramming-Effectiveness","page":"Metaprogramming","title":"Metaprogramming Effectiveness","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"The metaprogramming eliminates allocations and dynamic dispatch in hot paths and preserves small-formula performance for large formulas. See the measured results on the index page and the Benchmark Protocol for how to reproduce them on your hardware.","category":"page"},{"location":"metaprogramming/#Compilation-Time-Trade-offs","page":"Metaprogramming","title":"Compilation Time Trade-offs","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Metaprogramming increases first-compilation latency and compiled code size modestly for complex formulas; subsequent runs use cached code without additional cost. For statistical applications where a formula is compiled once and evaluated many times, this trade‑off is favorable.","category":"page"},{"location":"metaprogramming/#Implementation-Patterns","page":"Metaprogramming","title":"Implementation Patterns","text":"","category":"section"},{"location":"metaprogramming/#Pattern-1:-Type-Driven-Generation","page":"Metaprogramming","title":"Pattern 1: Type-Driven Generation","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Extract compile-time constants from type parameters:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function my_function(data::MyType{N, Positions}) where {N, Positions}\n    # N and Positions are compile-time constants\n    # Generate code using these values\nend","category":"page"},{"location":"metaprogramming/#Pattern-2:-Tuple-Length-Unrolling","page":"Metaprogramming","title":"Pattern 2: Tuple Length Unrolling","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Generate code for each tuple element:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function process_tuple(ops::Tuple{Vararg{Any,N}}) where N\n    exprs = Expr[]\n    for i in 1:N\n        push!(exprs, :(process_element(ops[$i])))\n    end\n    return quote; $(exprs...); end\nend","category":"page"},{"location":"metaprogramming/#Pattern-3:-Nested-Loop-Flattening","page":"Metaprogramming","title":"Pattern 3: Nested Loop Flattening","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Convert nested runtime loops into unrolled compile-time sequences:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function nested_computation(data::MyType{NVars, NTerms}) where {NVars, NTerms}\n    stmts = Expr[]\n    for var in 1:NVars\n        for term in 1:NTerms\n            push!(stmts, :(computation($var, $term)))\n        end\n    end\n    return quote; $(stmts...); end\nend","category":"page"},{"location":"metaprogramming/#Best-Practices","page":"Metaprogramming","title":"Best Practices","text":"","category":"section"},{"location":"metaprogramming/#When-to-Use-Metaprogramming","page":"Metaprogramming","title":"When to Use Metaprogramming","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Use metaprogramming when:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Julia's built-in mechanisms hit limits (tuple specialization, inference)\nRuntime dispatch causes measurable allocation or performance issues\nLoop bounds are known at compile time and unrolling provides benefits\nType parameters carry sufficient information for code generation","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Avoid metaprogramming when:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Natural Julia code achieves the same performance\nCode generation complexity outweighs benefits\nDebugging or maintenance becomes significantly harder\nCompilation time becomes prohibitive","category":"page"},{"location":"metaprogramming/#Code-Generation-Guidelines","page":"Metaprogramming","title":"Code Generation Guidelines","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Structure generated code clearly:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@generated function my_function(args...)\n    # 1. Extract compile-time information\n    N = get_compile_time_constant(args...)\n    \n    # 2. Build expressions systematically\n    setup_exprs = [...]\n    loop_exprs = [generate_loop(i) for i in 1:N]\n    cleanup_exprs = [...]\n    \n    # 3. Return well-structured quote block\n    return quote\n        $(setup_exprs...)\n        $(loop_exprs...)\n        $(cleanup_exprs...)\n        nothing  # Always explicit return\n    end\nend","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Validate generated code:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"# Include debug utilities\n@generated function my_function(args...)\n    code = generate_my_code(args...)\n    \n    # Optional: pretty-print generated code during development\n    @static if DEBUG_METAPROGRAMMING\n        @info \"Generated code:\" code\n    end\n    \n    return code\nend","category":"page"},{"location":"metaprogramming/#Fallback-Strategies","page":"Metaprogramming","title":"Fallback Strategies","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Always provide non-metaprogramming fallbacks:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"function my_api_function(args...)\n    if should_use_metaprogramming(args...)\n        generated_version(args...)\n    else\n        fallback_version(args...)\n    end\nend","category":"page"},{"location":"metaprogramming/#Integration-with-Broader-Architecture","page":"Metaprogramming","title":"Integration with Broader Architecture","text":"","category":"section"},{"location":"metaprogramming/#Position-Mapping-Preservation","page":"Metaprogramming","title":"Position Mapping Preservation","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"All metaprogramming maintains the package's core position mapping invariants:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Compile-time positions: All array indices embedded as constants\nType stability: Generated code preserves input/output types\nZero allocation: No dynamic memory management in generated paths","category":"page"},{"location":"metaprogramming/#Testing-Generated-Code","page":"Metaprogramming","title":"Testing Generated Code","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Generated functions require special testing considerations:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"@testset \"Generated Functions\" begin\n    # Test various type parameter combinations\n    for N in [1, 5, 10, 50, 100]\n        data = create_test_data(N)\n        \n        # Test correctness\n        @test generated_result(data) ≈ reference_result(data)\n        \n        # Test allocations\n        @test @allocated(generated_version(data)) == 0\n        \n        # Test performance\n        @test @elapsed(generated_version(data)) < performance_threshold\n    end\nend","category":"page"},{"location":"metaprogramming/#Future-Considerations","page":"Metaprogramming","title":"Future Considerations","text":"","category":"section"},{"location":"metaprogramming/#Evolution-Strategy","page":"Metaprogramming","title":"Evolution Strategy","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"The metaprogramming approach is designed to be incrementally replaceable:","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Compiler improvements: If Julia's tuple specialization improves, generated functions can be simplified\nNew language features: Future Julia versions may provide better alternatives\nPerformance monitoring: Continuous benchmarking ensures metaprogramming remains beneficial","category":"page"},{"location":"metaprogramming/#Maintenance-Approach","page":"Metaprogramming","title":"Maintenance Approach","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"Isolated complexity: All metaprogramming confined to specific, well-documented functions\nClear interfaces: Generated functions provide the same API as non-generated alternatives\nComprehensive testing: Extra validation for generated code paths","category":"page"},{"location":"metaprogramming/#Conclusion","page":"Metaprogramming","title":"Conclusion","text":"","category":"section"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"FormulaCompiler.jl's metaprogramming serves a specific, measurable purpose: achieving zero-allocation evaluation for arbitrarily complex statistical formulas. The approach is conservative, targeted, and provides clear performance benefits while maintaining code clarity and maintainability.","category":"page"},{"location":"metaprogramming/","page":"Metaprogramming","title":"Metaprogramming","text":"The key insight is that metaprogramming enables compile-time specialization that would be impossible through Julia's standard mechanisms alone, unlocking performance critical for statistical computing applications where the same formula is evaluated thousands or millions of times.","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"API reference for FormulaCompiler.jl functions and types.","category":"page"},{"location":"api/#Core-Compilation-Functions","page":"API Reference","title":"Core Compilation Functions","text":"","category":"section"},{"location":"api/#FormulaCompiler.compile_formula","page":"API Reference","title":"FormulaCompiler.compile_formula","text":"compile_formula(model, data) -> UnifiedCompiled\n\nCompile a fitted statistical model into a zero-allocation, type-specialized evaluator.\n\nTransforms statistical formulas into optimized computational engines using position mapping that achieves ~50ns per row evaluation with zero allocations. The resulting evaluator provides constant-time row access regardless of dataset size.\n\nArguments\n\nmodel: Fitted statistical model (GLM.LinearModel, GLM.GeneralizedLinearModel,          MixedModels.LinearMixedModel, etc.)\ndata: Data in Tables.jl format (preferably Tables.columntable(df) for optimal performance)\n\nReturns\n\nUnifiedCompiled{T,Ops,S,O}: Callable evaluator with embedded position mappings\nCall as compiled(output_vector, data, row_index) for zero-allocation evaluation\nlength(compiled) returns number of model matrix columns\n\nPerformance Characteristics\n\nCompilation: One-time cost for complex formulas\nEvaluation: Zero bytes allocated after warmup\nMemory: O(output_size) scratch space, reused across all evaluations\nScaling: Evaluation time independent of dataset size\n\nSupported Models\n\nLinear models: GLM.lm(@formula(y ~ x + group), df)\nGeneralized linear models: GLM.glm(@formula(success ~ x), df, Binomial(), LogitLink())\nMixed models: MixedModels.fit(MixedModel, @formula(y ~ x + (1|group)), df) (fixed effects only)\nCustom contrasts: Models with DummyCoding(), EffectsCoding(), HelmertCoding(), etc.\nStandardized predictors: Models with ZScore() standardization\n\nFormula Features\n\nBasic terms: x, log(z), x^2, (x > 0), integer and float variables\nCategorical variables: Must use CategoricalArrays.jl format - raw strings not supported\nInteractions: x * group, x * y * z, log(x) * group\nFunctions: log, exp, sqrt, sin, cos, abs, ^ (integer and fractional powers)\nBoolean conditions: (x > 0), (z >= mean(z)), (group == \"A\")\nComplex formulas: x * log(abs(z)) * group + sqrt(y) + (w > threshold)\n\nData Requirements\n\nCategorical variables: Must use categorical(column) before model fitting\nMissing values: Not supported - remove with dropmissing() or impute before compilation\nTable format: Use Tables.columntable(df) for optimal performance\n\nExample\n\nusing FormulaCompiler, GLM, DataFrames, Tables, CategoricalArrays\n\n# Fit model\ndf = DataFrame(\n    y = randn(1000), \n    x = randn(1000), \n    group = categorical(rand([\"A\", \"B\"], 1000))  # Required: use categorical()\n)\nmodel = lm(@formula(y ~ x * group + log(abs(x) + 1)), df)\n\n# Compile once\ndata = Tables.columntable(df)  # Convert for optimal performance\ncompiled = compile_formula(model, data)\n\n# Use many times (zero allocations)\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, data, 1)     # Zero allocations\ncompiled(output, data, 500)   # Zero allocations\n\n# Substantial speedup compared to modelmatrix(model)[row, :]\n\nMixed Models Example\n\nusing MixedModels\nmixed = fit(MixedModel, @formula(y ~ x + treatment + (1|subject)), df)\ncompiled = compile_formula(mixed, data)  # Compiles fixed effects: y ~ x + treatment\n\nSee also: modelrow!, ModelRowEvaluator\n\n\n\n\n\ncompile_formula(formula::StatsModels.FormulaTerm, data) -> UnifiedCompiled\n\nCompile a formula directly without a fitted model for zero-allocation evaluation.\n\nThis overload enables compilation from raw formulas, bypassing model fitting when only the computational structure is needed. Useful for custom model implementations or direct formula evaluation workflows.\n\nArguments\n\nformula::StatsModels.FormulaTerm: Formula specification (e.g., from @formula(y ~ x + group))\ndata: Data in Tables.jl format (preferably Tables.columntable(df))\n\nReturns\n\nUnifiedCompiled{T,Ops,S,O}: Zero-allocation evaluator, same interface as model-based compilation\n\nPerformance\n\nCompilation: Fast for complex formulas\nEvaluation: Zero bytes allocated\nMemory: Identical performance to model-based compilation\n\nExample\n\nusing StatsModels, FormulaCompiler, Tables\n\n# Direct formula compilation\nformula = @formula(y ~ x * group + log(z))\ndata = Tables.columntable(df)\ncompiled = compile_formula(formula, data)\n\n# Zero-allocation evaluation\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, data, 1)  # Zero allocations\n\nUse Cases\n\nCustom model implementations requiring direct formula evaluation\nPerformance-critical applications avoiding model fitting overhead\nExploratory analysis with formula variations\nIntegration with external statistical frameworks\n\nSee also: compile_formula(model, data) for model-based compilation\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.get_or_compile_formula","page":"API Reference","title":"FormulaCompiler.get_or_compile_formula","text":"get_or_compile_formula(model, data)\n\nGet cached compiled formula or compile new one with semantic type-aware caching.\n\nCache Key Strategy\n\nCreates cache key based on:\n\nModel object (coefficients, structure)\nColumn names (formula structure)\nSemantic type categories (compilation behavior)\n\nType Category Benefits\n\nBetter cache hits: Vector{Int} and Vector{Float64} share cache entry\nCorrect mixture handling: CategoricalArray vs CategoricalMixture distinguished\nFuture-proof: New types can be added to category system\n\nExamples\n\n# These share a cache entry (both :numeric):\ndata1 = (x = Float64[1.0, 2.0], y = ...)\ndata2 = (x = Int[1, 2], y = ...)  # Cache HIT ✓\n\n# These get separate entries (different compilation):\ndata3 = (edu = categorical([\"HS\"]), ...)      # :categorical\ndata4 = (edu = mix(\"HS\" => 0.5, \"C\" => 0.5), ...)  # :mixture - Cache MISS ✓\n\n\n\n\n\n","category":"function"},{"location":"api/#Model-Row-Evaluation","page":"API Reference","title":"Model Row Evaluation","text":"","category":"section"},{"location":"api/#FormulaCompiler.modelrow","page":"API Reference","title":"FormulaCompiler.modelrow","text":"modelrow(model, data, row_idx) -> Vector{Float64}\n\nEvaluate a single model matrix row, returning a new vector (allocating version).\n\nConvenient interface for when pre-allocation is not practical. Uses internal formula compilation and caching for performance optimization, though the non-allocating modelrow! interface is preferred for performance-critical code.\n\nArguments\n\nmodel: Fitted statistical model (GLM, MixedModel, etc.)\ndata: Data in Tables.jl format \nrow_idx::Int: Row index to evaluate (1-based)\n\nReturns\n\nVector{Float64}: New vector containing model matrix row values\n\nPerformance\n\nFirst call: Includes one-time compilation cost\nSubsequent calls: Fast evaluation plus allocation cost for vector creation\nMemory: Allocates new vector each call\nCaching: Automatically caches compiled formula for reuse\n\nExample\n\nusing FormulaCompiler, GLM\n\nmodel = lm(@formula(y ~ x * group + log(z)), df)\ndata = Tables.columntable(df)\n\n# Convenient single-row evaluation\nrow_1 = modelrow(model, data, 1)      # First call (includes compilation)\nrow_2 = modelrow(model, data, 2)      # Subsequent calls (uses cached compilation)\nrow_100 = modelrow(model, data, 100)  # Fast (uses cached compilation)\n\nWhen to Use\n\nPrototyping: Quick analysis and exploration\nSmall datasets: When allocation overhead is negligible\nConvenience: When code simplicity outweighs performance requirements\n\nPerformance Alternative\n\nFor zero-allocation performance in loops, use modelrow!:\n\noutput = Vector{Float64}(undef, length(compile_formula(model, data)))\nfor i in 1:n_iterations\n    modelrow!(output, compiled, data, i)  # Zero allocations each iteration\nend\n\nSee also: modelrow!, ModelRowEvaluator, compile_formula\n\n\n\n\n\nmodelrow(model, data, row_indices) -> Matrix{Float64}\n\nEvaluate multiple rows and return a new matrix (allocating version). Uses compiled formulas for optimal performance.\n\nExample\n\nmatrix = modelrow(model, data, [1, 5, 10])  # Returns Matrix{Float64}\n\n\n\n\n\nmodelrow(compiled_formula, data, row_idx) -> Vector{Float64}\n\nEvaluate a single row with pre-compiled compiled formula.\n\nExample\n\ncompiled = compile_formula(model, data)\nrow_values = modelrow(compiled, data, 1)  # Returns Vector{Float64}\n\n\n\n\n\nmodelrow(compiled_formula, data, row_indices) -> Matrix{Float64}\n\nEvaluate multiple rows with pre-compiled compiled formula.\n\nExample\n\ncompiled = compile_formula(model, data)\nmatrix = modelrow(compiled, data, [1, 5, 10])  # Returns Matrix{Float64}\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.modelrow!","page":"API Reference","title":"FormulaCompiler.modelrow!","text":"modelrow!(output, compiled, data, row_idx) -> output\n\nEvaluate a single model matrix row in-place with zero allocations.\n\nThe primary interface for high-performance row evaluation. This function provides zero-allocation evaluation, making it suitable for tight computational loops and performance-critical applications.\n\nArguments\n\noutput::AbstractVector{Float64}: Pre-allocated output vector (modified in-place)\nMust have length ≥ length(compiled)\nContents will be overwritten with model matrix row values\ncompiled: Compiled formula from compile_formula(model, data)\ndata: Data in Tables.jl format (preferably Tables.columntable(df) for best performance)\nrow_idx::Int: Row index to evaluate (1-based indexing)\n\nReturns\n\noutput: The same vector passed in, now containing the evaluated model matrix row\n\nPerformance\n\nMemory: Zero bytes allocated after warmup\nScaling: Constant time regardless of dataset size or formula complexity\nValidation: Tested across 2000+ diverse formula configurations\n\nExample\n\nusing FormulaCompiler, GLM, Tables\n\n# Setup (one-time cost)\nmodel = lm(@formula(y ~ x * group + log(z)), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\noutput = Vector{Float64}(undef, length(compiled))\n\n# High-performance evaluation (repeated many times)\nmodelrow!(output, compiled, data, 1)    # Zero allocations\nmodelrow!(output, compiled, data, 100)  # Zero allocations\n\n# Monte Carlo simulation example\nfor i in 1:1_000_000\n    row_idx = rand(1:nrow(df))\n    modelrow!(output, compiled, data, row_idx)  # Zero allocations each call\n    # Process output...\nend\n\nError Handling\n\nBoundsError: If row_idx exceeds data size\nDimensionMismatch: If output vector is too small\nValidates arguments in debug builds\n\nSee also: modelrow for allocating version, compile_formula, ModelRowEvaluator\n\n\n\n\n\nmodelrow!(row_vec, model, data, row_idx; cache=true)\n\nEvaluate a single row of the model matrix in-place with automatic compilation.\n\nArguments\n\nrow_vec::AbstractVector{Float64}: Pre-allocated output vector (modified in-place)\nmodel: Statistical model (GLM, MixedModel, etc.)\ndata: Data in Tables.jl format\nrow_idx::Int: Row index to evaluate\ncache::Bool: Whether to cache compiled formula (default: true)\n\nReturns\n\nrow_vec: The same vector passed in, now containing the evaluated row\n\nExample\n\nmodel = lm(@formula(y ~ x + group), df)\ndata = Tables.columntable(df)\nrow_vec = Vector{Float64}(undef, size(modelmatrix(model), 2))\nmodelrow!(row_vec, model, data, 1)\n\nnote: Note\nFirst call compiles the formula. Subsequent calls reuse cached version when cache=true.\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.ModelRowEvaluator","page":"API Reference","title":"FormulaCompiler.ModelRowEvaluator","text":"ModelRowEvaluator{T,Ops,S,O}\n\nObject-oriented interface for reusable, pre-compiled model evaluation.\n\nCombines compiled formula, data, and output buffer into a single object that can be called repeatedly for both allocating and non-allocating row evaluation. Useful when the same model and data will be evaluated many times.\n\nType Parameters\n\nT: Element type (typically Float64)\nOps: Compiled operations tuple type\nS: Scratch buffer size \nO: Output vector size\n\nFields\n\ncompiled::UnifiedCompiled: Pre-compiled formula\ndata::NamedTuple: Data in column-table format\nrow_vec::Vector{Float64}: Internal buffer for non-allocating calls\n\nConstructors\n\nModelRowEvaluator(model, df::DataFrame)      # Converts DataFrame to column table\nModelRowEvaluator(model, data::NamedTuple)   # Uses data directly\n\nInterface\n\n# Allocating interface - returns new vector\nresult = evaluator(row_idx)\n\n# Non-allocating interface - uses provided vector  \nevaluator(output_vector, row_idx)\n\nPerformance\n\nConstruction: One-time compilation cost\nAllocating calls: Fast evaluation plus allocation cost\nNon-allocating calls: Zero bytes allocated\nMemory: Minimal overhead beyond compiled formula and data reference\n\nExample\n\nusing FormulaCompiler, GLM\n\n# Create evaluator (one-time setup)\nmodel = lm(@formula(y ~ x * group + log(z)), df)\nevaluator = ModelRowEvaluator(model, df)\n\n# Allocating interface (convenient)\nrow_1 = evaluator(1)      # Returns Vector{Float64}\nrow_2 = evaluator(100)    # Returns Vector{Float64}\n\n# Non-allocating interface (fast)\noutput = Vector{Float64}(undef, length(evaluator))\nevaluator(output, 1)      # Zero allocations\nevaluator(output, 100)    # Zero allocations\n\n# Batch processing\nresults = Matrix{Float64}(undef, 1000, length(evaluator))\nfor i in 1:1000\n    evaluator(view(results, i, :), i)  # Zero allocations\nend\n\nWhen to Use\n\nRepeated evaluation: Same model and data used many times\nObject-oriented style: Prefer objects over function calls\nMixed interfaces: Need both allocating and non-allocating evaluation\nClean encapsulation: Bundle model, data, and buffer management\n\nSee also: modelrow!, modelrow, compile_formula\n\n\n\n\n\n","category":"type"},{"location":"api/#Derivatives","page":"API Reference","title":"Derivatives","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"FormulaCompiler provides computational primitives for computing derivatives of model matrix rows with respect to continuous variables. These functions enable zero-allocation Jacobian computation using either automatic differentiation (ForwardDiff) or finite differences.","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"For marginal effects, standard errors, and complete statistical workflows, see Margins.jl.","category":"page"},{"location":"api/#Evaluator-Construction","page":"API Reference","title":"Evaluator Construction","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Recommended: Use the unified dispatcher for user-facing code:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"# Automatic differentiation (preferred)\nde = derivativeevaluator(:ad, compiled, data, [:x, :z])\n\n# Finite differences\nde = derivativeevaluator(:fd, compiled, data, [:x, :z])","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Advanced: Direct constructor functions (primarily for internal use):","category":"page"},{"location":"api/#FormulaCompiler.derivativeevaluator_fd","page":"API Reference","title":"FormulaCompiler.derivativeevaluator_fd","text":"derivativeevaluator_fd(compiled, data, vars) -> FDEvaluator\n\nCreate a finite differences specialized FDEvaluator using Float64 counterfactual vectors.\n\nReturns a concrete FDEvaluator with only FD infrastructure, no field pollution from AD. Uses NumericCounterfactualVector{Float64} for type-stable counterfactual operations.\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.derivativeevaluator_ad","page":"API Reference","title":"FormulaCompiler.derivativeevaluator_ad","text":"derivativeevaluator_ad(compiled, data, vars) -> ADEvaluator\n\nCreate an automatic differentiation specialized ADEvaluator using Dual counterfactual vectors.\n\nReturns a concrete ADEvaluator with only AD infrastructure, no field pollution from FD. Uses NumericCounterfactualVector{Dual{...}} for type-stable dual number operations.\n\n\n\n\n\n","category":"function"},{"location":"api/#Jacobian-Computation","page":"API Reference","title":"Jacobian Computation","text":"","category":"section"},{"location":"api/#FormulaCompiler.derivative_modelrow!","page":"API Reference","title":"FormulaCompiler.derivative_modelrow!","text":"derivative_modelrow!(J, de::ADEvaluator, row) -> J\n\nPrimary automatic differentiation API - zero allocations via ForwardDiff.jacobian!.\n\nUse cached ForwardDiff configuration for zero allocations. Replaces manual dual construction with ForwardDiff's optimized jacobian! routine.\n\nArguments\n\nJ::AbstractMatrix{Float64}: Preallocated Jacobian buffer of size (n_terms, n_vars)\nde::ADEvaluator: AD evaluator built by derivativeevaluator(:ad, compiled, data, vars)\nrow::Int: Row index to evaluate (1-based indexing)\n\nReturns\n\nJ: The same matrix passed in, now containing J[i,j] = ∂X[i]/∂vars[j] for the specified row\n\nPerformance Characteristics\n\nMemory: 0 bytes allocated (cached buffers and ForwardDiff config)\nSpeed: Target ~60ns with ForwardDiff.jacobian! optimization\nAccuracy: Machine precision derivatives via ForwardDiff dual arithmetic\n\nExample\n\nusing FormulaCompiler, GLM\n\n# Setup model\nmodel = lm(@formula(y ~ x + z), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Build AD evaluator\nde = derivativeevaluator(:ad, compiled, data, [:x, :z])\n\n# Zero-allocation Jacobian computation\nJ = Matrix{Float64}(undef, length(compiled), length(de.vars))\nderivative_modelrow!(J, de, 1)  # 0 bytes allocated\n\n\n\n\n\nderivative_modelrow!(J, de::FDEvaluator, row) -> J\n\nPrimary finite differences API - zero allocations, concrete type dispatch.\n\nComputes full Jacobian matrix ∂X[i]/∂vars[j] using central differences with adaptive step sizing. Matches automatic_diff.jl signature for seamless backend switching.\n\nPerformance Characteristics\n\nMemory: 0 bytes allocated (uses pre-allocated FDEvaluator buffers)\nSpeed: ~65ns per variable with mathematical optimizations\nAccuracy: Adaptive step sizing balances truncation/roundoff error\n\nMathematical Method\n\nCentral differences: ∂f/∂x ≈ [f(x+h) - f(x-h)] / (2h) Step sizing: h = ε^(1/3) * max(1, |x|) for numerical stability\n\nArguments\n\nJ::AbstractMatrix{Float64}: Pre-allocated Jacobian buffer of size (n_terms, n_vars)\nde::FDEvaluator: Pre-built evaluator from derivativeevaluator_fd(compiled, data, vars)\nrow::Int: Row index to evaluate (1-based indexing)\n\nReturns\n\nJ: The same matrix passed in, containing J[i,j] = ∂X[i]/∂vars[j]\n\nExample\n\nusing FormulaCompiler, GLM\n\n# Setup model and data\nmodel = lm(@formula(y ~ x * group + log(abs(z) + 1)), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Build FD evaluator\nde_fd = derivativeevaluator_fd(compiled, data, [:x, :z])\n\n# Zero-allocation finite differences\nJ = Matrix{Float64}(undef, length(compiled), length(de_fd.vars))\nderivative_modelrow!(J, de_fd, 1)  # 0 bytes allocated\n\nSee also: derivativeevaluator_fd\n\n\n\n\n\n","category":"function"},{"location":"api/#Variable-Identification","page":"API Reference","title":"Variable Identification","text":"","category":"section"},{"location":"api/#FormulaCompiler.continuous_variables","page":"API Reference","title":"FormulaCompiler.continuous_variables","text":"continuous_variables(compiled, data) -> Vector{Symbol}\n\nIdentify continuous variables suitable for derivative computation from a compiled formula.\n\nAnalyzes compiled operations to distinguish between continuous variables (suitable for differentiation) and categorical variables (requiring discrete analysis). Essential for determining valid variable sets for derivative evaluators and marginal effects computation.\n\nArguments\n\ncompiled::UnifiedCompiled: Compiled formula from compile_formula(model, data)  \ndata::NamedTuple: Data in column-table format (from Tables.columntable(df))\n\nReturns\n\nVector{Symbol}: Sorted list of continuous variable names\nIncludes: Float64, Int64, Int32, Int variables used in LoadOp operations\nExcludes: Variables appearing only in ContrastOp operations (categorical contrasts)\nExcludes: Boolean variables (treated as categorical regardless of numeric type)\n\nClassification Algorithm\n\nOperation analysis: Scan compiled operations for LoadOp vs ContrastOp usage\nType filtering: Verify variables have Real element types in data\nBoolean exclusion: Remove Bool variables (categorical by convention)\nCategorical exclusion: Remove variables only appearing in contrast operations\n\nExample\n\nusing FormulaCompiler, GLM, CategoricalArrays\n\n# Mixed variable types\ndf = DataFrame(\n    y = randn(1000),\n    price = randn(1000),          # Float64 - continuous\n    quantity = rand(1:100, 1000), # Int64 - continuous\n    available = rand(Bool, 1000), # Bool - categorical\n    category = categorical(rand([\"A\", \"B\", \"C\"], 1000))  # Categorical - categorical\n)\n\nmodel = lm(@formula(y ~ price + quantity + available + category), df)\ncompiled = compile_formula(model, Tables.columntable(df))\n\n# Identify continuous variables\ncontinuous_vars = continuous_variables(compiled, Tables.columntable(df))\n# Returns: [:price, :quantity]\n\n# Use for derivative evaluator construction\nde_fd = derivativeevaluator_fd(compiled, Tables.columntable(df), continuous_vars)\nde_ad = derivativeevaluator_ad(compiled, Tables.columntable(df), continuous_vars)\n\nUse Cases\n\nPre-validation: Check variable suitability before building derivative evaluators\nAutomatic selection: Programmatically identify all differentiable variables\nError prevention: Avoid attempting derivatives on categorical variables\nModel introspection: Understand variable roles in compiled formulas\n\nImplementation Details\n\nScans LoadOp operations for direct variable usage (continuous indicators)\nIdentifies ContrastOp operations for categorical variable detection\nApplies type checking to ensure Real element types in the actual data\nReturns sorted list for consistent ordering across calls\n\nSee also: derivativeevaluator_fd, derivativeevaluator_ad, derivative_modelrow!\n\n\n\n\n\n","category":"function"},{"location":"api/#Link-Function-Derivatives","page":"API Reference","title":"Link Function Derivatives","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Computational primitives for GLM link function derivatives (used by Margins.jl for computing marginal effects on the mean response).","category":"page"},{"location":"api/#FormulaCompiler.supported_link_functions","page":"API Reference","title":"FormulaCompiler.supported_link_functions","text":"supported_link_functions() -> Vector{String}\n\nReturn list of GLM link functions with implemented dmudeta methods.\n\nNote: Link function support is now determined by Julia's method dispatch. Any link function with a dmudeta method will work automatically. This function provides a convenience list of commonly tested functions.\n\nExample\n\nlinks = supported_link_functions()\nprintln(\"Common GLM links: \", join(links, \", \"))\n\n\n\n\n\n","category":"function"},{"location":"api/#Categorical-Contrasts","page":"API Reference","title":"Categorical Contrasts","text":"","category":"section"},{"location":"api/#FormulaCompiler.ContrastEvaluator","page":"API Reference","title":"FormulaCompiler.ContrastEvaluator","text":"ContrastEvaluator{T, Ops, S, O, NTMerged, CounterfactualTuple}\n\nZero-allocation evaluator for categorical and binary variable contrasts.\n\nProvides efficient discrete marginal effects computation by pre-allocating all buffers and pre-computing categorical level mappings. Eliminates the ~2KB allocation overhead of the basic contrast_modelrow! function for batch contrast operations.\n\nUses typed counterfactual vectors for type-stable, zero-allocation performance.\n\nFields\n\ncompiled: Base compiled formula evaluator\nvars: Variables available for contrast computation\ndata_counterfactual: Counterfactual data structure for variable substitution\ncounterfactuals: Tuple of typed CounterfactualVector{T} subtypes for each variable\ny_from_buf: Pre-allocated buffer for \"from\" level evaluation\ny_to_buf: Pre-allocated buffer for \"to\" level evaluation\nrow: Current row being processed\n\nPerformance\n\nZero allocations after construction for all contrast operations\nType stability via typed counterfactual vectors\nBuffer reuse across multiple contrasts and rows\nType specialization for compiled formula operations\n\nUsage\n\n# One-time setup\nevaluator = contrastevaluator(compiled, data, [:treatment, :education])\ncontrast_buf = Vector{Float64}(undef, length(compiled))\n\n# Fast repeated contrasts (zero allocations)\nfor row in 1:n_rows\n    contrast_modelrow!(contrast_buf, evaluator, row, :treatment, \"Control\", \"Drug\")\n    # Process contrast_buf...\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#FormulaCompiler.contrastevaluator","page":"API Reference","title":"FormulaCompiler.contrastevaluator","text":"contrastevaluator(compiled, data, vars) -> ContrastEvaluator\n\nConstruct a ContrastEvaluator for efficient categorical and binary contrast computation.\n\nPre-allocates all necessary buffers and pre-computes categorical level mappings to eliminate allocations during contrast evaluation.\n\nArguments\n\ncompiled: Result from compile_formula(model, data)\ndata: Column-table data as NamedTuple\nvars: Vector of variable symbols available for contrasts\n\nReturns\n\nContrastEvaluator configured for zero-allocation contrast computation.\n\nPerformance Notes\n\nOne-time cost: Setup involves building override structures and categorical mappings\nCategorical optimization: Level mappings computed once, reused for all contrasts\nMemory efficiency: Buffers sized exactly for the compiled formula\n\nExample\n\n# Setup for categorical contrasts\nevaluator = contrastevaluator(compiled, data, [:group, :region, :binary_var])\n\n# Zero-allocation usage\ncontrast_buf = Vector{Float64}(undef, length(compiled))\ncontrast_modelrow!(contrast_buf, evaluator, 1, :group, \"Control\", \"Treatment\")\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.CategoricalLevelMap","page":"API Reference","title":"FormulaCompiler.CategoricalLevelMap","text":"CategoricalLevelMap{Var, LevelTuple}\n\nStores pre-computed level mappings for a categorical variable in contrast evaluators.\n\nSimilar to ContrastOp, this struct uses type parameters for compile-time specialization while storing runtime level data as a field.\n\nType Parameters\n\nVar::Symbol: Variable name (e.g., :group, :treatment)\nLevelTuple: Type of the levels tuple (e.g., NTuple{3, Tuple{String, CategoricalValue{UInt32}}})\n\nFields\n\nlevels: Tuple of (level, CategoricalValue) pairs preserving natural level types\n\nExample\n\n# String categorical with 3 levels\nCategoricalLevelMap{:group, NTuple{3, Tuple{String, CategoricalValue{UInt32}}}}(\n    ((\"Control\", catval1), (\"Treatment\", catval2), (\"Placebo\", catval3))\n)\n\n# Integer categorical with 5 levels\nCategoricalLevelMap{:age_group, NTuple{5, Tuple{Int64, CategoricalValue{UInt32}}}}(\n    ((1, catval1), (2, catval2), (3, catval3), (4, catval4), (5, catval5))\n)\n\nPerformance\n\nZero allocations: All types concrete, fully specialized\nNatural types: No String conversion needed for Int/Symbol levels\nFast lookup: Linear search through small tuple (2-10 levels typical)\n\n\n\n\n\n","category":"type"},{"location":"api/#FormulaCompiler.contrast_modelrow!","page":"API Reference","title":"FormulaCompiler.contrast_modelrow!","text":"contrast_modelrow!(Δ, evaluator, row, var, from, to) -> Δ\n\nCompute discrete contrast using pre-allocated ContrastEvaluator (zero allocations).\n\nEvaluates Δ = X(var=to) - X(var=from) using the evaluator's pre-allocated buffers and pre-computed categorical mappings for optimal performance.\n\nArguments\n\nΔ::AbstractVector{Float64}: Output contrast vector (modified in-place)\nevaluator::ContrastEvaluator: Pre-configured contrast evaluator\nrow::Int: Row index to evaluate\nvar::Symbol: Variable to contrast (must be in evaluator.vars)\nfrom: Reference level (baseline)\nto: Target level (comparison)\n\nPerformance\n\nZero allocations - uses pre-allocated buffers from evaluator\nCategorical optimization - uses pre-computed level mappings\nType specialization - compiled formula operations fully optimized\n\nError Handling\n\nValidates that var exists in evaluator's variable list\nHandles both categorical and numeric variable types\nProvides clear error messages for invalid level specifications\n\nExample\n\nevaluator = contrastevaluator(compiled, data, [:treatment])\ncontrast_buf = Vector{Float64}(undef, length(compiled))\n\n# Zero-allocation contrast computation\ncontrast_modelrow!(contrast_buf, evaluator, 1, :treatment, \"Control\", \"Drug\")\n# contrast_buf now contains the discrete effect vector\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.contrast_gradient!","page":"API Reference","title":"FormulaCompiler.contrast_gradient!","text":"contrast_gradient!(∇β, evaluator, row, var, from, to, β, [link]) -> ∇β\n\nCompute parameter gradients for discrete effects: ∂(discrete_effect)/∂β - zero allocations.\n\nComputes the gradient of discrete marginal effects with respect to model parameters using the mathematical formula:\n\nLinear scale (η): ∇β = ΔX = X₁ - X₀ (contrast vector)\nResponse scale (μ): ∇β = g'(η₁) × X₁ - g'(η₀) × X₀ (chain rule with link derivatives)\n\nThis enables uncertainty quantification via the delta method: SE = √(∇β' Σ ∇β).\n\nArguments\n\n∇β::AbstractVector{Float64}: Output gradient vector (modified in-place)\nevaluator::ContrastEvaluator: Pre-configured contrast evaluator\nrow::Int: Row index to evaluate\nvar::Symbol: Variable to contrast (must be in evaluator.vars)\nfrom: Reference level (baseline)\nto: Target level (comparison)\nβ::AbstractVector{<:Real}: Model coefficients (used only for response-scale computation)\nlink: GLM link function (optional, defaults to linear scale)\n\nReturns\n\n∇β: The same vector passed in, containing parameter gradients ∂(discrete_effect)/∂β\n\nPerformance\n\nZero allocations - uses pre-allocated buffers from evaluator\nLink function support - handles all GLM links (Identity, Log, Logit, etc.)\nType flexibility - accepts any Real coefficient type, converts internally\n\nMathematical Method\n\nLinear Scale (default):\n\ndiscrete_effect = η₁ - η₀ = (X₁'β) - (X₀'β) = (X₁ - X₀)'β = ΔX'β\n∇β = ΔX = X₁ - X₀\n\nResponse Scale (with link function):\n\ndiscrete_effect = μ₁ - μ₀ = g⁻¹(η₁) - g⁻¹(η₀)\n∇β = g'(η₁) × X₁ - g'(η₀) × X₀  (chain rule)\n\nExample\n\nevaluator = contrastevaluator(compiled, data, [:treatment])\n∇β = Vector{Float64}(undef, length(compiled))\n\n# Linear scale gradients (η = Xβ scale)\ncontrast_gradient!(∇β, evaluator, 1, :treatment, \"Control\", \"Drug\", β)\n\n# Response scale gradients (μ = g⁻¹(η) scale)\nlink = GLM.LogitLink()\ncontrast_gradient!(∇β, evaluator, 1, :treatment, \"Control\", \"Drug\", β, link)\n\n# Delta method standard error\nse = sqrt(∇β' * vcov_matrix * ∇β)\n\nIntegration with Delta Method\n\nParameter gradients enable uncertainty quantification:\n\n# Compute discrete effect + gradient simultaneously\ndiscrete_effect = contrast_modelrow(evaluator, row, var, from, to)\ncontrast_gradient!(∇β, evaluator, row, var, from, to, β, link)\n\n# Delta method confidence intervals\nvariance = ∇β' * vcov_matrix * ∇β\nse = sqrt(variance)\nci_lower = discrete_effect - 1.96 * se\nci_upper = discrete_effect + 1.96 * se\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.contrast_gradient","page":"API Reference","title":"FormulaCompiler.contrast_gradient","text":"contrast_gradient(evaluator, row, var, from, to, β, [link]) -> Vector{Float64}\n\nConvenience version that allocates and returns the gradient vector.\n\n\n\n\n\n","category":"function"},{"location":"api/#Categorical-Mixtures","page":"API Reference","title":"Categorical Mixtures","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Utilities for constructing and validating categorical mixtures used in efficient profile-based marginal effects.","category":"page"},{"location":"api/#FormulaCompiler.mix","page":"API Reference","title":"FormulaCompiler.mix","text":"mix(pairs...)\n\nConvenient constructor for CategoricalMixture from level => weight pairs. This is the main user-facing function for creating mixture specifications.\n\nArguments\n\npairs...: Level => weight pairs (e.g., \"A\" => 0.3, \"B\" => 0.7)\n\nReturns\n\nCategoricalMixture: Validated mixture object ready for use with FormulaCompiler\n\nExamples\n\n# Basic categorical mixture\ngroup_mix = mix(\"Control\" => 0.4, \"Treatment\" => 0.6)\n\n# Educational composition\neducation_mix = mix(\"high_school\" => 0.4, \"college\" => 0.4, \"graduate\" => 0.2)\n\n# Regional distribution using symbols\nregion_mix = mix(:urban => 0.7, :rural => 0.3)\n\n# Boolean mixture (30% false, 70% true)\ntreated_mix = mix(false => 0.3, true => 0.7)\n\n# Works with any comparable type\nage_group_mix = mix(\"young\" => 0.25, \"middle\" => 0.50, \"old\" => 0.25)\n\nValidation\n\nThe mix() function automatically validates:\n\nAt least one level => weight pair is provided\nAll weights are non-negative\nWeights sum to 1.0 (within numerical tolerance)\nAll levels are unique\n\nIntegration with FormulaCompiler\n\nCounterfactualVector Pattern for Categorical Mixtures\n\nThe unified row-wise architecture provides efficient single-row mixture perturbations:\n\nusing FormulaCompiler, DataFrames, Tables\n\n# Prepare data with mixture column\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    group = fill(mix(\"A\" => 0.4, \"B\" => 0.6), 1000)  # Baseline mixture\n)\ndata = Tables.columntable(df)\n\n# Compile formula\nmodel = lm(@formula(y ~ x * group), df)\ncompiled = compile_formula(model, data)\n\n# Pattern 1: Single-row mixture perturbation\n# Create counterfactual vector for mixture column\ncf_mixture = counterfactualvector(data.group, 1)  # CategoricalMixtureCounterfactualVector\n\n# Apply different mixture to specific row\nnew_mixture = mix(\"A\" => 0.8, \"B\" => 0.2)  # Policy counterfactual\nupdate_counterfactual_row!(cf_mixture, 500)  # Target row 500\nupdate_counterfactual_replacement!(cf_mixture, new_mixture)\n\n# Evaluate with counterfactual data\ndata_cf = (data..., group=cf_mixture)\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, data_cf, 500)  # Row 500 uses new mixture, others use baseline\n\n# Pattern 2: Population marginal effects with mixture profiles\nfunction mixture_marginal_effects(model, data, base_mixture, alt_mixture)\n    compiled = compile_formula(model, data)\n    cf_mixture = counterfactualvector(data.group, 1)\n    data_cf = (data..., group=cf_mixture)\n\n    n_rows = length(data.x)\n    baseline_effects = Vector{Float64}(undef, n_rows)\n    alternative_effects = Vector{Float64}(undef, n_rows)\n\n    for row in 1:n_rows\n        update_counterfactual_row!(cf_mixture, row)\n\n        # Baseline mixture\n        update_counterfactual_replacement!(cf_mixture, base_mixture)\n        compiled(view(baseline_effects, row:row), data_cf, row)\n\n        # Alternative mixture\n        update_counterfactual_replacement!(cf_mixture, alt_mixture)\n        compiled(view(alternative_effects, row:row), data_cf, row)\n    end\n\n    return mean(alternative_effects - baseline_effects)\nend\n\n# Example: Policy effect of changing group composition\nbase_mix = mix(\"A\" => 0.4, \"B\" => 0.6)\npolicy_mix = mix(\"A\" => 0.7, \"B\" => 0.3)\neffect = mixture_marginal_effects(model, data, base_mix, policy_mix)\n\nReference Grid Pattern\n\nFor systematic marginal effects computation across different mixture profiles:\n\n# Create reference grid with multiple mixture specifications\nmixtures = [\n    mix(\"A\" => 1.0, \"B\" => 0.0),    # Pure A\n    mix(\"A\" => 0.5, \"B\" => 0.5),    # Balanced\n    mix(\"A\" => 0.0, \"B\" => 1.0)     # Pure B\n]\n\n# Evaluate effects across all mixture profiles\neffects_by_mixture = Vector{Float64}(undef, length(mixtures))\ncf_mixture = counterfactualvector(data.group, 1)\ndata_cf = (data..., group=cf_mixture)\n\nfor (i, mixture_spec) in enumerate(mixtures)\n    update_counterfactual_replacement!(cf_mixture, mixture_spec)\n\n    # Compute average effect across all rows for this mixture\n    row_effects = Vector{Float64}(undef, n_rows)\n    for row in 1:n_rows\n        update_counterfactual_row!(cf_mixture, row)\n        compiled(view(row_effects, row:row), data_cf, row)\n    end\n    effects_by_mixture[i] = mean(row_effects)\nend\n\nPerformance\n\nMixture creation is lightweight and validation happens at construction time. The resulting CategoricalMixture objects are compiled into zero-allocation evaluators by FormulaCompiler's compilation system.\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.CategoricalMixture","page":"API Reference","title":"FormulaCompiler.CategoricalMixture","text":"CategoricalMixture{T}\n\nRepresents a mixture of categorical levels with associated weights for statistical analysis. Used to specify population composition scenarios and marginal effects computation.\n\nFields\n\nlevels::Vector{T}: Categorical levels (strings, symbols, booleans, or other types)\nweights::Vector{Float64}: Associated weights (must sum to 1.0)\n\nExample\n\n# Educational composition mixture\nedu_mix = CategoricalMixture([\"high_school\", \"college\"], [0.6, 0.4])\n\n# Using the convenient mix() constructor\ntreatment_mix = mix(\"control\" => 0.4, \"treatment\" => 0.6)\nboolean_mix = mix(false => 0.3, true => 0.7)\n\nValidation\n\nLevels and weights must have the same length\nAll weights must be non-negative\nWeights must sum to 1.0 (within tolerance)\nLevels must be unique\n\nIntegration with FormulaCompiler\n\nCategoricalMixture objects are automatically detected by FormulaCompiler's compilation system and compiled into efficient zero-allocation evaluators using MixtureContrastOp.\n\n\n\n\n\n","category":"type"},{"location":"api/#FormulaCompiler.MixtureWithLevels","page":"API Reference","title":"FormulaCompiler.MixtureWithLevels","text":"MixtureWithLevels{T}\n\nWrapper that includes original categorical levels with the mixture for FormulaCompiler processing. This type provides proper type-safe access to mixture components for the compilation system.\n\nFields\n\nmixture::CategoricalMixture{T}: The core mixture specification\noriginal_levels::Vector{String}: Original levels from the data column\n\nUsage\n\nThis type is used internally by FormulaCompiler's scenario system to provide type-safe  mixture processing with access to both mixture specifications and original data structure.\n\n# Usually created automatically by FormulaCompiler's scenario system\nmixture = mix(\"A\" => 0.3, \"B\" => 0.7)\noriginal_levels = [\"A\", \"B\", \"C\"]  # From the actual data column\nwrapper = MixtureWithLevels(mixture, original_levels)\n\n# Direct property access\nwrapper.mixture.levels     # Access to mixture levels\nwrapper.mixture.weights    # Access to mixture weights\nwrapper.original_levels    # Access to original data levels\n\n\n\n\n\n","category":"type"},{"location":"api/#FormulaCompiler.validate_mixture_against_data","page":"API Reference","title":"FormulaCompiler.validate_mixture_against_data","text":"validate_mixture_against_data(mixture::CategoricalMixture, col, var::Symbol)\n\nValidate that all levels in the mixture exist in the actual data column. Throws ArgumentError if any mixture levels are not found in the data.\n\nArguments\n\nmixture::CategoricalMixture: The mixture specification to validate\ncol: The data column to validate against\nvar::Symbol: Variable name for error reporting\n\nThrows\n\nArgumentError: If mixture contains levels not found in the data\n\nExamples\n\n# Validate mixture against categorical data\ndata_col = categorical([\"A\", \"B\", \"C\", \"A\", \"B\"])\nmixture = mix(\"A\" => 0.5, \"B\" => 0.5)\nvalidate_mixture_against_data(mixture, data_col, :group)  # ✓ Valid\n\n# This would throw an error\nbad_mixture = mix(\"A\" => 0.5, \"X\" => 0.5)  # \"X\" not in data\nvalidate_mixture_against_data(bad_mixture, data_col, :group)  # ✗ Error\n\nThis function is used internally by FormulaCompiler's scenario system to ensure mixture specifications are compatible with the actual data.\n\n\n\n\n\n","category":"function"},{"location":"api/#FormulaCompiler.mixture_to_scenario_value","page":"API Reference","title":"FormulaCompiler.mixture_to_scenario_value","text":"mixture_to_scenario_value(mixture::CategoricalMixture, original_col)\n\nConvert a categorical mixture to a representative value for FormulaCompiler scenario creation. Uses weighted average encoding to provide a smooth, continuous representation.\n\nStrategy\n\nCategoricalArray: Weighted average of level indices\nBool: Probability of true (equivalent to current fractional Bool support)  \nOther: Weighted average of sorted unique level indices\n\nArguments\n\nmixture::CategoricalMixture: The mixture to convert\noriginal_col: The original data column for context\n\nReturns\n\nFloat64: Continuous representation of the mixture\n\nExamples\n\n# Boolean mixture -> probability of true\nbool_mix = mix(false => 0.3, true => 0.7)\nmixture_to_scenario_value(bool_mix, [true, false, true]) # -> 0.7\n\n# Categorical mixture -> weighted average of level indices\ncat_mix = mix(\"A\" => 0.6, \"B\" => 0.4)  \ncat_col = categorical([\"A\", \"B\", \"C\"])\nmixture_to_scenario_value(cat_mix, cat_col) # -> 1.4 (0.6*1 + 0.4*2)\n\nThis function is used internally by FormulaCompiler's scenario system to convert mixture specifications into values that can be used with the existing override system.\n\n\n\n\n\n","category":"function"},{"location":"api/#Utilities","page":"API Reference","title":"Utilities","text":"","category":"section"},{"location":"api/#FormulaCompiler.not","page":"API Reference","title":"FormulaCompiler.not","text":"not(x)\n\nLogical NOT operation for use in formula specifications.\n\nArguments\n\nx::Bool: Returns the logical negation (!x)\nx::Real: Returns 1 - x (useful for probability complements)\n\nReturns\n\nFor Bool: The opposite boolean value\nFor Real: The complement (1 - x)\n\nExample\n\n# In a formula\nmodel = lm(@formula(y ~ not(treatment)), df)\n\n# For probabilities\np = 0.3\nq = not(p)  # 0.7\n\nwarning: Warning\nFor Real values, this assumes x is in [0,1] range. No bounds checking is performed.\n\n\n\n\n\n","category":"function"},{"location":"guide/basic_usage/#Basic-Usage","page":"Basic Usage","title":"Basic Usage","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"This page covers the core functionality of FormulaCompiler.jl with practical examples.","category":"page"},{"location":"guide/basic_usage/#Core-Interfaces","page":"Basic Usage","title":"Core Interfaces","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"FormulaCompiler.jl provides three main interfaces for different use cases:","category":"page"},{"location":"guide/basic_usage/#1.-Zero-Allocation-Interface-(Fastest)","page":"Basic Usage","title":"1. Zero-Allocation Interface (Fastest)","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"This is the primary interface for performance-critical applications:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using FormulaCompiler, GLM, DataFrames, Tables\n\n# Setup\ndf = DataFrame(x = randn(1000), y = randn(1000), group = rand([\"A\", \"B\"], 1000))\nmodel = lm(@formula(y ~ x * group), df)\ndata = Tables.columntable(df)\n\n# Compile once\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Use many times (zero allocations)\ncompiled(row_vec, data, 1)    # Zero allocations\ncompiled(row_vec, data, 100)  # Zero allocations","category":"page"},{"location":"guide/basic_usage/#2.-Convenient-Interface-(Allocating)","page":"Basic Usage","title":"2. Convenient Interface (Allocating)","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"For quick prototyping or when allocation isn't critical:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Single row (returns new vector)\nrow_1 = modelrow(model, data, 1)\n\n# Multiple rows (returns matrix)\nrows_subset = modelrow(model, data, [1, 10, 50, 100])\n\n# Range of rows\nrows_range = modelrow(model, data, 1:10)","category":"page"},{"location":"guide/basic_usage/#3.-Object-Based-Interface","page":"Basic Usage","title":"3. Object-Based Interface","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Create a reusable evaluator object:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"evaluator = ModelRowEvaluator(model, df)\n\n# Allocating version\nresult = evaluator(1)\n\n# Zero-allocation version\nrow_vec = Vector{Float64}(undef, length(evaluator))\nevaluator(row_vec, 1)","category":"page"},{"location":"guide/basic_usage/#Understanding-the-Compiled-Object","page":"Basic Usage","title":"Understanding the Compiled Object","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Compiled formulas contain important information:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"compiled = compile_formula(model, data)\n\n# Number of terms in the model matrix (columns)\nlength(compiled)  # e.g., 4 for intercept + x + group_B + x:group_B\n\n# You can call it like a function\nrow_vec = Vector{Float64}(undef, length(compiled))\ncompiled(row_vec, data, row_index)","category":"page"},{"location":"guide/basic_usage/#Batch-Operations","page":"Basic Usage","title":"Batch Operations","text":"","category":"section"},{"location":"guide/basic_usage/#Multiple-Row-Evaluation","page":"Basic Usage","title":"Multiple Row Evaluation","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Pre-allocate matrix for multiple rows\nn_rows = 100\nmatrix = Matrix{Float64}(undef, n_rows, length(compiled))\n\n# Evaluate multiple rows efficiently\nfor i in 1:n_rows\n    compiled(view(matrix, i, :), data, i)\nend\n\n# Or specific rows\nspecific_rows = [1, 5, 10, 50, 100]\nmatrix_subset = Matrix{Float64}(undef, length(specific_rows), length(compiled))\nfor (idx, row) in enumerate(specific_rows)\n    compiled(view(matrix_subset, idx, :), data, row)\nend","category":"page"},{"location":"guide/basic_usage/#Working-with-Views","page":"Basic Usage","title":"Working with Views","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"For memory efficiency, you can work with matrix views:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"big_matrix = Matrix{Float64}(undef, 1000, length(compiled))\n\n# Fill specific rows using views\nfor i in 1:10\n    row_view = view(big_matrix, i, :)\n    compiled(row_view, data, i)\nend","category":"page"},{"location":"guide/basic_usage/#Data-Format-Considerations","page":"Basic Usage","title":"Data Format Considerations","text":"","category":"section"},{"location":"guide/basic_usage/#Column-Tables-(Recommended)","page":"Basic Usage","title":"Column Tables (Recommended)","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"For best performance, convert DataFrames to column tables:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Convert once, reuse many times\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)","category":"page"},{"location":"guide/basic_usage/#Using-DataFrames-(via-Tables.columntable)","page":"Basic Usage","title":"Using DataFrames (via Tables.columntable)","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Convert DataFrames to column tables once, then reuse the result:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"data = Tables.columntable(df)      # Convert once\ncompiled = compile_formula(model, data)\ncompiled(row_vec, data, 1)        # Zero allocations after warmup","category":"page"},{"location":"guide/basic_usage/#Supported-Formula-Features","page":"Basic Usage","title":"Supported Formula Features","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"FormulaCompiler.jl handles all standard StatsModels.jl formula syntax:","category":"page"},{"location":"guide/basic_usage/#Basic-Terms","page":"Basic Usage","title":"Basic Terms","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Continuous variables\n@formula(y ~ x + z)\n\n# Transformations\n@formula(y ~ log(x) + sqrt(z) + x^2)\n\n# Boolean conditions\n@formula(y ~ (x > 0) + (z < mean(z)))","category":"page"},{"location":"guide/basic_usage/#Boolean-Variables","page":"Basic Usage","title":"Boolean Variables","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Boolean variables (Vector{Bool}) are treated as continuous variables, matching StatsModels behavior exactly:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Boolean data - treated as continuous\ndf = DataFrame(\n    outcome = randn(100),\n    x = randn(100),\n    treated = rand(Bool, 100)  # true/false values\n)\n\nmodel = lm(@formula(outcome ~ x + treated), df)\ncompiled = compile_formula(model, Tables.columntable(df))\n\n# Numerical encoding: false → 0.0, true → 1.0\n# This matches StatsModels exactly","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"For counterfactual analysis, use data modification with merge():","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Get dataset size\nn_rows = length(data.treated)\n\n# Boolean scenarios - individual counterfactuals\ndata_treated = merge(data, (treated = fill(true, n_rows),))   # All treated\ncompiled(output, data_treated, 1)  # Evaluate treated scenario\n\ndata_control = merge(data, (treated = fill(false, n_rows),))  # All control\ncompiled(output, data_control, 1)  # Evaluate control scenario\n\n# Numeric scenarios - population analysis (70% treated probability)\ndata_partial = merge(data, (treated = fill(0.7, n_rows),))\ncompiled(output, data_partial, 1)  # Evaluate partial treatment scenario","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Key Points:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Vector{Bool} columns work automatically - no conversion needed\nProduces identical results to StatsModels\nSupports both boolean (true/false) and numeric (0.7) overrides\nZero-allocation performance maintained","category":"page"},{"location":"guide/basic_usage/#Categorical-Variables","page":"Basic Usage","title":"Categorical Variables","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Required: FormulaCompiler only supports categorical variables created with CategoricalArrays.jl. Raw string variables are not supported.","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using CategoricalArrays\n\n# Required: Convert string columns to categorical\ndf.group = categorical(df.group)\n@formula(y ~ x + group)  # Automatic contrast coding\n\n# Not supported: Raw string variables\ndf.category = [\"A\", \"B\", \"C\"]  # String vector\n@formula(y ~ x + category)     # Will cause compilation errors\n\n# Correct approach\ndf.category = categorical([\"A\", \"B\", \"C\"])\n@formula(y ~ x + category)     # Works correctly","category":"page"},{"location":"guide/basic_usage/#Interactions","page":"Basic Usage","title":"Interactions","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Two-way interactions\n@formula(y ~ x * group)  # Expands to: x + group + x:group\n\n# Three-way interactions\n@formula(y ~ x * y * z)\n\n# Function interactions\n@formula(y ~ log(x) * group)","category":"page"},{"location":"guide/basic_usage/#Complex-Formulas","page":"Basic Usage","title":"Complex Formulas","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"@formula(y ~ x * group + log(z) * treatment + sqrt(abs(w)) + (x > mean(x)))","category":"page"},{"location":"guide/basic_usage/#Error-Handling","page":"Basic Usage","title":"Error Handling","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"FormulaCompiler.jl provides clear error messages:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Invalid row index\ntry\n    compiled(row_vec, data, 1001)  # Only 1000 rows\ncatch BoundsError\n    println(\"Row index out of bounds\")\nend\n\n# Mismatched output vector size\ntry\n    wrong_size = Vector{Float64}(undef, 3)  # Should be length(compiled)\n    compiled(wrong_size, data, 1)\ncatch DimensionMismatch\n    println(\"Output vector has wrong size\")\nend","category":"page"},{"location":"guide/basic_usage/#Memory-Management","page":"Basic Usage","title":"Memory Management","text":"","category":"section"},{"location":"guide/basic_usage/#Pre-allocation-Best-Practices","page":"Basic Usage","title":"Pre-allocation Best Practices","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# Good: Pre-allocate and reuse\nrow_vec = Vector{Float64}(undef, length(compiled))\nfor i in 1:1000\n    compiled(row_vec, data, i)\n    # Process row_vec...\nend\n\n# Bad: Allocate each time\nfor i in 1:1000\n    row_vec = modelrow(model, data, i)  # Allocates!\n    # Process row_vec...\nend","category":"page"},{"location":"guide/basic_usage/#Large-Dataset-Considerations","page":"Basic Usage","title":"Large Dataset Considerations","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"# For very large datasets, process in chunks\nchunk_size = 1000\nn_chunks = div(nrow(df), chunk_size)\n\nresults = Matrix{Float64}(undef, nrow(df), length(compiled))\n\nfor chunk in 1:n_chunks\n    start_idx = (chunk - 1) * chunk_size + 1\n    end_idx = min(chunk * chunk_size, nrow(df))\n\n    # Evaluate each row in the chunk\n    for i in start_idx:end_idx\n        compiled(view(results, i, :), data, i)\n    end\nend","category":"page"},{"location":"guide/basic_usage/#Validation-and-Debugging","page":"Basic Usage","title":"Validation and Debugging","text":"","category":"section"},{"location":"guide/basic_usage/#Compilation-Validation","page":"Basic Usage","title":"Compilation Validation","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Verify that compilation produces expected results:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using FormulaCompiler, GLM, Tables\n\n# Setup test case\ndf = DataFrame(\n    y = randn(100),\n    x = randn(100), \n    group = rand([\"A\", \"B\", \"C\"], 100)\n)\nmodel = lm(@formula(y ~ x * group), df)\ndata = Tables.columntable(df)\n\n# Compile and validate\ncompiled = compile_formula(model, data)\n\n# Check dimensions\n@assert length(compiled) == size(modelmatrix(model), 2) \"Column count mismatch\"\n\n# Validate against GLM's modelmatrix for first few rows\nmm = modelmatrix(model)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\nfor i in 1:min(5, nrow(df))\n    compiled(row_vec, data, i)\n    expected = mm[i, :]\n    \n    if !isapprox(row_vec, expected; rtol=1e-12)\n        @warn \"Mismatch in row $i\" row_vec expected\n    else\n        println(\"Row $i matches GLM modelmatrix\")\n    end\nend","category":"page"},{"location":"guide/basic_usage/#Performance-Validation","page":"Basic Usage","title":"Performance Validation","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Verify zero-allocation performance:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using BenchmarkTools\n\n# Test zero allocations\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Benchmark evaluation\nresult = @benchmark $compiled($row_vec, $data, 1)\n\n# Validate performance characteristics (absolute times vary by hardware and Julia version)\n@assert result.memory == 0 \"Expected zero allocations, got $(result.memory) bytes\"\n@assert result.allocs == 0 \"Expected zero allocations, got $(result.allocs) allocations\"\n\nprintln(\"Zero-allocation validation passed\")\nprintln(\"Memory: $(result.memory) bytes\")\nprintln(\"Allocations: $(result.allocs)\")","category":"page"},{"location":"guide/basic_usage/#Data-Integrity-Validation","page":"Basic Usage","title":"Data Integrity Validation","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Ensure data format compatibility:","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function validate_data_compatibility(model, data)\n    try\n        compiled = compile_formula(model, data)\n        row_vec = Vector{Float64}(undef, length(compiled))\n        compiled(row_vec, data, 1)\n        println(\"Data format compatible\")\n        return true\n    catch e\n        @error \"Data format incompatible\" exception=e\n        return false\n    end\nend\n\n# Test your data\nis_compatible = validate_data_compatibility(model, data)","category":"page"},{"location":"guide/basic_usage/#Common-Workflow-Patterns","page":"Basic Usage","title":"Common Workflow Patterns","text":"","category":"section"},{"location":"guide/basic_usage/#Pattern-1:-Monte-Carlo-Simulation","page":"Basic Usage","title":"Pattern 1: Monte Carlo Simulation","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function monte_carlo_analysis(model, base_data, n_simulations=10000)\n    compiled = compile_formula(model, base_data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    results = Vector{Float64}(undef, n_simulations)\n    \n    for i in 1:n_simulations\n        # Random row selection\n        random_row = rand(1:length(first(base_data)))\n        compiled(row_vec, base_data, random_row)\n        \n        # Compute prediction (example: linear predictor)\n        prediction = dot(coef(model), row_vec)\n        results[i] = prediction\n    end\n    \n    return results\nend\n\n# Usage\nmc_results = monte_carlo_analysis(model, data, 10000)\nprintln(\"Mean prediction: $(mean(mc_results))\")\nprintln(\"Std prediction: $(std(mc_results))\")","category":"page"},{"location":"guide/basic_usage/#Pattern-2:-Cross-Validation-Support","page":"Basic Usage","title":"Pattern 2: Cross-Validation Support","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function evaluate_fold(model, train_data, test_data, test_indices)\n    # Compile using training data structure\n    compiled = compile_formula(model, train_data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Evaluate on test data\n    predictions = Vector{Float64}(undef, length(test_indices))\n    \n    for (i, test_row) in enumerate(test_indices)\n        compiled(row_vec, test_data, test_row)\n        predictions[i] = dot(coef(model), row_vec)\n    end\n    \n    return predictions\nend\n\n# Example usage in cross-validation\ntrain_data = Tables.columntable(df_train)\ntest_data = Tables.columntable(df_test)\nfold_predictions = evaluate_fold(model, train_data, test_data, 1:nrow(df_test))","category":"page"},{"location":"guide/basic_usage/#Pattern-3:-Streaming-Data-Processing","page":"Basic Usage","title":"Pattern 3: Streaming Data Processing","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function process_streaming_data(model, data_stream)\n    # Compile once with example data\n    example_data = first(data_stream)\n    compiled = compile_formula(model, example_data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    processed_results = Float64[]\n    \n    for data_batch in data_stream\n        n_rows = length(first(data_batch))\n        for row in 1:n_rows\n            compiled(row_vec, data_batch, row)\n            # Process each row with zero allocations\n            result = dot(coef(model), row_vec)\n            push!(processed_results, result)\n        end\n    end\n    \n    return processed_results\nend","category":"page"},{"location":"guide/basic_usage/#Pattern-4:-Performance-Critical-Loops","page":"Basic Usage","title":"Pattern 4: Performance-Critical Loops","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function high_frequency_evaluation(model, data, row_indices)\n    # Pre-compile and pre-allocate everything\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    results = Vector{Float64}(undef, length(row_indices))\n    \n    # Inner loop with zero allocations\n    @inbounds for (i, row_idx) in enumerate(row_indices)\n        compiled(row_vec, data, row_idx)\n        # Custom computation with pre-allocated vectors\n        results[i] = sum(row_vec)  # Example: sum of predictors\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/basic_usage/#Integration-with-Statistical-Ecosystem","page":"Basic Usage","title":"Integration with Statistical Ecosystem","text":"","category":"section"},{"location":"guide/basic_usage/#GLM.jl-Integration","page":"Basic Usage","title":"GLM.jl Integration","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using GLM, Distributions\n\n# Linear regression\nlinear_model = lm(@formula(y ~ x + group), df)\ncompiled_linear = compile_formula(linear_model, data)\n\n# Logistic regression\ndf_binary = DataFrame(\n    success = rand(Bool, 1000),  # Boolean response: true/false → 1.0/0.0\n    x = randn(1000),\n    group = rand([\"A\", \"B\"], 1000)\n)\nlogit_model = glm(@formula(success ~ x + group), df_binary, Binomial(), LogitLink())\ncompiled_logit = compile_formula(logit_model, Tables.columntable(df_binary))\n\n# Poisson regression\ndf_count = DataFrame(\n    count = rand(Poisson(2), 1000),\n    x = randn(1000),\n    exposure = rand(0.5:0.1:2.0, 1000)\n)\npoisson_model = glm(@formula(count ~ x + log(exposure)), df_count, Poisson(), LogLink())\ncompiled_poisson = compile_formula(poisson_model, Tables.columntable(df_count))","category":"page"},{"location":"guide/basic_usage/#MixedModels.jl-Integration","page":"Basic Usage","title":"MixedModels.jl Integration","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using MixedModels\n\n# Mixed effects model (extracts fixed effects only)\ndf_mixed = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    treatment = rand(Bool, 1000),  # Boolean predictor: treated/untreated\n    subject = rand(1:100, 1000),\n    cluster = rand(1:50, 1000)\n)\n\nmixed_model = fit(MixedModel, @formula(y ~ x + treatment + (1|subject) + (1|cluster)), df_mixed)\ncompiled_mixed = compile_formula(mixed_model, Tables.columntable(df_mixed))\n\n# Note: Only fixed effects (x + treatment) are compiled\n# Random effects are not included in the compiled evaluator","category":"page"},{"location":"guide/basic_usage/#Custom-Contrasts","page":"Basic Usage","title":"Custom Contrasts","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using StatsModels\n\n# Define custom contrast coding\ncontrasts_dict = Dict(\n    :group => EffectsCoding(),           # Effects coding for group\n    :treatment => DummyCoding(base=false) # Dummy coding with true as reference\n)\n\nmodel_contrasts = lm(@formula(y ~ x + group + treatment), df, contrasts=contrasts_dict)\ncompiled_contrasts = compile_formula(model_contrasts, data)","category":"page"},{"location":"guide/basic_usage/#Debugging-and-Troubleshooting","page":"Basic Usage","title":"Debugging and Troubleshooting","text":"","category":"section"},{"location":"guide/basic_usage/#Common-Validation-Checks","page":"Basic Usage","title":"Common Validation Checks","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function comprehensive_validation(model, data)\n    println(\"=== FormulaCompiler Validation ===\")\n    \n    # 1. Compilation check\n    try\n        compiled = compile_formula(model, data)\n        println(\"Compilation successful\")\n        println(\"  Formula length: $(length(compiled))\")\n    catch e\n        println(\"Compilation failed: $e\")\n        return false\n    end\n    \n    # 2. Zero allocation check\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    alloc_result = @allocated compiled(row_vec, data, 1)\n    if alloc_result == 0\n        println(\"Zero allocations achieved\")\n    else\n        println(\"WARNING: Non-zero allocations: $alloc_result bytes\")\n    end\n    \n    # 3. Correctness check (first 3 rows)\n    if applicable(modelmatrix, model)\n        mm = modelmatrix(model)\n        max_check = min(3, size(mm, 1))\n        \n        for i in 1:max_check\n            compiled(row_vec, data, i)\n            expected = mm[i, :]\n            \n            if isapprox(row_vec, expected; rtol=1e-12)\n                println(\"Row $i matches reference implementation\")\n            else\n                println(\"Row $i mismatch detected\")\n                println(\"  Expected: $(expected[1:min(3, length(expected))])...\")\n                println(\"  Got:      $(row_vec[1:min(3, length(row_vec))])...\")\n                return false\n            end\n        end\n    end\n    \n    println(\"All validation checks passed\")\n    return true\nend\n\n# Run comprehensive validation\nvalidation_result = comprehensive_validation(model, data)","category":"page"},{"location":"guide/basic_usage/#Performance-Diagnostics","page":"Basic Usage","title":"Performance Diagnostics","text":"","category":"section"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"function diagnose_performance(model, data)\n    println(\"=== Performance Diagnostics ===\")\n    \n    # Compilation timing\n    compilation_time = @elapsed compile_formula(model, data)\n    println(\"Compilation time: $(round(compilation_time * 1000, digits=1))ms\")\n    \n    # Setup for evaluation timing\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Warmup (important for accurate timing)\n    for _ in 1:100\n        compiled(row_vec, data, 1)\n    end\n    \n    # Memory allocation check\n    alloc_check = @allocated compiled(row_vec, data, 1)\n    println(\"Memory allocations: $alloc_check bytes\")\n    \n    # Performance benchmark\n    bench_result = @benchmark $compiled($row_vec, $data, 1)\n    println(\"Evaluation performance:\")\n    println(\"  Memory: $(bench_result.memory) bytes\")  \n    println(\"  Allocations: $(bench_result.allocs)\")\n    \n    # Cache effectiveness test\n    println(\"\\nCache effectiveness:\")\n    cache_time_1 = @elapsed modelrow!(row_vec, model, data, 1; cache=true)\n    cache_time_2 = @elapsed modelrow!(row_vec, model, data, 2; cache=true)  \n    println(\"  First call (with compilation): $(round(cache_time_1 * 1000, digits=2))ms\")\n    println(\"  Second call (cached): $(round(cache_time_2 * 1000000, digits=1))μs\")\n    \n    return bench_result\nend\n\n# Run diagnostics\nperformance_result = diagnose_performance(model, data)","category":"page"},{"location":"guide/basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"For advanced performance optimization techniques, see the Performance Guide.","category":"page"},{"location":"guide/categorical_mixtures/#Categorical-Mixtures-in-FormulaCompiler.jl","page":"Categorical Mixtures","title":"Categorical Mixtures in FormulaCompiler.jl","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Overview","page":"Categorical Mixtures","title":"Overview","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"FormulaCompiler.jl supports categorical mixtures - weighted combinations of categorical levels for profile-based marginal effects computation. Fractional values like mix(\"A\" => 0.3, \"B\" => 0.7) are compiled into zero-allocation evaluators using type-specialized contrast operations. For boolean variables, use simple numeric probabilities (e.g., treated = 0.7 for 70% treatment rate).","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Implementation characteristics:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Allocation behavior: 0 bytes allocated during execution (verified in test suite)\nCompile-time specialization: Mixture weights embedded in type parameters\nStatistical integration: Compatible with marginal effects packages (Margins.jl)\nMemory complexity: O(1) memory usage independent of data size","category":"page"},{"location":"guide/categorical_mixtures/#Quick-Start","page":"Categorical Mixtures","title":"Quick Start","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"using FormulaCompiler, GLM, DataFrames, Tables\n\n# Create data with categorical mixtures\ndf = DataFrame(\n    x = [1.0, 2.0, 3.0],\n    group = [mix(\"A\" => 0.3, \"B\" => 0.7),   # 30% A, 70% B\n             mix(\"A\" => 0.3, \"B\" => 0.7),\n             mix(\"A\" => 0.3, \"B\" => 0.7)]\n)\n\n# Fit and compile model\nmodel = lm(@formula(y ~ x * group), training_data)\ncompiled = compile_formula(model, Tables.columntable(df))\n\n# Zero-allocation evaluation\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, Tables.columntable(df), 1)  # Zero allocations; time varies by hardware","category":"page"},{"location":"guide/categorical_mixtures/#Mixture-Object-Interface","page":"Categorical Mixtures","title":"Mixture Object Interface","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Categorical mixtures are detected via duck typing - any object with levels and weights properties:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Example mixture object structure\nstruct MixtureExample\n    levels::Vector{String}    # [\"A\", \"B\", \"C\"]\n    weights::Vector{Float64}  # [0.2, 0.3, 0.5]\nend\n\n# FormulaCompiler will automatically detect and handle such objects\nmixture = MixtureExample([\"Control\", \"Treatment\"], [0.4, 0.6])","category":"page"},{"location":"guide/categorical_mixtures/#Creating-Mixture-Data","page":"Categorical Mixtures","title":"Creating Mixture Data","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Boolean-Variables-and-Population-Analysis","page":"Categorical Mixtures","title":"Boolean Variables and Population Analysis","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Boolean variables work seamlessly with FormulaCompiler's continuous interpretation. For population-level analysis and marginal effects, simply use numeric probabilities directly:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Population analysis with boolean probabilities - much simpler!\ndf = DataFrame(\n    x = [1.0, 2.0, 3.0],\n    treated = fill(0.7, 3)  # 70% treatment probability for population analysis\n)\n\n# Fits naturally with FormulaCompiler's boolean handling\ncompiled = compile_formula(model, Tables.columntable(df))\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, Tables.columntable(df), 1)  # treated effect = 0.7","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Numeric approach properties:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Implementation: Uses standard Float64 values without mixture object construction\nSyntax: treated = 0.7 represents probability directly\nPerformance: Maintains zero-allocation execution\nCompatibility: Works with data modification and counterfactual functions\nConsistency: Matches StatsModels.jl boolean variable semantics","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Application patterns:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Individual scenarios: treated = true or treated = false\nPopulation analysis: treated = 0.6 (60% treatment rate)\nMarginal effects: Varying treatment probabilities across reference grids","category":"page"},{"location":"guide/categorical_mixtures/#Helper-Functions","page":"Categorical Mixtures","title":"Helper Functions","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"FormulaCompiler provides several utilities for creating mixture data:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Create mixture column for reference grids\nmixture_spec = mix(\"A\" => 0.3, \"B\" => 0.7)  # Your mixture constructor\ncolumn = FormulaCompiler.create_mixture_column(mixture_spec, 1000)  # 1000 identical rows\n\n# Create balanced (equal weight) mixtures\nbalanced_dict = create_balanced_mixture([\"A\", \"B\", \"C\"])\n# Returns: Dict(\"A\" => 0.333..., \"B\" => 0.333..., \"C\" => 0.333...)\nbalanced_mixture = mix(balanced_dict...)\n\n# Expand base data with mixture specifications\nbase_data = (x = [1.0, 2.0], y = [0.1, 0.2])\nmixtures = Dict(:group => mix(\"A\" => 0.5, \"B\" => 0.5))\nexpanded = FormulaCompiler.expand_mixture_grid(base_data, mixtures)","category":"page"},{"location":"guide/categorical_mixtures/#Reference-Grid-Creation","page":"Categorical Mixtures","title":"Reference Grid Creation","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"For marginal effects analysis, create reference grids with mixtures:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Method 1: Direct DataFrame creation\nreference_grid = DataFrame(\n    x = [1.0, 2.0, 3.0],\n    continuous_var = [0.0, 0.5, 1.0],\n    categorical_mix = fill(mix(\"A\" => 0.5, \"B\" => 0.5), 3)\n)\n\n# Method 2: Using helper functions  \nbase_grid = DataFrame(x = [1.0, 2.0, 3.0])\nmixture_grid = FormulaCompiler.expand_mixture_grid(\n    Tables.columntable(base_grid), \n    Dict(:treatment => mix(\"Control\" => 0.3, \"Treated\" => 0.7))\n)","category":"page"},{"location":"guide/categorical_mixtures/#Validation-and-Error-Handling","page":"Categorical Mixtures","title":"Validation and Error Handling","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Automatic-Validation","page":"Categorical Mixtures","title":"Automatic Validation","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"FormulaCompiler automatically validates mixture data during compilation:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# ✓ Valid - consistent mixtures\nvalid_data = (x = [1, 2], group = [mix(\"A\"=>0.3, \"B\"=>0.7), mix(\"A\"=>0.3, \"B\"=>0.7)])\n\n# ✗ Invalid - inconsistent mixtures\ninvalid_data = (x = [1, 2], group = [mix(\"A\"=>0.3, \"B\"=>0.7), mix(\"A\"=>0.5, \"B\"=>0.5)])\ncompile_formula(model, invalid_data)  # Throws ArgumentError\n\n# ✗ Invalid - weights don't sum to 1.0  \nbad_weights = (x = [1, 2], group = [mix(\"A\"=>0.3, \"B\"=>0.6), mix(\"A\"=>0.3, \"B\"=>0.6)])\ncompile_formula(model, bad_weights)  # Throws ArgumentError","category":"page"},{"location":"guide/categorical_mixtures/#Manual-Validation","page":"Categorical Mixtures","title":"Manual Validation","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"You can also validate mixture data manually:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Validate entire dataset\nFormulaCompiler.validate_mixture_consistency!(data)\n\n# Validate individual components\nFormulaCompiler.validate_mixture_weights([0.3, 0.7])        # ✓ Valid\nFormulaCompiler.validate_mixture_weights([0.3, 0.6])        # ✗ Sum ≠ 1.0\nFormulaCompiler.validate_mixture_levels([\"A\", \"B\", \"C\"])    # ✓ Valid  \nFormulaCompiler.validate_mixture_levels([\"A\", \"A\", \"B\"])    # ✗ Duplicates","category":"page"},{"location":"guide/categorical_mixtures/#Performance-Characteristics","page":"Categorical Mixtures","title":"Performance Characteristics","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Compilation-Time","page":"Categorical Mixtures","title":"Compilation Time","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Mixture detection: ~1μs per column\nType specialization: ~10μs per unique mixture specification\nOverall overhead: <20% increase for mixture-containing formulas","category":"page"},{"location":"guide/categorical_mixtures/#Execution-Performance","page":"Categorical Mixtures","title":"Execution Performance","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Simple mixtures: tens of nanoseconds per row (similar to standard categorical)\nComplex mixtures: still on the order of tens to low hundreds of nanoseconds per row\nMemory usage: 0 bytes allocated during execution\nScaling: Performance independent of mixture complexity","category":"page"},{"location":"guide/categorical_mixtures/#Benchmarks","page":"Categorical Mixtures","title":"Benchmarks","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Performance comparison (indicative)\n@benchmark compiled(output, data, 1)\n@benchmark compiled(output, mix_data, 1)\n# Overhead should remain modest; measure on your system.","category":"page"},{"location":"guide/categorical_mixtures/#Integration-with-Marginal-Effects","page":"Categorical Mixtures","title":"Integration with Marginal Effects","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Basic-Marginal-Effects-Workflow","page":"Categorical Mixtures","title":"Basic Marginal Effects Workflow","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"using FormulaCompiler, GLM\n\n# Create reference grid with mixture\nreference_data = DataFrame(\n    x = [0.0, 1.0, 2.0],  # Values to evaluate at\n    group = fill(mix(\"Control\" => 0.5, \"Treatment\" => 0.5), 3)  # Population mixture\n)\n\n# Compile model\nmodel = lm(@formula(y ~ x * group), training_data)\ncompiled = compile_formula(model, Tables.columntable(reference_data))\n\n# Evaluate marginal effects at each reference point\nn_points = nrow(reference_data)\nresults = Matrix{Float64}(undef, n_points, length(compiled))\n\nfor i in 1:n_points\n    compiled(view(results, i, :), Tables.columntable(reference_data), i)\nend","category":"page"},{"location":"guide/categorical_mixtures/#Integration-with-Derivatives-System","page":"Categorical Mixtures","title":"Integration with Derivatives System","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Mixtures work seamlessly with derivative computation:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"using Margins  # Provides marginal_effects_eta!\n\n# Build derivative evaluator with mixture data\nvars = [:x]  # Continuous variables for derivatives\nde_fd = derivativeevaluator(:fd, compiled, Tables.columntable(reference_data), vars)\n\n# Compute marginal effects with zero allocations (requires Margins.jl)\ngradient = Vector{Float64}(undef, length(vars))\nmarginal_effects_eta!(gradient, de_fd, coef(model), 1)  # 0 bytes","category":"page"},{"location":"guide/categorical_mixtures/#Advanced-Usage","page":"Categorical Mixtures","title":"Advanced Usage","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Multiple-Mixture-Variables","page":"Categorical Mixtures","title":"Multiple Mixture Variables","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"You can have multiple categorical mixture variables in the same model:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"df = DataFrame(\n    x = [1.0, 2.0, 3.0],\n    treatment = [mix(\"Control\" => 0.3, \"Treated\" => 0.7),\n                 mix(\"Control\" => 0.3, \"Treated\" => 0.7),\n                 mix(\"Control\" => 0.3, \"Treated\" => 0.7)],\n    region = [mix(\"North\" => 0.4, \"South\" => 0.6),\n              mix(\"North\" => 0.4, \"South\" => 0.6), \n              mix(\"North\" => 0.4, \"South\" => 0.6)]\n)\n\nmodel = lm(@formula(y ~ x * treatment * region), training_data)\ncompiled = compile_formula(model, Tables.columntable(df))  # Handles multiple mixtures","category":"page"},{"location":"guide/categorical_mixtures/#Complex-Mixture-Specifications","page":"Categorical Mixtures","title":"Complex Mixture Specifications","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Support for arbitrary numbers of levels:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Multi-level mixture\ncomplex_mixture = mix(\n    \"Category_A\" => 0.25,\n    \"Category_B\" => 0.30, \n    \"Category_C\" => 0.20,\n    \"Category_D\" => 0.15,\n    \"Category_E\" => 0.10\n)\n\ndf = DataFrame(\n    x = [1.0, 2.0],\n    complex_cat = [complex_mixture, complex_mixture]\n)","category":"page"},{"location":"guide/categorical_mixtures/#Interaction-Terms-with-Mixtures","page":"Categorical Mixtures","title":"Interaction Terms with Mixtures","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Mixtures work with all interaction patterns:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Two-way interactions\n@formula(y ~ x * mixture_group)\n\n# Three-way interactions  \n@formula(y ~ x * z * mixture_group)\n\n# Mixed interactions\n@formula(y ~ log(x) * mixture_group * other_categorical)","category":"page"},{"location":"guide/categorical_mixtures/#Implementation-Details","page":"Categorical Mixtures","title":"Implementation Details","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Type-Specialization","page":"Categorical Mixtures","title":"Type Specialization","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Mixture specifications are embedded in type parameters for maximum performance:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Each unique mixture gets its own compiled method\nMixtureContrastOp{\n    :group,                    # Column name\n    (1, 2),                   # Output positions\n    (1, 2),                   # Level indices  \n    (0.3, 0.7)               # Weights (embedded in type!)\n}","category":"page"},{"location":"guide/categorical_mixtures/#Contrast-Matrix-Computation","page":"Categorical Mixtures","title":"Contrast Matrix Computation","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Mixtures are evaluated as weighted combinations of contrast matrices:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# For dummy coding with mix(\"A\" => 0.3, \"B\" => 0.7):\n# Standard contrast matrix:\n#   A: [1, 0]  (A vs reference)\n#   B: [0, 1]  (B vs reference)\n# \n# Mixture result: 0.3 * [1, 0] + 0.7 * [0, 1] = [0.3, 0.7]","category":"page"},{"location":"guide/categorical_mixtures/#Memory-Layout","page":"Categorical Mixtures","title":"Memory Layout","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"The implementation uses compile-time specialization for optimal memory usage:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Compile time: Mixture specs embedded in types (~0 runtime memory)\nExecution time: Only scratch vector allocation (~8 bytes per term)\nData storage: No mixture expansion in actual data (O(1) vs O(n))","category":"page"},{"location":"guide/categorical_mixtures/#Error-Messages-and-Debugging","page":"Categorical Mixtures","title":"Error Messages and Debugging","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Common-Error-Messages","page":"Categorical Mixtures","title":"Common Error Messages","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Inconsistent mixture specifications\n\"Inconsistent mixture specification in column group at row 2: expected (levels=[\\\"A\\\", \\\"B\\\"], weights=[0.3, 0.7]), got (levels=[\\\"A\\\", \\\"B\\\"], weights=[0.5, 0.5])\"\n\n# Weights don't sum to 1.0\n\"Mixture weights in column group do not sum to 1.0: [0.3, 0.6] (sum = 0.9)\"\n\n# Duplicate levels\n\"Mixture in column group contains duplicate levels: [\\\"A\\\", \\\"B\\\", \\\"A\\\"]\"\n\n# Negative weights\n\"Mixture weights in column group must be non-negative: [0.5, -0.2]\"","category":"page"},{"location":"guide/categorical_mixtures/#Debugging-Tips","page":"Categorical Mixtures","title":"Debugging Tips","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Check mixture consistency: All rows must have identical mixture specifications\nValidate weights: Must be non-negative and sum to 1.0 (within 1e-10 tolerance)\nVerify levels: Must be unique strings/symbols\nTest detection: Use is_mixture_column(column) to verify detection","category":"page"},{"location":"guide/categorical_mixtures/#Testing-and-Validation","page":"Categorical Mixtures","title":"Testing and Validation","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Built-in-Tests","page":"Categorical Mixtures","title":"Built-in Tests","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"FormulaCompiler includes comprehensive mixture tests:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Run mixture-specific tests\njulia --project=test -e \"include(\\\"test/test_mixture_detection.jl\\\")\"      # 142 tests\njulia --project=test -e \"include(\\\"test/test_categorical_mixtures.jl\\\")\"  # 62 tests\n\n# Run full test suite  \njulia --project=. -e \"using Pkg; Pkg.test()\"  # 237 mixture tests included","category":"page"},{"location":"guide/categorical_mixtures/#Custom-Testing","page":"Categorical Mixtures","title":"Custom Testing","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Validate your mixture implementations:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"using Test\n\n# Test mixture detection\n@test is_mixture_column([mix(\"A\" => 0.3, \"B\" => 0.7), mix(\"A\" => 0.3, \"B\" => 0.7)])\n@test !is_mixture_column([\"A\", \"B\", \"A\"])\n\n# Test compilation and execution\ndf_mix = DataFrame(x = [1.0], group = [mix(\"A\" => 0.3, \"B\" => 0.7)])\ncompiled = compile_formula(model, Tables.columntable(df_mix))\noutput = Vector{Float64}(undef, length(compiled))\n\n# Should execute without allocation\n@test (@allocated compiled(output, Tables.columntable(df_mix), 1)) == 0","category":"page"},{"location":"guide/categorical_mixtures/#Migration-Guide","page":"Categorical Mixtures","title":"Migration Guide","text":"","category":"section"},{"location":"guide/categorical_mixtures/#From-Override-System","page":"Categorical Mixtures","title":"From Override System","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"If you're currently using the override system for categorical mixtures:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"# Pattern 1: Direct Mixture Data (Recommended - Compile-time Specialization)\nmix_data = DataFrame(x = [1.0, 2.0], group = [mix(\"A\" => 0.3, \"B\" => 0.7), mix(\"A\" => 0.3, \"B\" => 0.7)])\ncompiled = compile_formula(model, Tables.columntable(mix_data))  # → MixtureContrastOp (fastest)\n\n# Pattern 2: Manual Data Modification (Flexible for dynamic scenarios)\nbase_data = DataFrame(x = [1.0, 2.0], group = [\"A\", \"A\"])\nmixture_data = merge(Tables.columntable(base_data), (group = fill(mix(\"A\" => 0.3, \"B\" => 0.7), 2),))\ncompiled_cf = compile_formula(model, mixture_data)  # → MixtureContrastOp with data modification\n\n# Pattern 3: Manual Population Analysis\nbase_data = DataFrame(x = [1.0, 2.0], group = [\"A\", \"A\"])\nresults = []\nfor (level, weight) in [(\"A\", 0.3), (\"B\", 0.7)]\n    level_data = merge(Tables.columntable(base_data), (group = fill(level, 2),))\n    compiled = compile_formula(model, level_data)\n    # Evaluate and weight results manually\n    push!(results, (compiled, weight))\nend","category":"page"},{"location":"guide/categorical_mixtures/#Performance-Comparison","page":"Categorical Mixtures","title":"Performance Comparison","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Approach Compilation Memory Usage Allocations Relative Speed\nOverride system Per-scenario O(scenarios) 0 bytes Baseline\nCompile-time mixtures Once O(1) 0 bytes ~3-4x faster","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Note: Both achieve zero allocations. Absolute timing varies by system; relative speedup is consistent.","category":"page"},{"location":"guide/categorical_mixtures/#Limitations-and-Considerations","page":"Categorical Mixtures","title":"Limitations and Considerations","text":"","category":"section"},{"location":"guide/categorical_mixtures/#Current-Limitations","page":"Categorical Mixtures","title":"Current Limitations","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Consistent specifications: All rows must have identical mixture specifications\nCompile-time binding: Cannot change mixture weights at runtime  \nDuck typing dependency: Mixture objects must have levels, weights, and original_levels properties","category":"page"},{"location":"guide/categorical_mixtures/#Design-Trade-offs","page":"Categorical Mixtures","title":"Design Trade-offs","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Compile-time vs Runtime: Compile-time binding provides zero-allocation performance; mixture weights cannot be changed at runtime\nMemory vs Speed: Type specialization uses more compilation time/memory for faster execution\nConsistency requirement: Simplifies implementation but limits some use cases","category":"page"},{"location":"guide/categorical_mixtures/#Future-Enhancements","page":"Categorical Mixtures","title":"Future Enhancements","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Potential areas for future development:","category":"page"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Runtime mixture resolution for varying specifications\nOptimized binary mixture methods\nIntegration with more statistical packages\nSupport for hierarchical mixture specifications","category":"page"},{"location":"guide/categorical_mixtures/#References","page":"Categorical Mixtures","title":"References","text":"","category":"section"},{"location":"guide/categorical_mixtures/","page":"Categorical Mixtures","title":"Categorical Mixtures","text":"Design Document: CATEGORICAL_MIXTURES_DESIGN.md - Complete technical design\nImplementation: Phases 1-5 complete with 237 tests passing\nPerformance Targets: All targets met (≤110% of standard categorical performance)\nIntegration: Ready for Margins.jl and other marginal effects packages","category":"page"},{"location":"integration/glm/#GLM.jl-Integration","page":"GLM.jl","title":"GLM.jl Integration","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"FormulaCompiler.jl seamlessly integrates with GLM.jl to provide zero-allocation model matrix evaluation for both linear and generalized linear models.","category":"page"},{"location":"integration/glm/#Supported-Models","page":"GLM.jl","title":"Supported Models","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"FormulaCompiler.jl works with all GLM.jl model types:","category":"page"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"Linear models (lm)\nGeneralized linear models (glm)\nAll distribution families and link functions\nCustom contrasts and standardized predictors","category":"page"},{"location":"integration/glm/#Basic-Usage","page":"GLM.jl","title":"Basic Usage","text":"","category":"section"},{"location":"integration/glm/#Linear-Models","page":"GLM.jl","title":"Linear Models","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"using GLM, FormulaCompiler, DataFrames, Tables\n\n# Create sample data\ndf = DataFrame(\n    y = randn(1000),\n    x1 = randn(1000),\n    x2 = randn(1000),\n    group = rand([\"A\", \"B\", \"C\"], 1000)\n)\n\n# Fit linear model\nmodel = lm(@formula(y ~ x1 + x2 * group), df)\n\n# Compile for zero-allocation evaluation\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Zero-allocation evaluation\ncompiled(row_vec, data, 1)  # Zero allocations; time varies by hardware","category":"page"},{"location":"integration/glm/#Generalized-Linear-Models","page":"GLM.jl","title":"Generalized Linear Models","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"using CategoricalArrays\n\n# Binary outcome data\ndf_binary = DataFrame(\n    success = rand(Bool, 1000),\n    x = randn(1000),\n    treatment = categorical(rand([\"control\", \"treatment\"], 1000)),\n    age = rand(20:80, 1000)\n)\n\n# Logistic regression\nlogit_model = glm(\n    @formula(success ~ x + treatment + age), \n    df_binary, \n    Binomial(), \n    LogitLink()\n)\n\n# Compile and use\ncompiled_logit = compile_formula(logit_model, Tables.columntable(df_binary))\nrow_vec = Vector{Float64}(undef, length(compiled_logit))\ncompiled_logit(row_vec, Tables.columntable(df_binary), 1)","category":"page"},{"location":"integration/glm/#Distribution-Families","page":"GLM.jl","title":"Distribution Families","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"FormulaCompiler.jl works with all GLM.jl distribution families:","category":"page"},{"location":"integration/glm/#Gaussian-(Normal)-Identity-Link","page":"GLM.jl","title":"Gaussian (Normal) - Identity Link","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"normal_model = glm(@formula(y ~ x1 + x2), df, Normal(), IdentityLink())\ncompiled_normal = compile_formula(normal_model, data)","category":"page"},{"location":"integration/glm/#Binomial-Logit-Link","page":"GLM.jl","title":"Binomial - Logit Link","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"# Logistic regression\nlogit_model = glm(@formula(success ~ x + age), df_binary, Binomial(), LogitLink())\n\n# Probit regression  \nprobit_model = glm(@formula(success ~ x + age), df_binary, Binomial(), ProbitLink())\n\n# Complementary log-log\ncloglog_model = glm(@formula(success ~ x + age), df_binary, Binomial(), CloglogLink())","category":"page"},{"location":"integration/glm/#Poisson-Log-Link","page":"GLM.jl","title":"Poisson - Log Link","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"# Count data\ndf_count = DataFrame(\n    count = rand(Poisson(2), 1000),\n    x = randn(1000),\n    exposure = rand(0.5:0.1:2.0, 1000)\n)\n\npoisson_model = glm(@formula(count ~ x + log(exposure)), df_count, Poisson(), LogLink())\ncompiled_poisson = compile_formula(poisson_model, Tables.columntable(df_count))","category":"page"},{"location":"integration/glm/#Gamma-Inverse-Link","page":"GLM.jl","title":"Gamma - Inverse Link","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"# Positive continuous data\ndf_gamma = DataFrame(\n    response = rand(Gamma(2, 3), 1000),\n    x = randn(1000),\n    factor = rand([\"low\", \"high\"], 1000)\n)\n\ngamma_model = glm(@formula(response ~ x + factor), df_gamma, Gamma(), InverseLink())\ncompiled_gamma = compile_formula(gamma_model, Tables.columntable(df_gamma))","category":"page"},{"location":"integration/glm/#Advanced-GLM-Features","page":"GLM.jl","title":"Advanced GLM Features","text":"","category":"section"},{"location":"integration/glm/#Custom-Contrasts","page":"GLM.jl","title":"Custom Contrasts","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"using StatsModels\n\n# Define custom contrasts\ncontrasts_dict = Dict(\n    :treatment => DummyCoding(base=\"control\"),\n    :group => EffectsCoding(),\n    :region => HelmertCoding()\n)\n\n# Fit model with custom contrasts\ndf_contrasts = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    treatment = categorical(rand([\"control\", \"low\", \"high\"], 1000)),\n    group = categorical(rand([\"A\", \"B\", \"C\", \"D\"], 1000)),\n    region = categorical(rand([\"North\", \"South\", \"East\", \"West\"], 1000))\n)\n\nmodel_contrasts = lm(\n    @formula(y ~ x + treatment + group + region), \n    df_contrasts, \n    contrasts = contrasts_dict\n)\n\ncompiled_contrasts = compile_formula(model_contrasts, Tables.columntable(df_contrasts))","category":"page"},{"location":"integration/glm/#Weights-and-Offsets","page":"GLM.jl","title":"Weights and Offsets","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"# Weighted regression\nweights = rand(0.5:0.1:2.0, 1000)\nweighted_model = lm(@formula(y ~ x1 + x2), df, wts=weights)\n\n# GLM with offset\ndf_offset = DataFrame(\n    y = rand(Poisson(2), 1000),\n    x = randn(1000),\n    offset_var = log.(rand(0.5:0.1:2.0, 1000))\n)\n\noffset_model = glm(\n    @formula(y ~ x + offset(offset_var)), \n    df_offset, \n    Poisson(), \n    LogLink()\n)\n\n# FormulaCompiler handles both\ncompiled_weighted = compile_formula(weighted_model, Tables.columntable(df))\ncompiled_offset = compile_formula(offset_model, Tables.columntable(df_offset))","category":"page"},{"location":"integration/glm/#Performance-Comparisons","page":"GLM.jl","title":"Performance Comparisons","text":"","category":"section"},{"location":"integration/glm/#Benchmark-Against-modelmatrix()","page":"GLM.jl","title":"Benchmark Against modelmatrix()","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"using BenchmarkTools\n\n# Setup\ndf = DataFrame(\n    y = randn(1000),\n    x1 = randn(1000), \n    x2 = randn(1000),\n    group = categorical(rand([\"A\", \"B\", \"C\"], 1000))\n)\n\nmodel = lm(@formula(y ~ x1 * x2 + group + log(abs(x1) + 1)), df)\ndata = Tables.columntable(df)\n\n# Traditional approach\nfunction traditional_single_row(model, row_idx)\n    mm = modelmatrix(model)\n    return mm[row_idx, :]\nend\n\n# FormulaCompiler approach\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\nfunction fc_single_row(compiled, data, row_vec, row_idx)\n    compiled(row_vec, data, row_idx)\n    return row_vec\nend\n\n# Benchmark comparison\n# Note: Absolute times vary by hardware and Julia version; see the Benchmark Protocol.\nprintln(\"Traditional approach:\")\n@benchmark traditional_single_row($model, 1)\n\nprintln(\"\\nFormulaCompiler approach:\")\n@benchmark fc_single_row($compiled, $data, $row_vec, 1)\n\n# Expected results (indicative):\n# Traditional: ~10μs, 1 allocation\n# FormulaCompiler: tens of ns, 0 allocations (order-of-magnitude faster)","category":"page"},{"location":"integration/glm/#Large-Model-Performance","page":"GLM.jl","title":"Large Model Performance","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"# Create a large, complex model\nfunction create_large_model(n_obs=10000)\n    df = DataFrame(\n        y = randn(n_obs),\n        x1 = randn(n_obs),\n        x2 = randn(n_obs),\n        x3 = randn(n_obs),\n        x4 = randn(n_obs),\n        group1 = categorical(rand(1:10, n_obs)),\n        group2 = categorical(rand(1:5, n_obs)),\n        group3 = categorical(rand(1:3, n_obs))\n    )\n    \n    # Complex formula with interactions\n    formula = @formula(y ~ (x1 + x2 + x3 + x4) * (group1 + group2) + \n                          log(abs(x1) + 1) * group3 + \n                          sqrt(abs(x2) + 1) + \n                          x3^2 + \n                          (x4 > 0))\n    \n    model = lm(formula, df)\n    return model, df\nend\n\n# Test performance on large model\nlarge_model, large_df = create_large_model(10000)\nlarge_data = Tables.columntable(large_df)\nlarge_compiled = compile_formula(large_model, large_data)\n\nprintln(\"Large model performance:\")\nprintln(\"Model matrix size: \", size(modelmatrix(large_model)))\nprintln(\"Compilation time:\")\n@time compile_formula(large_model, large_data)\n\nprintln(\"Single row evaluation:\")\nrow_vec = Vector{Float64}(undef, length(large_compiled))\n@benchmark $large_compiled($row_vec, $large_data, 1)","category":"page"},{"location":"integration/glm/#Real-world-Applications","page":"GLM.jl","title":"Real-world Applications","text":"","category":"section"},{"location":"integration/glm/#Marginal-Effects-Calculation","page":"GLM.jl","title":"Marginal Effects Calculation","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"function calculate_marginal_effects(model, data, variable_col, delta=0.01)\n    compiled = compile_formula(model, data)\n    n_rows = Tables.rowcount(data)\n    \n    # Get original variable values\n    original_values = data[variable_col]\n    \n    # Create scenarios with perturbed values\n    perturbed_values = original_values .+ delta\n    perturbed_data = (; data..., variable_col => perturbed_values)\n    \n    row_vec_original = Vector{Float64}(undef, length(compiled))\n    row_vec_perturbed = Vector{Float64}(undef, length(compiled))\n    \n    marginal_effects = Matrix{Float64}(undef, n_rows, length(compiled))\n    \n    for i in 1:n_rows\n        # Original prediction\n        compiled(row_vec_original, data, i)\n        \n        # Perturbed prediction  \n        compiled(row_vec_perturbed, perturbed_data, i)\n        \n        # Marginal effect\n        marginal_effects[i, :] .= (row_vec_perturbed .- row_vec_original) ./ delta\n    end\n    \n    return marginal_effects\nend\n\n# Example usage\nmarginal_fx = calculate_marginal_effects(model, data, :x1)","category":"page"},{"location":"integration/glm/#Bootstrap-Confidence-Intervals","page":"GLM.jl","title":"Bootstrap Confidence Intervals","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"function bootstrap_glm_coefficients(model, data, n_bootstrap=1000)\n    compiled = compile_formula(model, data)\n    n_obs = Tables.rowcount(data)\n    n_coefs = length(compiled)\n    \n    # Get original response variable\n    y = data[Symbol(model.mf.f.lhs)]\n    \n    bootstrap_coefs = Matrix{Float64}(undef, n_bootstrap, n_coefs)\n    row_vec = Vector{Float64}(undef, n_coefs)\n    \n    for boot in 1:n_bootstrap\n        # Bootstrap sample\n        sample_idx = rand(1:n_obs, n_obs)\n        \n        # Create design matrix for bootstrap sample\n        X_boot = Matrix{Float64}(undef, n_obs, n_coefs)\n        y_boot = Vector{Float64}(undef, n_obs)\n        \n        for (i, idx) in enumerate(sample_idx)\n            compiled(row_vec, data, idx)\n            X_boot[i, :] .= row_vec\n            y_boot[i] = y[idx]\n        end\n        \n        # Fit bootstrap model (simplified OLS)\n        bootstrap_coefs[boot, :] = X_boot \\ y_boot\n    end\n    \n    return bootstrap_coefs\nend","category":"page"},{"location":"integration/glm/#Prediction-Intervals","page":"GLM.jl","title":"Prediction Intervals","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"function prediction_intervals(model, data, confidence_level=0.95)\n    compiled = compile_formula(model, data)\n    n_obs = Tables.rowcount(data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Get model coefficients and residual variance\n    coefs = coef(model)\n    σ² = deviance(model) / dof_residual(model)\n    \n    # Critical value\n    α = 1 - confidence_level\n    t_crit = quantile(TDist(dof_residual(model)), 1 - α/2)\n    \n    predictions = Vector{Float64}(undef, n_obs)\n    lower_bounds = Vector{Float64}(undef, n_obs)\n    upper_bounds = Vector{Float64}(undef, n_obs)\n    \n    for i in 1:n_obs\n        compiled(row_vec, data, i)\n        \n        # Point prediction\n        pred = dot(coefs, row_vec)\n        predictions[i] = pred\n        \n        # Prediction standard error\n        # SE = sqrt(σ² * (1 + x'(X'X)⁻¹x))\n        # Simplified for demonstration\n        se = sqrt(σ² * (1 + sum(row_vec.^2) / n_obs))\n        \n        # Confidence bounds\n        margin = t_crit * se\n        lower_bounds[i] = pred - margin\n        upper_bounds[i] = pred + margin\n    end\n    \n    return (predictions = predictions, lower = lower_bounds, upper = upper_bounds)\nend","category":"page"},{"location":"integration/glm/#Integration-Best-Practices","page":"GLM.jl","title":"Integration Best Practices","text":"","category":"section"},{"location":"integration/glm/#Model-Validation","page":"GLM.jl","title":"Model Validation","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"function validate_glm_integration(model, data)\n    compiled = compile_formula(model, data)\n    \n    # Compare first few rows with modelmatrix\n    mm = modelmatrix(model)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    for i in 1:min(10, size(mm, 1))\n        compiled(row_vec, data, i)\n        original_row = mm[i, :]\n        \n        if !isapprox(row_vec, original_row, rtol=1e-12)\n            @warn \"Mismatch in row $i\"\n            println(\"Original: \", original_row)\n            println(\"Compiled: \", row_vec)\n            return false\n        end\n    end\n    \n    println(\"✓ FormulaCompiler matches GLM.jl modelmatrix for all tested rows\")\n    return true\nend\n\n# Validate integration\nvalidate_glm_integration(model, data)","category":"page"},{"location":"integration/glm/#Memory-Usage-Comparison","page":"GLM.jl","title":"Memory Usage Comparison","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"function compare_memory_usage(model, data)\n    # Traditional approach\n    traditional_memory = @allocated modelmatrix(model)\n    \n    # FormulaCompiler approach\n    compilation_memory = @allocated compile_formula(model, data)\n    \n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    evaluation_memory = @allocated compiled(row_vec, data, 1)\n    \n    println(\"Memory Usage Comparison:\")\n    println(\"Traditional modelmatrix(): \", traditional_memory, \" bytes\")\n    println(\"FormulaCompiler compilation: \", compilation_memory, \" bytes\")\n    println(\"FormulaCompiler evaluation: \", evaluation_memory, \" bytes\")\n    \n    if evaluation_memory == 0\n        println(\"✓ Zero-allocation evaluation achieved\")\n    else\n        @warn \"Non-zero allocation detected in evaluation\"\n    end\nend\n\ncompare_memory_usage(model, data)","category":"page"},{"location":"integration/glm/#Troubleshooting","page":"GLM.jl","title":"Troubleshooting","text":"","category":"section"},{"location":"integration/glm/#Common-Issues","page":"GLM.jl","title":"Common Issues","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"Type instability: Ensure all variables have consistent types\nMissing values: Handle missing values before compilation\nCategorical levels: Ensure categorical variables have the same levels in test data\nFormula complexity: Very complex formulas may have longer compilation times","category":"page"},{"location":"integration/glm/#Debugging-Tools","page":"GLM.jl","title":"Debugging Tools","text":"","category":"section"},{"location":"integration/glm/","page":"GLM.jl","title":"GLM.jl","text":"# Check compilation success\nfunction debug_compilation(model, data)\n    try\n        compiled = compile_formula(model, data)\n        println(\"✓ Compilation successful\")\n        println(\"Formula length: \", length(compiled))\n        return compiled\n    catch e\n        @error \"Compilation failed\" exception = e\n        return nothing\n    end\nend\n\n# Performance diagnostics\nfunction diagnose_performance(model, data)\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Check allocation\n    alloc = @allocated compiled(row_vec, data, 1)\n    if alloc > 0\n        @warn \"Non-zero allocation detected: $alloc bytes\"\n    end\n    \n    # Check timing\n    time_ns = @elapsed compiled(row_vec, data, 1) * 1e9\n    if time_ns > 1000  # > 1μs\n        @warn \"Evaluation slower than expected: $(round(time_ns))ns\"\n    end\n    \n    println(\"Performance: $(round(time_ns))ns, $(alloc) bytes\")\nend","category":"page"},{"location":"integration/standardized_predictors/#StandardizedPredictors.jl-Integration-Guide","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl Integration Guide","text":"","category":"section"},{"location":"integration/standardized_predictors/#Overview","page":"StandardizedPredictors.jl","title":"Overview","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"This guide explains how FormulaCompiler.jl integrates with StandardizedPredictors.jl to provide efficient evaluation of models with standardized variables. The guide covers user-facing workflows and the underlying architectural principles that enable this integration.","category":"page"},{"location":"integration/standardized_predictors/#Table-of-Contents","page":"StandardizedPredictors.jl","title":"Table of Contents","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Quick Start\nUnderstanding the Architecture\nUser Guide: Working with Standardized Variables\nDeveloper Guide: How Integration Works\nAdvanced Usage Patterns\nPerformance Considerations\nTroubleshooting","category":"page"},{"location":"integration/standardized_predictors/#Quick-Start","page":"StandardizedPredictors.jl","title":"Quick Start","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"using FormulaCompiler, StandardizedPredictors, GLM, DataFrames, Tables\n\n# Create sample data\ndf = DataFrame(\n    y = randn(1000),\n    income = randn(1000) * 20000 .+ 50000,  # Mean ≈ 50k, std ≈ 20k\n    age = randn(1000) * 10 .+ 35,           # Mean ≈ 35, std ≈ 10\n    education = rand([\"High School\", \"College\", \"Graduate\"], 1000)\n)\n\n# Fit model with standardized predictors\nmodel = lm(@formula(y ~ income + age + education), df,\n           contrasts = Dict(:income => ZScore(), :age => ZScore()))\n\n# Compile for fast evaluation\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Zero-allocation evaluation\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, data, 1)  # Fast evaluation for row 1","category":"page"},{"location":"integration/standardized_predictors/#Understanding-the-Architecture","page":"StandardizedPredictors.jl","title":"Understanding the Architecture","text":"","category":"section"},{"location":"integration/standardized_predictors/#The-Julia-Statistical-Ecosystem-Layer-Architecture","page":"StandardizedPredictors.jl","title":"The Julia Statistical Ecosystem Layer Architecture","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The Julia statistical ecosystem operates on a three-layer architecture that separates concerns for efficiency and flexibility:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"┌─────────────────────────────────────┐\n│ SCHEMA LAYER (Data Transformation)  │  StandardizedPredictors.jl\n├─────────────────────────────────────┤\n│ COMPILATION LAYER (Optimization)    │  FormulaCompiler.jl  \n├─────────────────────────────────────┤\n│ EXECUTION LAYER (Computation)       │  Generated machine code\n└─────────────────────────────────────┘","category":"page"},{"location":"integration/standardized_predictors/#Layer-1:-Schema-Layer","page":"StandardizedPredictors.jl","title":"Layer 1: Schema Layer","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Purpose: Data preprocessing and transformation Packages: StandardizedPredictors.jl, CategoricalArrays.jl, StatsModels.jl contrasts Operation: Transforms raw data during model fitting","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Schema layer work happens here:\nmodel = lm(@formula(y ~ x), data, contrasts = Dict(:x => ZScore()))\n# Standardization applied during fitting","category":"page"},{"location":"integration/standardized_predictors/#Layer-2:-Compilation-Layer","page":"StandardizedPredictors.jl","title":"Layer 2: Compilation Layer","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Purpose: Generate optimized evaluation code   Packages: FormulaCompiler.jl, StatsModels.jl   Operation: Creates zero-allocation evaluators for pre-transformed data","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Compilation layer work happens here:\ncompiled = compile_formula(model, data)\n# Generates optimized code for standardized data","category":"page"},{"location":"integration/standardized_predictors/#Layer-3:-Execution-Layer","page":"StandardizedPredictors.jl","title":"Layer 3: Execution Layer","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Purpose: Fast, zero-allocation computation   Packages: Generated Julia code, LLVM optimizations   Operation: Per-row evaluation","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Execution layer work happens here:\ncompiled(output, data, row)  # 0 allocations; time varies by hardware","category":"page"},{"location":"integration/standardized_predictors/#Architecture-Properties","page":"StandardizedPredictors.jl","title":"Architecture Properties","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Separation of Concerns: Each layer has a single responsibility\nOptimal Performance: Transformations happen once, evaluations happen many times\nComposability: Mix and match different schema transformations\nType Stability: Each layer can be fully optimized by Julia's compiler","category":"page"},{"location":"integration/standardized_predictors/#Common-Misconception","page":"StandardizedPredictors.jl","title":"Common Misconception","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Incorrect approach: FormulaCompiler should apply z-scoring during evaluation","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# This would be inefficient - applying transformation every evaluation\ncompiled(output, data, row)  # Would standardize x every time","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Correct approach: FormulaCompiler operates on pre-standardized data","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Efficient - transformation applied once during model fitting\nmodel = lm(..., contrasts = Dict(:x => ZScore()))  # Transform once\ncompiled(output, data, row)  # Use pre-transformed data","category":"page"},{"location":"integration/standardized_predictors/#User-Guide:-Working-with-Standardized-Variables","page":"StandardizedPredictors.jl","title":"User Guide: Working with Standardized Variables","text":"","category":"section"},{"location":"integration/standardized_predictors/#Basic-Usage","page":"StandardizedPredictors.jl","title":"Basic Usage","text":"","category":"section"},{"location":"integration/standardized_predictors/#Single-Variable-Standardization","page":"StandardizedPredictors.jl","title":"Single Variable Standardization","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"using StandardizedPredictors, FormulaCompiler, GLM\n\n# Standardize income only\nmodel = lm(@formula(sales ~ income + region), data,\n           contrasts = Dict(:income => ZScore()))\n\ncompiled = compile_formula(model, Tables.columntable(data))","category":"page"},{"location":"integration/standardized_predictors/#Multiple-Variable-Standardization","page":"StandardizedPredictors.jl","title":"Multiple Variable Standardization","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Standardize multiple continuous variables\nmodel = lm(@formula(y ~ income + age + experience), data,\n           contrasts = Dict(\n               :income => ZScore(),\n               :age => ZScore(),\n               :experience => ZScore()\n           ))","category":"page"},{"location":"integration/standardized_predictors/#Mixed-Standardization-and-Contrasts","page":"StandardizedPredictors.jl","title":"Mixed Standardization and Contrasts","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Combine standardization with categorical contrasts\nmodel = lm(@formula(y ~ income + age + region + education), data,\n           contrasts = Dict(\n               :income => ZScore(),           # Standardize continuous\n               :age => ZScore(),             # Standardize continuous  \n               :region => EffectsCoding(),   # Effects coding for categorical\n               :education => DummyCoding()   # Dummy coding for categorical\n           ))","category":"page"},{"location":"integration/standardized_predictors/#Working-with-Complex-Formulas","page":"StandardizedPredictors.jl","title":"Working with Complex Formulas","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"StandardizedPredictors.jl works with any formula complexity:","category":"page"},{"location":"integration/standardized_predictors/#Functions-and-Transformations","page":"StandardizedPredictors.jl","title":"Functions and Transformations","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"model = lm(@formula(y ~ log(income) + age^2 + sqrt(experience)), data,\n           contrasts = Dict(\n               :income => ZScore(),      # Standardizes log(income)  \n               :age => ZScore(),        # Standardizes age^2\n               :experience => ZScore()   # Standardizes sqrt(experience)\n           ))","category":"page"},{"location":"integration/standardized_predictors/#Interactions-with-Standardized-Variables","page":"StandardizedPredictors.jl","title":"Interactions with Standardized Variables","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"model = lm(@formula(y ~ income * age + region), data,\n           contrasts = Dict(\n               :income => ZScore(),\n               :age => ZScore()\n           ))\n# The interaction income * age uses standardized values","category":"page"},{"location":"integration/standardized_predictors/#Scenario-Analysis-with-Standardized-Variables","page":"StandardizedPredictors.jl","title":"Scenario Analysis with Standardized Variables","text":"","category":"section"},{"location":"integration/standardized_predictors/#Understanding-Override-Scales","page":"StandardizedPredictors.jl","title":"Understanding Override Scales","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"When creating scenarios with standardized variables, override values must be in the standardized scale:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Calculate standardization parameters\nincome_mean = mean(data.income)\nincome_std = std(data.income)\n\n# Create scenario with standardized override\nraw_income = 75000  # Raw income value\nstandardized_income = (raw_income - income_mean) / income_std\n\n# Population analysis with standardized income override\nn_rows = length(first(data))\ndata_high_income = merge(data, (income = fill(standardized_income, n_rows),))","category":"page"},{"location":"integration/standardized_predictors/#Helper-Function-for-Raw-Values","page":"StandardizedPredictors.jl","title":"Helper Function for Raw Values","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"function create_standardized_data(data, original_data, standardized_vars; overrides...)\n    # Create data with automatic standardization of override values\n    standardized_overrides = Dict{Symbol, Any}()\n    n_rows = length(first(data))\n\n    for (var, raw_value) in overrides\n        if var in standardized_vars  # Track which vars are standardized\n            var_mean = mean(original_data[var])\n            var_std = std(original_data[var])\n            standardized_value = (raw_value - var_mean) / var_std\n            standardized_overrides[var] = fill(standardized_value, n_rows)\n        else\n            standardized_overrides[var] = fill(raw_value, n_rows)\n        end\n    end\n\n    return merge(data, standardized_overrides)\nend\n\n# Usage\ndata_analysis = create_standardized_data(data, original_data, [:income, :age];\n                                        income = 75000,    # Raw value\n                                        age = 45)          # Raw value","category":"page"},{"location":"integration/standardized_predictors/#Derivative-Analysis","page":"StandardizedPredictors.jl","title":"Derivative Analysis","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Derivatives are automatically computed on the original (raw) scale through the chain rule:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Build derivative evaluator\ncompiled = compile_formula(model, data)\nde_fd = derivativeevaluator(:fd, compiled, data, [:income, :age])\n\n# Compute model matrix Jacobian\nJ = Matrix{Float64}(undef, length(compiled), 2)\nderivative_modelrow!(J, de_fd, row)\n\n# The Jacobian is already on the original scale!\n# J[:,1] contains ∂X/∂income_dollars (NOT ∂X/∂income_standardized)\n# J[:,2] contains ∂X/∂age_years (NOT ∂X/∂age_standardized)\n\n# Compute marginal effect on linear predictor\ng = J' * coef(model)\n# g[1] = marginal effect of income (per dollar) - no conversion needed!\n# g[2] = marginal effect of age (per year) - no conversion needed!","category":"page"},{"location":"integration/standardized_predictors/#Why-Automatic-Back-Transformation-Works","page":"StandardizedPredictors.jl","title":"Why Automatic Back-Transformation Works","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"When FormulaCompiler evaluates StandardizeOp, the chain rule is applied automatically:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Finite Differences: Perturbs raw values (x → x + h) → StandardizeOp transforms during evaluation (x_std → x_std + h/σ) → derivative includes 1/σ factor automatically","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Automatic Differentiation: Dual arithmetic propagates through (x - μ)/σ → derivative includes 1/σ factor automatically","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Result: ∂X_standardized/∂x_raw = 1/σ, giving derivatives on the original scale without manual conversion.","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Common Mistake to Avoid:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# ❌ WRONG - this divides by σ twice!\nincome_effect_WRONG = g[1] / std(original_data.income)\n\n# ✅ CORRECT - derivatives are already on the original scale\nincome_effect_per_dollar = g[1]  # Already per dollar!","category":"page"},{"location":"integration/standardized_predictors/#Understanding-Derivative-Scales","page":"StandardizedPredictors.jl","title":"Understanding Derivative Scales","text":"","category":"section"},{"location":"integration/standardized_predictors/#Key-Principle:-Chain-Rule-is-Automatic","page":"StandardizedPredictors.jl","title":"Key Principle: Chain Rule is Automatic","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"When you call derivative_modelrow! on a model with standardized predictors, FormulaCompiler automatically accounts for the standardization transformation via the chain rule.","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Mathematical detail:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Model uses: x_std = (x - μ) / σ\nFD perturbs: x_raw → x_raw + h\nStandardizeOp transforms: x_std → (x_raw + h - μ)/σ = x_std + h/σ\nCentral difference: [f(x_std + h/σ) - f(x_std - h/σ)] / (2h) = (∂f/∂x_std) × (1/σ)","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Result: Derivative is w.r.t. x_raw, not x_std.","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The same logic applies to AD via dual number arithmetic through StandardizeOp:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"AD seeds: Dual(x_raw, 1.0)\nStandardizeOp on dual: (Dual(x_raw, 1.0) - μ) / σ = Dual((x_raw - μ)/σ, 1/σ)\nDerivative extraction: partials(result) includes the 1/σ factor","category":"page"},{"location":"integration/standardized_predictors/#Common-Misconception-2","page":"StandardizedPredictors.jl","title":"Common Misconception","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"❌ WRONG: \"I need to divide by std() to get effects per original unit\" ✅ CORRECT: \"Derivatives are already per original unit due to automatic chain rule\"","category":"page"},{"location":"integration/standardized_predictors/#Technical-Implications","page":"StandardizedPredictors.jl","title":"Technical Implications","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The automatic chain rule means:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Model coefficients (coef(model)): These ARE on standardized scale\nβ₁ in standardized model = effect per SD change in x\nDerivatives from FormulaCompiler (derivative_modelrow!): These are on RAW scale\n∂X/∂x = derivative w.r.t. raw variable (includes 1/σ from chain rule)","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"When you multiply them: g = (∂X/∂x_raw)' * β_std, you get the correct marginal effect on raw scale because the 1/σ in the Jacobian combines correctly with the standardized coefficients.","category":"page"},{"location":"integration/standardized_predictors/#For-Margins.jl-Users","page":"StandardizedPredictors.jl","title":"For Margins.jl Users","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"If you're using Margins.jl (which builds on FormulaCompiler), marginal effects are automatically on the original scale. Margins.jl handles standardized predictors correctly through FormulaCompiler's automatic chain rule application.","category":"page"},{"location":"integration/standardized_predictors/#Validation","page":"StandardizedPredictors.jl","title":"Validation","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"This behavior is validated by comprehensive tests in test/test_standardized_predictors.jl:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Compare raw vs standardized models\nmodel_raw = lm(@formula(y ~ x), df)\nmodel_std = lm(@formula(y ~ x), df, contrasts=Dict(:x => ZScore()))\n\n# Compute marginal effects\ng_raw = (J_raw' * coef(model_raw))[1]\ng_std = (J_std' * coef(model_std))[1]\n\n# Critical validation: both should be equal (both on raw scale)\n@test g_raw ≈ g_std rtol=1e-10  # ✓ PASSES","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"All 278 tests pass, including 18 tests specifically validating derivative scale correctness.","category":"page"},{"location":"integration/standardized_predictors/#Developer-Guide:-How-Integration-Works","page":"StandardizedPredictors.jl","title":"Developer Guide: How Integration Works","text":"","category":"section"},{"location":"integration/standardized_predictors/#The-ZScoredTerm-Implementation","page":"StandardizedPredictors.jl","title":"The ZScoredTerm Implementation","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"FormulaCompiler.jl handles StandardizedPredictors.jl through a simple but crucial implementation:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# src/compilation/decomposition.jl\nfunction decompose_term!(ctx::CompilationContext, term::ZScoredTerm, data_example)\n    # StandardizedPredictors.jl applies transformations at the schema level during model fitting\n    # By compilation time, the data has already been transformed\n    # We just decompose the inner term normally\n    return decompose_term!(ctx, term.term, data_example)\nend","category":"page"},{"location":"integration/standardized_predictors/#Why-Pass-Through-is-Correct","page":"StandardizedPredictors.jl","title":"Why Pass-Through is Correct","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Schema-Level Transformation: By the time decompose_term! is called, the data has already been standardized\nMetadata Only: ZScoredTerm contains transformation metadata, not active transformation instructions\nNo Double-Standardization: Applying standardization again would be incorrect","category":"page"},{"location":"integration/standardized_predictors/#ZScoredTerm-Structure","page":"StandardizedPredictors.jl","title":"ZScoredTerm Structure","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"struct ZScoredTerm{T,C,S} <: AbstractTerm\n    term::T        # Original term (e.g., Term(:income))\n    center::C      # Mean value used for centering\n    scale::S       # Standard deviation used for scaling  \nend","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The center and scale fields contain the transformation parameters, but they're metadata only - the actual transformation has already been applied to the data.","category":"page"},{"location":"integration/standardized_predictors/#Integration-Points","page":"StandardizedPredictors.jl","title":"Integration Points","text":"","category":"section"},{"location":"integration/standardized_predictors/#1.-Import-Declaration","page":"StandardizedPredictors.jl","title":"1. Import Declaration","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# src/FormulaCompiler.jl\nusing StandardizedPredictors: ZScoredTerm","category":"page"},{"location":"integration/standardized_predictors/#2.-Term-Decomposition","page":"StandardizedPredictors.jl","title":"2. Term Decomposition","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# src/compilation/decomposition.jl  \nfunction decompose_term!(ctx::CompilationContext, term::ZScoredTerm, data_example)\n    return decompose_term!(ctx, term.term, data_example)\nend","category":"page"},{"location":"integration/standardized_predictors/#3.-Column-Extraction-(Mixed-Models)","page":"StandardizedPredictors.jl","title":"3. Column Extraction (Mixed Models)","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# src/integration/mixed_models.jl\nfunction extract_columns_recursive!(columns::Vector{Symbol}, term::ZScoredTerm)\n    extract_columns_recursive!(columns, term.term)\nend","category":"page"},{"location":"integration/standardized_predictors/#Testing-Framework","page":"StandardizedPredictors.jl","title":"Testing Framework","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The integration is validated through comprehensive tests:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# test/test_standardized_predictors.jl\n@testset \"StandardizedPredictors Integration\" begin\n    # Basic modelrow evaluation\n    # Derivative computation  \n    # Scenario analysis\n    # Complex formulas with functions and interactions\n    # Performance validation (zero allocations)\nend","category":"page"},{"location":"integration/standardized_predictors/#Advanced-Usage-Patterns","page":"StandardizedPredictors.jl","title":"Advanced Usage Patterns","text":"","category":"section"},{"location":"integration/standardized_predictors/#Policy-Analysis-with-Standardized-Variables","page":"StandardizedPredictors.jl","title":"Policy Analysis with Standardized Variables","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"function standardized_policy_analysis(model, data, original_data)\n    compiled = compile_formula(model, data)\n    \n    # Define policy scenarios in original scale\n    policies = Dict(\n        \"baseline\" => Dict(),\n        \"high_income\" => Dict(:income => 100000),  # $100k income\n        \"young_demographic\" => Dict(:age => 25),    # 25 years old\n        \"combined_policy\" => Dict(:income => 80000, :age => 30)\n    )\n    \n    results = Dict()\n    for (name, policy) in policies\n        # Convert to standardized scale\n        standardized_policy = Dict()\n        for (var, value) in policy\n            var_mean = mean(original_data[var])\n            var_std = std(original_data[var])\n            standardized_policy[var] = (value - var_mean) / var_std\n        end\n        \n        # Create modified data and evaluate\n        n_rows = length(first(data))\n        policy_data = merge(data, Dict(k => fill(v, n_rows) for (k, v) in standardized_policy))\n        scenario_results = evaluate_scenario(compiled, policy_data, coef(model))\n        results[name] = scenario_results\n    end\n    \n    return results\nend","category":"page"},{"location":"integration/standardized_predictors/#Batch-Marginal-Effects","page":"StandardizedPredictors.jl","title":"Batch Marginal Effects","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"using Margins  # Provides marginal_effects_eta!\n\nfunction batch_marginal_effects_standardized(model, data, variables, rows)\n    compiled = compile_formula(model, data)\n    de_fd = derivativeevaluator(:fd, compiled, data, variables)\n\n    n_vars = length(variables)\n    n_rows = length(rows)\n\n    # Pre-allocate results\n    marginal_effects = Matrix{Float64}(undef, n_rows, n_vars)\n    g = Vector{Float64}(undef, n_vars)\n\n    for (i, row) in enumerate(rows)\n        marginal_effects_eta!(g, de_fd, coef(model), row)\n        marginal_effects[i, :] .= g\n    end\n\n    return marginal_effects\nend","category":"page"},{"location":"integration/standardized_predictors/#Model-Comparison-Framework","page":"StandardizedPredictors.jl","title":"Model Comparison Framework","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"function compare_standardized_models(formulas, data, standardized_vars)\n    models = Dict()\n    compiled_models = Dict()\n    \n    for (name, formula) in formulas\n        # Create contrasts dict for standardized variables\n        contrasts = Dict(var => ZScore() for var in standardized_vars)\n        \n        # Fit model\n        model = lm(formula, data, contrasts=contrasts)\n        compiled = compile_formula(model, Tables.columntable(data))\n        \n        models[name] = model\n        compiled_models[name] = compiled\n    end\n    \n    return models, compiled_models\nend\n\n# Usage\nformulas = Dict(\n    \"linear\" => @formula(y ~ income + age),\n    \"with_interactions\" => @formula(y ~ income * age),  \n    \"with_functions\" => @formula(y ~ log(income) + age^2)\n)\n\nmodels, compiled = compare_standardized_models(formulas, df, [:income, :age])","category":"page"},{"location":"integration/standardized_predictors/#Performance-Considerations","page":"StandardizedPredictors.jl","title":"Performance Considerations","text":"","category":"section"},{"location":"integration/standardized_predictors/#Compilation-Overhead","page":"StandardizedPredictors.jl","title":"Compilation Overhead","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Standardization adds zero compilation overhead because:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"No additional operations: ZScoredTerm just passes through to inner term\nSame generated code: Identical operations as non-standardized models\nSame memory usage: No additional scratch space or operations","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Performance is identical\n@benchmark compile_formula($model_regular, $data)\n@benchmark compile_formula($model_standardized, $data)","category":"page"},{"location":"integration/standardized_predictors/#Runtime-Performance","page":"StandardizedPredictors.jl","title":"Runtime Performance","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Zero-allocation guarantees are maintained:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"compiled = compile_formula(model_standardized, data)\noutput = Vector{Float64}(undef, length(compiled))\n\n@benchmark $compiled($output, $data, 1)  # Still 0 allocations","category":"page"},{"location":"integration/standardized_predictors/#Memory-Efficiency-with-Scenarios","page":"StandardizedPredictors.jl","title":"Memory Efficiency with Scenarios","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The override system provides massive memory savings for policy analysis:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Instead of copying data for each scenario (expensive):\nscenario_data_copy = deepcopy(large_dataset)  # Expensive!\nscenario_data_copy.income .= 75000\n\n# Use simple data modification (straightforward):\nn_rows = length(first(data))\ndata_policy = merge(data, (income = fill(standardized_value, n_rows),))  # Direct approach","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Memory comparison for 1M rows:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Data copying: ~4.8GB per scenario\nOverride system: ~48 bytes per scenario  \nMemory reduction: 99.999999%","category":"page"},{"location":"integration/standardized_predictors/#Troubleshooting","page":"StandardizedPredictors.jl","title":"Troubleshooting","text":"","category":"section"},{"location":"integration/standardized_predictors/#Common-Issues","page":"StandardizedPredictors.jl","title":"Common Issues","text":"","category":"section"},{"location":"integration/standardized_predictors/#Issue-1:-Unexpected-Results-in-Scenarios","page":"StandardizedPredictors.jl","title":"Issue 1: Unexpected Results in Scenarios","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Incorrect - using raw values with standardized model\nn_rows = length(first(standardized_data))\ndata_incorrect = merge(standardized_data, (income = fill(75000, n_rows),))\n\n# Correct - convert to standardized scale first\nincome_std = (75000 - mean(original_data.income)) / std(original_data.income)\ndata_correct = merge(standardized_data, (income = fill(income_std, n_rows),))","category":"page"},{"location":"integration/standardized_predictors/#Issue-2:-Understanding-Derivative-Scales","page":"StandardizedPredictors.jl","title":"Issue 2: Understanding Derivative Scales","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Important: Derivatives from FormulaCompiler are already on the original scale due to automatic chain rule application.","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Compute derivatives\nde_fd = derivativeevaluator(:fd, compiled, data, [:income, :age])\nJ = Matrix{Float64}(undef, length(compiled), length(vars))\nderivative_modelrow!(J, de_fd, row)\n\n# J already contains ∂X/∂x_raw (NOT ∂X/∂x_std)\n# The chain rule through StandardizeOp is applied automatically!\n\n# Compute marginal effects\ng = J' * coef(model)\n\n# ✅ CORRECT - derivatives are already per original unit\nincome_effect_per_dollar = g[1]  # Already per dollar!\nage_effect_per_year = g[2]        # Already per year!\n\n# ❌ WRONG - this would divide by σ twice\n# income_effect_WRONG = g[1] / std(original_data.income)","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Why this works: When standardized variables are used, FormulaCompiler perturbs raw input values (FD) or seeds raw input duals (AD), then applies StandardizeOp during evaluation. The 1/σ factor from the chain rule is automatically included in the computed derivatives.","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"\n#### Issue 3: Mixing Standardized and Non-Standardized Variables","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"julia","category":"page"},{"location":"integration/standardized_predictors/#Specify-which-variables-are-standardized","page":"StandardizedPredictors.jl","title":"Specify which variables are standardized","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"contrasts = Dict(     :income => ZScore(),      # Standardized     :age => ZScore(),         # Standardized       # :region not specified - uses default (DummyCoding for categorical) )","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"model = lm(@formula(y ~ income + age + region), data, contrasts=contrasts)","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"\n### Debugging Tips\n\n#### Verify Standardization Applied","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"julia","category":"page"},{"location":"integration/standardized_predictors/#Check-that-standardized-variables-have-expected-properties","page":"StandardizedPredictors.jl","title":"Check that standardized variables have expected properties","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"function validate_standardization(model, data)     # Extract model matrix       X = modelmatrix(model)","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# For standardized columns, mean should ≈ 0, std ≈ 1\nfor i in 2:size(X, 2)  # Skip intercept\n    col_mean = mean(X[:, i])\n    col_std = std(X[:, i])\n    \n    if abs(col_mean) > 1e-10  # Not centered\n        @warn \"Column $i may not be properly standardized\" col_mean col_std\n    end\nend","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"end","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"\n#### Check Override Scales","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"julia function checkoverridescale(data, compiled, expected_range)     output = Vector{Float64}(undef, length(compiled))     compiled(output, data, 1)","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"# Values should be in reasonable range for standardized data\nif any(abs.(output) .> 10)\n    @warn \"Unusually large values detected - check override scale\" extrema(output)\nend","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"end ```","category":"page"},{"location":"integration/standardized_predictors/#Summary","page":"StandardizedPredictors.jl","title":"Summary","text":"","category":"section"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"FormulaCompiler.jl's integration with StandardizedPredictors.jl demonstrates Julia's layered statistical ecosystem:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Schema Layer: StandardizedPredictors.jl transforms data during model fitting\nCompilation Layer: FormulaCompiler.jl generates optimized code for pre-transformed data  \nExecution Layer: Zero-allocation evaluation with full performance guarantees","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"This architecture provides:","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"Correctness: No double-standardization, proper handling of transformations\nPerformance: Zero additional overhead, maintains all speed guarantees  \nFlexibility: Works with any formula complexity and transformation combination\nComposability: Integrates seamlessly with scenarios, derivatives, and advanced features","category":"page"},{"location":"integration/standardized_predictors/","page":"StandardizedPredictors.jl","title":"StandardizedPredictors.jl","text":"The key insight is that each layer performs its function once and performs it well: transformations happen during fitting, optimization happens during compilation, and execution is pure computation.","category":"page"},{"location":"guide/advanced_features/#Advanced-Features","page":"Advanced Features","title":"Advanced Features","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler.jl provides sophisticated capabilities for advanced statistical computing, high-performance applications, and complex analytical workflows. This guide covers memory-efficient scenario analysis, derivative computation, and integration patterns for demanding computational environments.","category":"page"},{"location":"guide/advanced_features/#Counterfactual-Analysis","page":"Advanced Features","title":"Counterfactual Analysis","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler provides efficient counterfactual analysis through high-level APIs designed for user applications. For most use cases, you should use one of the recommended approaches below rather than internal implementation details.","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"warning: Internal vs. Public API\nCounterfactualVector types (NumericCounterfactualVector, BoolCounterfactualVector, etc.) and their constructors are internal implementation details NOT exported from FormulaCompiler. They power the high-level APIs but should not be used directly in application code.Use these high-level APIs instead:Simple contrasts: Direct data modification with merge()\nBatch contrasts: contrastevaluator() + contrast_modelrow!()\nPopulation analysis: Simple loops over rows","category":"page"},{"location":"guide/advanced_features/#Recommended-Approach-#1:-Direct-Data-Modification","page":"Advanced Features","title":"Recommended Approach #1: Direct Data Modification","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"For simple one-off counterfactual analysis, modify data directly:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using FormulaCompiler, GLM, DataFrames, Tables\n\n# Fit model\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    treatment = rand([true, false], 1000)\n)\nmodel = lm(@formula(y ~ x * treatment), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Create counterfactual data scenarios\nn_rows = length(data.treatment)\ndata_treated = merge(data, (treatment = fill(true, n_rows),))\ndata_control = merge(data, (treatment = fill(false, n_rows),))\n\n# Compare outcomes for same individual under different treatments\nrow_vec = Vector{Float64}(undef, length(compiled))\nβ = coef(model)\n\ncompiled(row_vec, data_treated, 1)  # Individual 1 if treated\neffect_treated = dot(β, row_vec)\n\ncompiled(row_vec, data_control, 1)  # Individual 1 if control\neffect_control = dot(β, row_vec)\n\ntreatment_effect = effect_treated - effect_control","category":"page"},{"location":"guide/advanced_features/#Recommended-Approach-#2:-ContrastEvaluator-(Batch-Processing)","page":"Advanced Features","title":"Recommended Approach #2: ContrastEvaluator (Batch Processing)","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"For batch categorical contrasts with zero allocations, use contrastevaluator():","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Create zero-allocation evaluator for categorical contrasts\nevaluator = contrastevaluator(compiled, data, [:treatment])\ncontrast_buf = Vector{Float64}(undef, length(compiled))\n\n# Batch contrasts (zero allocations)\nfor row in 1:100\n    contrast_modelrow!(contrast_buf, evaluator, row, :treatment, false, true)\n    # Process contrast_buf...\nend","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"See \"Categorical Contrasts\" section below for comprehensive examples.","category":"page"},{"location":"guide/advanced_features/#Population-Analysis-with-Loop-Patterns","page":"Advanced Features","title":"Population Analysis with Loop Patterns","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler uses simple loops for population analysis instead of special infrastructure:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using DataFrames, Tables\n\ndf = DataFrame(\n    x = randn(1000),\n    y = randn(1000),\n    treatment = rand(Bool, 1000),\n    group = rand([\"A\", \"B\", \"C\"], 1000)\n)\n\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Population average marginal effects (simple loop)\nfunction compute_population_ame(compiled, data, β, vars)\n    de_fd = derivativeevaluator(:fd, compiled, data, vars)\n    n_rows = length(first(data))\n    ame_sum = zeros(length(vars))\n    g_temp = Vector{Float64}(undef, length(vars))\n\n    for row in 1:n_rows\n        marginal_effects_eta!(g_temp, de_fd, β, row)  # Zero allocations\n        ame_sum .+= g_temp\n    end\n\n    return ame_sum ./ n_rows  # Average marginal effects\nend\n\n# Treatment effect analysis (loop over scenarios)\nfunction treatment_effects(compiled, data, β, treatment_var)\n    n_rows = length(first(data))\n    effects = Vector{Float64}(undef, n_rows)\n    row_vec = Vector{Float64}(undef, length(compiled))\n\n    for row in 1:n_rows\n        # Treatment on\n        data_on = merge(data, (treatment = fill(true, n_rows),))\n        compiled(row_vec, data_on, row)\n        effect_on = dot(β, row_vec)\n\n        # Treatment off\n        data_off = merge(data, (treatment = fill(false, n_rows),))\n        compiled(row_vec, data_off, row)\n        effect_off = dot(β, row_vec)\n\n        effects[row] = effect_on - effect_off\n    end\n\n    return effects\nend","category":"page"},{"location":"guide/advanced_features/#Example:-Treatment-Effect-Analysis","page":"Advanced Features","title":"Example: Treatment Effect Analysis","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Compare the same individual under different treatment assignments:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"model = lm(@formula(y ~ x * treatment + group), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\nβ = coef(model)\n\n# Option 1: Simple data modification (recommended for 1-10 contrasts)\nn_rows = length(first(data))\ndata_treated = merge(data, (treatment = fill(true, n_rows),))\ndata_untreated = merge(data, (treatment = fill(false, n_rows),))\n\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Evaluate individual 1 under both scenarios\ncompiled(row_vec, data_treated, 1)\neffect_treated = dot(β, row_vec)\n\ncompiled(row_vec, data_untreated, 1)\neffect_untreated = dot(β, row_vec)\n\nindividual_treatment_effect = effect_treated - effect_untreated\n\n# Option 2: Zero-allocation batch processing (for 100+ contrasts)\nevaluator = contrastevaluator(compiled, data, [:treatment])\ncontrast_buf = Vector{Float64}(undef, length(compiled))\n\ncontrast_modelrow!(contrast_buf, evaluator, 1, :treatment, false, true)\nindividual_treatment_effect = dot(β, contrast_buf)  # Same result, 0 bytes","category":"page"},{"location":"guide/advanced_features/#Grid-Analysis-with-Loops","page":"Advanced Features","title":"Grid Analysis with Loops","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Use simple loops for comprehensive parameter analysis:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Create comprehensive policy analysis using loops\nfunction evaluate_policy_grid(compiled, data, grid_params, row_idx)\n    treatment_values = [false, true]\n    dose_values = [50.0, 100.0, 150.0]\n    region_values = [\"North\", \"South\", \"East\", \"West\"]\n\n    # Pre-allocate results: 2×3×4 = 24 scenarios\n    n_scenarios = length(treatment_values) * length(dose_values) * length(region_values)\n    results = Matrix{Float64}(undef, n_scenarios, length(compiled))\n    row_vec = Vector{Float64}(undef, length(compiled))\n\n    scenario_idx = 1\n    for treatment in treatment_values\n        for dose in dose_values\n            for region in region_values\n                # Create modified data for this scenario\n                n_rows = length(first(data))\n                scenario_data = merge(data, (\n                    treatment = fill(treatment, n_rows),\n                    dose = fill(dose, n_rows),\n                    region = fill(region, n_rows)\n                ))\n\n                # Evaluate scenario\n                compiled(row_vec, scenario_data, row_idx)\n                results[scenario_idx, :] .= row_vec\n                scenario_idx += 1\n            end\n        end\n    end\n\n    return results\nend\n\n# Usage\nresults = evaluate_policy_grid(compiled, data, grid_params, 1)","category":"page"},{"location":"guide/advanced_features/#Multi-Variable-Counterfactual-Analysis","page":"Advanced Features","title":"Multi-Variable Counterfactual Analysis","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Analyze multiple counterfactual variables simultaneously:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Option 1: Simple approach with data modification\nn_rows = length(first(data))\n\n# Create scenarios with multiple variables modified\nbaseline = data\nscenario_1 = merge(data, (x = fill(2.0, n_rows), treatment = fill(true, n_rows)))\nscenario_2 = merge(data, (x = fill(0.5, n_rows), treatment = fill(false, n_rows)))\n\n# Evaluate same individual under different scenarios\nrow = 5\nrow_vec = Vector{Float64}(undef, length(compiled))\nβ = coef(model)\n\ncompiled(row_vec, baseline, row)\neffect_baseline = dot(β, row_vec)\n\ncompiled(row_vec, scenario_1, row)\neffect_scenario_1 = dot(β, row_vec)\n\ncompiled(row_vec, scenario_2, row)\neffect_scenario_2 = dot(β, row_vec)\n\nprintln(\"Scenario effects: \", effect_scenario_1 - effect_baseline, \", \", effect_scenario_2 - effect_baseline)","category":"page"},{"location":"guide/advanced_features/#Advanced-Compilation-Features","page":"Advanced Features","title":"Advanced Compilation Features","text":"","category":"section"},{"location":"guide/advanced_features/#Introspection-and-Performance","page":"Advanced Features","title":"Introspection and Performance","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Profile compilation performance:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using BenchmarkTools\n\n# Benchmark compilation time\n@benchmark compile_formula($model, $data)","category":"page"},{"location":"guide/advanced_features/#Derivative-Computation-System","page":"Advanced Features","title":"Derivative Computation System","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler provides comprehensive automatic differentiation capabilities for computing Jacobians with dual backend support. For marginal effects, standard errors, and statistical inference, use Margins.jl which builds on these computational primitives.","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Note: Examples in this section use functions from Margins.jl (marginal_effects_eta!, marginal_effects_mu!, delta_method_se). Install Margins.jl to use these examples: using Pkg; Pkg.add(url=\"https://github.com/emfeltham/Margins.jl\")","category":"page"},{"location":"guide/advanced_features/#Performance-Characteristics","page":"Advanced Features","title":"Performance Characteristics","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Core evaluation: Zero allocations (modelrow!, compiled functions)\nBoth derivative backends: Zero allocations (ForwardDiff and finite differences)\nAD backend preferred: Higher accuracy (machine precision) and faster performance\nFD backend alternative: Explicit step size control\nValidation: Cross-validated between backends for robustness","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"note: Backend Selection\nFormulaCompiler provides dual backends for derivative computation, both achieving zero allocations. Use :ad (ForwardDiff) as the default for higher accuracy and performance. Use :fd (finite differences) only when you need explicit control over step sizes.","category":"page"},{"location":"guide/advanced_features/#Derivative-Evaluator-Construction","page":"Advanced Features","title":"Derivative Evaluator Construction","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Build reusable derivative evaluators for efficient computation:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using FormulaCompiler, GLM\n\n# Setup model with mixed variable types\ndf = DataFrame(\n    y = randn(1000),\n    price = randn(1000),          # Float64 continuous\n    quantity = rand(1:100, 1000), # Int64 continuous (auto-converted)\n    available = rand(Bool, 1000), # Bool continuous (true→1.0, false→0.0)\n    region = categorical(rand([\"North\", \"South\"], 1000))  # Categorical\n)\n\nmodel = lm(@formula(y ~ price * region + log(quantity + 1) + available), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Boolean variables are treated as continuous (matching StatsModels behavior)\n# available: true → 1.0, false → 0.0 in model matrix\n# This produces identical results to StatsModels\n\n# Identify continuous variables automatically\ncontinuous_vars = continuous_variables(compiled, data)  # [:price, :quantity]\n\n# Build derivative evaluator (AD backend preferred: zero allocations, higher accuracy)\nde_ad = derivativeevaluator(:ad, compiled, data, continuous_vars)\n# OR build FD evaluator (alternative: zero allocations, explicit step control)\nde_fd = derivativeevaluator(:fd, compiled, data, continuous_vars)","category":"page"},{"location":"guide/advanced_features/#Jacobian-Computation","page":"Advanced Features","title":"Jacobian Computation","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Compute partial derivatives of model matrix rows:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Method 1: Automatic differentiation (zero allocations, higher accuracy - preferred)\nde_ad = derivativeevaluator(:ad, compiled, data, continuous_vars)\nJ_ad = Matrix{Float64}(undef, length(compiled), length(continuous_vars))\nderivative_modelrow!(J_ad, de_ad, 1)\n\n# Method 2: Finite differences (zero allocations, explicit step control - alternative)\nde_fd = derivativeevaluator(:fd, compiled, data, continuous_vars)\nJ_fd = Matrix{Float64}(undef, length(compiled), length(continuous_vars))\nderivative_modelrow!(J_fd, de_fd, 1)\n\n# All methods produce equivalent results\n@assert isapprox(J_ad, J_fd; rtol=1e-6) \"AD and FD should match\"","category":"page"},{"location":"guide/advanced_features/#Marginal-Effects-Computation","page":"Advanced Features","title":"Marginal Effects Computation","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Compute effects on linear predictor and response scales:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using Margins  # Provides marginal_effects_eta!, marginal_effects_mu!\n\nβ = coef(model)\n\n# Effects on linear predictor η = Xβ\ng_eta = Vector{Float64}(undef, length(continuous_vars))\n\n# AD backend: Zero allocations, higher accuracy (preferred)\nde_ad = derivativeevaluator(:ad, compiled, data, continuous_vars)\nmarginal_effects_eta!(g_eta, de_ad, β, 1)\n\n# FD backend: Zero allocations, explicit step control (alternative)\nde_fd = derivativeevaluator(:fd, compiled, data, continuous_vars)\nmarginal_effects_eta!(g_eta, de_fd, β, 1)\n\n# Effects on response scale μ (for GLM models)\nif model isa GLM.GeneralizedLinearModel\n    link_function = GLM.Link(model)\n    g_mu = Vector{Float64}(undef, length(continuous_vars))\n\n    # Using AD evaluator for response scale effects\n    marginal_effects_mu!(g_mu, de_ad, β, 1, link_function)\n\n    println(\"Marginal effects on linear predictor: $g_eta\")\n    println(\"Marginal effects on response scale: $g_mu\")\nend","category":"page"},{"location":"guide/advanced_features/#Categorical-Contrasts","page":"Advanced Features","title":"Categorical Contrasts","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler provides two approaches for computing counterfactual discrete differences: comparing the same observation under different categorical levels, holding all other covariates constant.","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"note: Counterfactual vs Cross-Sectional\nThese methods compute counterfactual effects (same person, different treatment), NOT cross-sectional comparisons (different people with different treatments). This ensures we isolate the treatment effect without confounding from other variables.","category":"page"},{"location":"guide/advanced_features/#Simple-Approach:-Direct-Data-Modification","page":"Advanced Features","title":"Simple Approach: Direct Data Modification","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"For exploratory analysis or one-off contrasts, modify data directly:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Create data with different categorical levels\n# (keeps all other variables at their original values)\nn_rows = length(data.region)\ndata_north = merge(data, (region = fill(\"North\", n_rows),))\ndata_south = merge(data, (region = fill(\"South\", n_rows),))\n\n# Evaluate SAME row with different region assignments\nrow = 1  # Same person/observation\nX_north = modelrow(compiled, data_north, row)  # If they were in North\nX_south = modelrow(compiled, data_south, row)  # If they were in South\nΔ = X_south .- X_north  # Counterfactual difference\n\n# Scalar effect with uncertainty quantification\nβ = coef(model)\neffect = dot(β, Δ)  # Effect of South vs North for person at row 1\n\n# Standard error via delta method\n∇β = Δ  # Parameter gradient (for linear scale)\nvcov_matrix = vcov(model)\nse = sqrt(dot(∇β, vcov_matrix, ∇β))\nci_lower = effect - 1.96 * se\nci_upper = effect + 1.96 * se\n\nprintln(\"Effect: $effect ± $se, 95% CI: [$ci_lower, $ci_upper]\")","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"When to use: Quick checks, 1-10 contrasts, exploratory analysis.","category":"page"},{"location":"guide/advanced_features/#Zero-Allocation-Approach:-ContrastEvaluator","page":"Advanced Features","title":"Zero-Allocation Approach: ContrastEvaluator","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"For batch processing or performance-critical code, use the zero-allocation evaluator:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Create zero-allocation contrast evaluator\nevaluator = contrastevaluator(compiled, data, [:region])\ncontrast_buf = Vector{Float64}(undef, length(compiled))\n\n# Compare categorical levels for specific row\ncontrast_modelrow!(contrast_buf, evaluator, 1, :region, \"North\", \"South\")\ncontrast_north_south = copy(contrast_buf)  # Save result if needed\n\n# Batch contrasts across multiple rows (zero allocations)\nrows_to_analyze = [1, 50, 100, 500]\ncontrasts = Matrix{Float64}(undef, length(rows_to_analyze), length(compiled))\n\nfor (i, row) in enumerate(rows_to_analyze)\n    contrast_modelrow!(contrast_buf, evaluator, row, :region, \"North\", \"South\")\n    contrasts[i, :] .= contrast_buf\nend\n\n# Parameter gradients for uncertainty quantification\nβ = coef(model)\n∇β = Vector{Float64}(undef, length(compiled))\ncontrast_gradient!(∇β, evaluator, 1, :region, \"North\", \"South\", β)\n\n# Delta method standard error\nvcov_matrix = vcov(model)\nse = delta_method_se(evaluator, 1, :region, \"North\", \"South\", β, vcov_matrix)","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"When to use: 100+ contrasts, production pipelines, memory-constrained environments.","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"note: How Categorical Contrasts Work\nFor a detailed explanation of both approaches, including the internal mechanism of ContrastEvaluator and CounterfactualVectors, see How Categorical Contrasts Work.","category":"page"},{"location":"guide/advanced_features/#Advanced-Configuration","page":"Advanced Features","title":"Advanced Configuration","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Optimize derivative computation for specific use cases:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Variable selection strategies\nall_continuous = continuous_variables(compiled, data)\neconomic_vars = [:price, :quantity]  # Domain-specific subset\ninteraction_vars = [:price]          # Focus on key interactions\n\n# Backend selection based on requirements\nfunction compute_derivatives_with_backend_choice(compiled, data, vars, β, row, backend=:ad)\n    de = derivativeevaluator(backend, compiled, data, vars)\n    g = Vector{Float64}(undef, length(vars))\n    marginal_effects_eta!(g, de, β, row)\n    return g\nend","category":"page"},{"location":"guide/advanced_features/#Mixed-Models-(Fixed-Effects)","page":"Advanced Features","title":"Mixed Models (Fixed Effects)","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Derivatives target the fixed-effects design (random effects are intentionally excluded):","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using MixedModels\n\ndf = DataFrame(y = randn(500), x = randn(500), z = abs.(randn(500)) .+ 0.1,\n               group = categorical(rand(1:20, 500)))\nmm = fit(MixedModel, @formula(y ~ 1 + x + z + (1|group)), df; progress=false)\n\ndata = Tables.columntable(df)\ncompiled = compile_formula(mm, data)  # fixed-effects only\nvars = [:x, :z]\nde_fd = derivativeevaluator(:fd, compiled, data, vars)\n\nJ = Matrix{Float64}(undef, length(compiled), length(vars))\nderivative_modelrow!(J, de_fd, 1)","category":"page"},{"location":"guide/advanced_features/#Architecture-and-Optimization","page":"Advanced Features","title":"Architecture and Optimization","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"The derivative system achieves near-zero allocations through:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Preallocated buffers: Jacobian matrices, gradient vectors, and temporary arrays stored in derivativeevaluator\nTyped closures: Compile-time specialization eliminates runtime dispatch\nPrebuilt data structures: Override vectors and merged data reused across calls\nOptimized memory layout: All allocations front-loaded during evaluator construction","category":"page"},{"location":"guide/advanced_features/#Performance-Benchmarking","page":"Advanced Features","title":"Performance Benchmarking","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using BenchmarkTools\n\n# Build evaluators once (one-time cost)\nde_ad = derivativeevaluator(:ad, compiled, data, [:x, :z])  # Zero allocations, higher accuracy (preferred)\nde_fd = derivativeevaluator(:fd, compiled, data, [:x, :z])  # Zero allocations, explicit step control (alternative)\nJ = Matrix{Float64}(undef, length(compiled), length(de_ad.vars))\n\n# Benchmark derivatives\n@benchmark derivative_modelrow!($J, $de_ad, 25)  # AD (faster)\n@benchmark derivative_modelrow!($J, $de_fd, 25)  # FD\n\n# Benchmark marginal effects\nβ = coef(model)\ng = Vector{Float64}(undef, length(de_ad.vars))\n@benchmark marginal_effects_eta!($g, $de_ad, $β, 25)  # AD (faster, more accurate)\n@benchmark marginal_effects_eta!($g, $de_fd, $β, 25)  # FD","category":"page"},{"location":"guide/advanced_features/#Complex-Formula-Support","page":"Advanced Features","title":"Complex Formula Support","text":"","category":"section"},{"location":"guide/advanced_features/#Nested-Functions","page":"Advanced Features","title":"Nested Functions","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler.jl handles complex nested functions:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"@formula(y ~ log(sqrt(abs(x))) + exp(sin(z)) * group)","category":"page"},{"location":"guide/advanced_features/#Boolean-Logic","page":"Advanced Features","title":"Boolean Logic","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Sophisticated boolean expressions:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"@formula(y ~ (x > 0) * (z < mean(z)) + (group == \"A\") * log(w))","category":"page"},{"location":"guide/advanced_features/#Custom-Functions","page":"Advanced Features","title":"Custom Functions","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Define custom functions for use in formulas:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Define custom function\ncustom_transform(x) = x > 0 ? log(1 + x) : -log(1 - x)\n\n# Use in formula (requires function to be defined in scope)\n@formula(y ~ custom_transform(x) + group)","category":"page"},{"location":"guide/advanced_features/#Categorical-Mixtures","page":"Advanced Features","title":"Categorical Mixtures","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler.jl supports categorical mixtures for marginal effects computation:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"# Create data with weighted categorical specifications\ndf = DataFrame(\n    x = [1.0, 2.0, 3.0],\n    group = [mix(\"A\" => 0.3, \"B\" => 0.7),   # 30% A, 70% B\n             mix(\"A\" => 0.3, \"B\" => 0.7),\n             mix(\"A\" => 0.3, \"B\" => 0.7)]\n)\n\n# Compile and evaluate with zero allocations\ncompiled = compile_formula(model, Tables.columntable(df))\ncompiled(output, Tables.columntable(df), 1)  # Zero allocations; time varies by hardware","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"For comprehensive coverage of categorical mixtures including validation, helper functions, and marginal effects integration, see the Categorical Mixtures guide.","category":"page"},{"location":"guide/advanced_features/#High-Performance-Computing-Patterns","page":"Advanced Features","title":"High-Performance Computing Patterns","text":"","category":"section"},{"location":"guide/advanced_features/#Zero-Allocation-Computational-Loops","page":"Advanced Features","title":"Zero-Allocation Computational Loops","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Design computational patterns that maintain zero-allocation performance:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"function monte_carlo_predictions(model, data, n_simulations=10000)\n    # Pre-compile and pre-allocate all necessary buffers\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    β = coef(model)\n    \n    # Pre-allocate result storage\n    predictions = Vector{Float64}(undef, n_simulations)\n    data_size = length(first(data))\n    \n    # Zero-allocation simulation loop\n    for sim in 1:n_simulations\n        # Random row selection\n        row_idx = rand(1:data_size)\n        \n        # Zero-allocation model matrix evaluation\n        compiled(row_vec, data, row_idx)\n        \n        # Zero-allocation prediction computation\n        predictions[sim] = dot(β, row_vec)\n    end\n    \n    return predictions\nend\n\n# Usage with performance validation\npredictions = monte_carlo_predictions(model, data, 100000)","category":"page"},{"location":"guide/advanced_features/#Advanced-Memory-Management","page":"Advanced Features","title":"Advanced Memory Management","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Optimize memory usage for large-scale applications:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"function memory_efficient_batch_processing(model, large_dataset, batch_size=1000)\n    compiled = compile_formula(model, large_dataset)\n    n_total = length(first(large_dataset))\n    n_batches = cld(n_total, batch_size)\n    \n    # Pre-allocate reusable buffers\n    row_vec = Vector{Float64}(undef, length(compiled))\n    batch_results = Matrix{Float64}(undef, batch_size, length(compiled))\n    \n    all_results = Vector{Matrix{Float64}}()\n    \n    for batch in 1:n_batches\n        start_idx = (batch - 1) * batch_size + 1\n        end_idx = min(batch * batch_size, n_total)\n        actual_batch_size = end_idx - start_idx + 1\n        \n        # Resize for last batch if needed\n        if actual_batch_size != batch_size\n            batch_results = Matrix{Float64}(undef, actual_batch_size, length(compiled))\n        end\n        \n        # Zero-allocation batch evaluation\n        for (local_idx, global_idx) in enumerate(start_idx:end_idx)\n            compiled(view(batch_results, local_idx, :), large_dataset, global_idx)\n        end\n        \n        # Store results (could write to disk here for very large datasets)\n        push!(all_results, copy(batch_results))\n    end\n    \n    return all_results\nend","category":"page"},{"location":"guide/advanced_features/#Batch-Processing-Large-Datasets","page":"Advanced Features","title":"Batch Processing Large Datasets","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"function process_large_dataset(model, data, batch_size=1000)\n    compiled = compile_formula(model, data)\n    n_rows = Tables.rowcount(data)\n    n_cols = length(compiled)\n    \n    results = Vector{Matrix{Float64}}()\n    \n    for start_idx in 1:batch_size:n_rows\n        end_idx = min(start_idx + batch_size - 1, n_rows)\n        batch_size_actual = end_idx - start_idx + 1\n\n        batch_result = Matrix{Float64}(undef, batch_size_actual, n_cols)\n\n        # Evaluate each row in the batch\n        for (batch_idx, data_idx) in enumerate(start_idx:end_idx)\n            compiled(view(batch_result, batch_idx, :), data, data_idx)\n        end\n\n        push!(results, batch_result)\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/advanced_features/#Parallel-Processing","page":"Advanced Features","title":"Parallel Processing","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Combine with Julia's parallel processing capabilities:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using Distributed\n\n@everywhere using FormulaCompiler, DataFrames, Tables\n\nfunction parallel_evaluation(model, data, row_indices)\n    compiled = compile_formula(model, data)\n    \n    results = @distributed (vcat) for row_idx in row_indices\n        row_vec = Vector{Float64}(undef, length(compiled))\n        compiled(row_vec, data, row_idx)\n        row_vec'  # Return as row matrix\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/advanced_features/#Integration-with-Optimization","page":"Advanced Features","title":"Integration with Optimization","text":"","category":"section"},{"location":"guide/advanced_features/#Gradient-Based-Optimization","page":"Advanced Features","title":"Gradient-Based Optimization","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"FormulaCompiler.jl works well with automatic differentiation:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using ForwardDiff\n\nfunction objective_function(params, compiled_formula, data, target)\n    # Update data with new parameters\n    modified_data = (; data..., x = params[1], z = params[2])\n    \n    row_vec = Vector{Float64}(undef, length(compiled_formula))\n    compiled_formula(row_vec, modified_data, 1)\n    \n    # Compute loss\n    return sum((row_vec .- target).^2)\nend\n\n# Use with ForwardDiff for gradients\ncompiled = compile_formula(model, data)\ntarget = [1.0, 2.0, 3.0, 4.0]  # Target model matrix row\n\ngradient = ForwardDiff.gradient(\n    params -> objective_function(params, compiled, data, target),\n    [0.0, 1.0]  # Initial parameters\n)","category":"page"},{"location":"guide/advanced_features/#Bayesian-Analysis-Integration","page":"Advanced Features","title":"Bayesian Analysis Integration","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Efficient model evaluation in MCMC samplers:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using MCMCChains\n\nfunction log_likelihood(params, compiled_formula, data, y_observed)\n    # Extract parameters\n    β = params[1:length(compiled_formula)]\n    σ = exp(params[end])  # Log-scale for positivity\n    \n    n_obs = length(y_observed)\n    row_vec = Vector{Float64}(undef, length(compiled_formula))\n    \n    ll = 0.0\n    for i in 1:n_obs\n        compiled_formula(row_vec, data, i)\n        μ = dot(β, row_vec)\n        ll += logpdf(Normal(μ, σ), y_observed[i])\n    end\n    \n    return ll\nend\n\n# Use in MCMC sampler (pseudocode)\n# sampler = MCMCSampler(log_likelihood, compiled, data, y)","category":"page"},{"location":"guide/advanced_features/#Memory-and-Performance-Monitoring","page":"Advanced Features","title":"Memory and Performance Monitoring","text":"","category":"section"},{"location":"guide/advanced_features/#Allocation-Tracking","page":"Advanced Features","title":"Allocation Tracking","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Monitor allocation performance:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using BenchmarkTools\n\nfunction check_allocations(compiled, data, n_tests=1000)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Warm up\n    compiled(row_vec, data, 1)\n    \n    # Benchmark\n    result = @benchmark begin\n        for i in 1:$n_tests\n            $compiled($row_vec, $data, i % nrow($data) + 1)\n        end\n    end\n    \n    return result\nend\n\n# Should show 0 allocations\nbenchmark_result = check_allocations(compiled, data)","category":"page"},{"location":"guide/advanced_features/#Memory-Usage-Analysis","page":"Advanced Features","title":"Memory Usage Analysis","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"using Profile\n\nfunction profile_memory_usage(model, data, n_evaluations=10000)\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Profile memory\n    Profile.clear_malloc_data()\n    \n    for i in 1:n_evaluations\n        compiled(row_vec, data, i % length(first(data)) + 1)\n    end\n    \n    # Analyze results\n    # (Use ProfileView.jl or similar for visualization)\nend","category":"page"},{"location":"guide/advanced_features/#Real-World-Application-Patterns","page":"Advanced Features","title":"Real-World Application Patterns","text":"","category":"section"},{"location":"guide/advanced_features/#Economic-Policy-Analysis","page":"Advanced Features","title":"Economic Policy Analysis","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Combine scenario analysis with derivative computation for comprehensive policy evaluation:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"function policy_impact_analysis(baseline_model, policy_data, policy_parameters)\n    # Compile baseline model\n    compiled = compile_formula(baseline_model, policy_data)\n    β = coef(baseline_model)\n    \n    # Identify continuous policy levers\n    policy_vars = intersect(keys(policy_parameters), continuous_variables(compiled, policy_data))\n    de_fd = derivativeevaluator(:fd, compiled, policy_data, collect(policy_vars))\n    \n    # Create policy scenarios using data modification\n    scenarios = [\n        (\"status_quo\", policy_data),\n        (\"moderate_policy\", merge(policy_data, policy_parameters)),\n        (\"aggressive_policy\", merge(policy_data,\n                       [k => fill(v * 1.5, length(first(policy_data))) for (k, v) in policy_parameters]))\n    ]\n    \n    # Evaluate policy impacts\n    n_individuals = min(1000, length(first(policy_data)))  # Sample for analysis\n    \n    results = Dict()\n    for (scenario_name, scenario_data) in scenarios\n        scenario_predictions = Vector{Float64}(undef, n_individuals)\n        scenario_marginals = Matrix{Float64}(undef, n_individuals, length(policy_vars))\n\n        # Evaluate predictions and marginal effects for each individual\n        row_vec = Vector{Float64}(undef, length(compiled))\n        marginal_vec = Vector{Float64}(undef, length(policy_vars))\n\n        for i in 1:n_individuals\n            # Prediction\n            compiled(row_vec, scenario_data, i)\n            scenario_predictions[i] = dot(β, row_vec)\n\n            # Marginal effects\n            marginal_effects_eta!(marginal_vec, de_fd, β, i)  # Zero allocations\n            scenario_marginals[i, :] .= marginal_vec\n        end\n\n        results[scenario_name] = (\n            predictions = scenario_predictions,\n            marginal_effects = scenario_marginals,\n            mean_prediction = mean(scenario_predictions),\n            policy_sensitivity = mean(scenario_marginals, dims=1)\n        )\n    end\n    \n    return results\nend\n\n# Example usage\npolicy_params = Dict(:minimum_wage => 15.0, :tax_rate => 0.25)\nanalysis_results = policy_impact_analysis(economic_model, economic_data, policy_params)\n\n# Compare scenarios\nstatus_quo_mean = analysis_results[\"status_quo\"].mean_prediction\nmoderate_mean = analysis_results[\"moderate_policy\"].mean_prediction\npolicy_effect = moderate_mean - status_quo_mean\n\nprintln(\"Policy effect: $(round(policy_effect, digits=3))\")","category":"page"},{"location":"guide/advanced_features/#Biostatistical-Applications","page":"Advanced Features","title":"Biostatistical Applications","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"High-throughput analysis for medical and biological research:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"function biomarker_analysis(survival_model, patient_data, biomarker_ranges)\n    compiled = compile_formula(survival_model, patient_data)\n    β = coef(survival_model)\n    \n    # Identify biomarker variables for sensitivity analysis\n    biomarker_vars = Symbol.(keys(biomarker_ranges))\n    continuous_biomarkers = intersect(biomarker_vars, continuous_variables(compiled, patient_data))\n\n    if !isempty(continuous_biomarkers)\n        de_fd = derivativeevaluator(:fd, compiled, patient_data, continuous_biomarkers)\n    end\n    \n    # Create biomarker scenarios using loops\n    biomarker_combinations = Iterators.product(values(biomarker_ranges)...)\n    biomarker_scenarios = [(\"scenario_$i\", merge(patient_data,\n        Dict(zip(keys(biomarker_ranges), [fill(val, length(first(patient_data))) for val in combo])))\n    ) for (i, combo) in enumerate(biomarker_combinations)]\n    \n    # Patient risk stratification\n    n_patients = length(first(patient_data))\n    risk_matrix = Matrix{Float64}(undef, length(biomarker_scenarios), n_patients)\n    \n    # Pre-allocate evaluation buffers\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Evaluate all scenario-patient combinations\n    for (scenario_idx, (scenario_name, scenario_data)) in enumerate(biomarker_scenarios)\n        for patient_idx in 1:n_patients\n            compiled(row_vec, scenario_data, patient_idx)\n            \n            # Compute risk score (example: linear predictor)\n            risk_score = dot(β, row_vec)\n            risk_matrix[scenario_idx, patient_idx] = risk_score\n        end\n    end\n    \n    # Compute marginal effects for sensitivity analysis\n    if !isempty(continuous_biomarkers)\n        marginal_matrix = Matrix{Float64}(undef, n_patients, length(continuous_biomarkers))\n        marginal_vec = Vector{Float64}(undef, length(continuous_biomarkers))\n        \n        for patient_idx in 1:n_patients\n            marginal_effects_eta!(marginal_vec, de_fd, β, patient_idx)\n            marginal_matrix[patient_idx, :] .= marginal_vec\n        end\n        \n        return (\n            risk_scores = risk_matrix,\n            marginal_effects = marginal_matrix,\n            scenarios = [name for (name, _) in biomarker_scenarios],\n            biomarker_vars = continuous_biomarkers\n        )\n    else\n        return (\n            risk_scores = risk_matrix,\n            scenarios = biomarker_scenarios\n        )\n    end\nend\n\n# Example usage\nbiomarker_ranges = Dict(\n    :tumor_size => [1.0, 2.0, 3.0, 4.0],     # cm\n    :psa_level => [4.0, 10.0, 20.0],         # ng/mL\n    :age => [50, 65, 80]                     # years\n)\n\nbio_results = biomarker_analysis(oncology_model, patient_data, biomarker_ranges)","category":"page"},{"location":"guide/advanced_features/#Financial-Risk-Modeling","page":"Advanced Features","title":"Financial Risk Modeling","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Scenario analysis for financial applications:","category":"page"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"function portfolio_risk_analysis(risk_model, market_data, stress_scenarios)\n    compiled = compile_formula(risk_model, market_data)\n    β = coef(risk_model)\n    \n    # Risk factor sensitivity\n    risk_factors = continuous_variables(compiled, market_data)\n    if !isempty(risk_factors)\n        de_fd = derivativeevaluator(:fd, compiled, market_data, risk_factors)\n    end\n    \n    # Create market stress scenarios using data modification\n    stress_scenario_objects = [\n        (name, merge(market_data,\n            Dict(k => fill(v, length(first(market_data))) for (k, v) in parameters)))\n        for (name, parameters) in stress_scenarios\n    ]\n    \n    # Portfolio evaluation across scenarios\n    n_assets = length(first(market_data))\n    scenario_valuations = Dict{String, Vector{Float64}}()\n    \n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    for (scenario_name, scenario_data) in stress_scenario_objects\n        asset_valuations = Vector{Float64}(undef, n_assets)\n\n        for asset_idx in 1:n_assets\n            compiled(row_vec, scenario_data, asset_idx)\n            # Risk-adjusted valuation\n            asset_valuations[asset_idx] = dot(β, row_vec)\n        end\n\n        scenario_valuations[scenario_name] = asset_valuations\n    end\n    \n    # Risk sensitivity analysis\n    if !isempty(risk_factors)\n        sensitivity_matrix = Matrix{Float64}(undef, n_assets, length(risk_factors))\n        sensitivity_vec = Vector{Float64}(undef, length(risk_factors))\n        \n        for asset_idx in 1:n_assets\n            marginal_effects_eta!(sensitivity_vec, de_fd, β, asset_idx)\n            sensitivity_matrix[asset_idx, :] .= sensitivity_vec\n        end\n        \n        return (\n            scenario_valuations = scenario_valuations,\n            risk_sensitivities = sensitivity_matrix,\n            risk_factors = risk_factors\n        )\n    else\n        return (scenario_valuations = scenario_valuations,)\n    end\nend\n\n# Example usage\nstress_scenarios = [\n    (\"market_crash\", Dict(:market_volatility => 0.4, :interest_rate => 0.02)),\n    (\"inflation_shock\", Dict(:inflation_rate => 0.08, :commodity_index => 1.5)),\n    (\"recession\", Dict(:gdp_growth => -0.03, :unemployment => 0.12))\n]\n\nrisk_analysis = portfolio_risk_analysis(financial_model, market_data, stress_scenarios)\n\n# Analyze results\nbaseline_value = sum(risk_analysis.scenario_valuations[\"baseline\"])\ncrash_value = sum(risk_analysis.scenario_valuations[\"market_crash\"])\nportfolio_risk = (crash_value - baseline_value) / baseline_value\n\nprintln(\"Portfolio stress loss: $(round(portfolio_risk * 100, digits=2))%\")","category":"page"},{"location":"guide/advanced_features/#Further-Reading","page":"Advanced Features","title":"Further Reading","text":"","category":"section"},{"location":"guide/advanced_features/","page":"Advanced Features","title":"Advanced Features","text":"Categorical Contrasts Guide - Detailed coverage of categorical contrasts and mixtures\nPerformance Guide - Detailed optimization strategies and benchmarking\nAPI Reference - Complete function documentation","category":"page"},{"location":"internals/contrast_mechanism/#How-Categorical-Contrasts-Work","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"This document explains the internal architecture and mechanism of categorical contrast computation in FormulaCompiler.jl, showing how the ContrastEvaluator achieves zero-allocation performance through the CounterfactualVector system.","category":"page"},{"location":"internals/contrast_mechanism/#Table-of-Contents","page":"How Categorical Contrasts Work","title":"Table of Contents","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Overview\nSimple Approach: Direct Data Modification\nCounterfactualVector Mechanism\nContrastEvaluator Initialization\nContrast Computation Flow\nGradient Computation\nPerformance Characteristics\nAdvanced Topics","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Overview","page":"How Categorical Contrasts Work","title":"Overview","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Categorical contrasts compute counterfactual discrete differences: comparing the same observation under different categorical levels.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# For a specific individual/observation at row i\nΔ = X(row=i, treatment=\"Drug\") - X(row=i, treatment=\"Control\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"This answers: \"What would be the treatment effect for this specific individual, holding all other characteristics constant?\"","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Important: This is NOT comparing two different observations that happen to have different treatment levels (which would confound treatment effects with individual differences).","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"FormulaCompiler provides two approaches for computing these counterfactual contrasts:","category":"page"},{"location":"internals/contrast_mechanism/#1.-Simple-Approach:-Direct-Data-Modification","page":"How Categorical Contrasts Work","title":"1. Simple Approach: Direct Data Modification","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For simple cases, you can modify data directly and compute differences:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Evaluate with different categorical levels\ndata_control = merge(data, (treatment = fill(\"Control\", n_rows),))\ndata_drug = merge(data, (treatment = fill(\"Drug\", n_rows),))\n\nX_control = modelrow(compiled, data_control, row)\nX_drug = modelrow(compiled, data_drug, row)\nΔ = X_drug - X_control","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Pros: Simple, straightforward, no special APIs Cons: Allocates new data structures, not suitable for batch processing","category":"page"},{"location":"internals/contrast_mechanism/#2.-Zero-Allocation-Approach:-ContrastEvaluator-CounterfactualVectors","page":"How Categorical Contrasts Work","title":"2. Zero-Allocation Approach: ContrastEvaluator + CounterfactualVectors","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For performance-critical batch operations, use the zero-allocation system:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"evaluator = contrastevaluator(compiled, data, [:treatment])\nΔ = Vector{Float64}(undef, length(compiled))\ncontrast_modelrow!(Δ, evaluator, row, :treatment, \"Control\", \"Drug\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Pros: Zero allocations, optimized for batch processing Cons: More setup, requires understanding of evaluator pattern","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The rest of this document focuses on Approach 2 (the zero-allocation system).","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Simple-Approach:-Direct-Data-Modification","page":"How Categorical Contrasts Work","title":"Simple Approach: Direct Data Modification","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For exploratory analysis, one-off contrasts, or when performance isn't critical, you can compute contrasts by directly modifying data and evaluating the compiled formula twice.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"warning: Analytical Distinction: Counterfactual vs Cross-Sectional Contrasts\nThis approach computes counterfactual contrasts: comparing the same observation under different categorical levels. This is fundamentally different from comparing two different observations that happen to have different levels.Counterfactual (what we're doing here):# Same person (row 5), different treatments\nX_row5_if_control = modelrow(compiled, data_control, 5)\nX_row5_if_drug = modelrow(compiled, data_drug, 5)\nΔ_counterfactual = X_row5_if_drug - X_row5_if_controlThis answers: \"What would be the effect if this person received Drug instead of Control?\"Cross-sectional (NOT what we're doing):# Different people, different treatments\nX_person_in_control = modelrow(compiled, data, row_a)  # Person A (in Control)\nX_person_in_drug = modelrow(compiled, data, row_b)     # Person B (in Drug)\nΔ_cross_sectional = X_person_in_drug - X_person_in_controlThis confounds treatment effect with individual differences!","category":"page"},{"location":"internals/contrast_mechanism/#Basic-Pattern","page":"How Categorical Contrasts Work","title":"Basic Pattern","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"using FormulaCompiler, GLM, DataFrames, Tables\n\n# Fit model and compile\ndf = DataFrame(\n    y = randn(100),\n    x = randn(100),\n    treatment = rand([\"Control\", \"Drug_A\", \"Drug_B\"], 100)\n)\nmodel = lm(@formula(y ~ x * treatment), df)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Choose a row to analyze\nrow = 1\n\n# Create modified data with different treatment levels\nn_rows = length(data.y)\ndata_control = merge(data, (treatment = fill(\"Control\", n_rows),))\ndata_drug = merge(data, (treatment = fill(\"Drug_A\", n_rows),))\n\n# Evaluate model rows with different levels\nX_control = modelrow(compiled, data_control, row)\nX_drug = modelrow(compiled, data_drug, row)\n\n# Compute contrast\nΔ = X_drug .- X_control\n\n# Compute effect and standard error\nβ = coef(model)\neffect = dot(β, Δ)\n\n# Gradient for uncertainty quantification (linear scale)\n∇β = Δ  # Parameter gradient: ∂(effect)/∂β = Δ\nvcov_matrix = vcov(model)\nse = sqrt(dot(∇β, vcov_matrix, ∇β))\n\nprintln(\"Treatment effect: $effect ± $se\")","category":"page"},{"location":"internals/contrast_mechanism/#What-This-Does","page":"How Categorical Contrasts Work","title":"What This Does","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"merge(data, (treatment = fill(\"Control\", n_rows),))\nCreates a new NamedTuple with all columns from data\nReplaces the :treatment column with a vector of all \"Control\" values\nCrucially: Keeps all other covariates (x, age, etc.) at their original values for each row\nMemory: Allocates new vector for treatment column (~100 bytes for 100 rows)\nmodelrow(compiled, data_control, row)\nEvaluates the compiled formula for row 1 using data_control\nReturns the model matrix row X for the same individual (row 1) as if they had treatment=\"Control\"\nAll other characteristics (x, age, etc.) remain as observed for row 1\nMemory: Allocates new output vector (~80 bytes for typical model)\nX_drug .- X_control\nElement-wise subtraction: the discrete effect vector\nShows the treatment effect for this specific individual with their specific covariate values\nHolds everything else constant (ceteris paribus)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Key insight: Both X_control and X_drug are evaluated for the same row (same person/observation), just with different treatment assignments. This is a counterfactual comparison, not a comparison across different observations.","category":"page"},{"location":"internals/contrast_mechanism/#Why-Counterfactual-Contrasts-Matter","page":"How Categorical Contrasts Work","title":"Why Counterfactual Contrasts Matter","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The counterfactual approach isolates the treatment effect by holding all other variables constant:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Example: Effect for a 45-year-old with specific characteristics\nrow = 15  # Person with: age=45, x=2.3, education=\"College\"\n\n# Counterfactual contrast: Same person, different treatment\nX_if_control = modelrow(compiled, data_control, 15)  # This person AS IF Control\nX_if_drug = modelrow(compiled, data_drug, 15)        # This person AS IF Drug\nΔ_counterfactual = X_if_drug - X_if_control\n\n# Result: Pure treatment effect for THIS SPECIFIC person\n# Holds constant: age=45, x=2.3, education=\"College\"\neffect = dot(β, Δ_counterfactual)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Interpretation: \"If this 45-year-old college graduate with x=2.3 received Drug instead of Control, the predicted outcome would change by effect.\"","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Contrast with cross-sectional comparison (wrong approach):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Find someone in Control and someone in Drug\nrow_control = findfirst(data.treatment .== \"Control\")  # Person A: age=45, x=2.3\nrow_drug = findfirst(data.treatment .== \"Drug\")        # Person B: age=60, x=-1.5\n\nX_person_control = modelrow(compiled, data, row_control)\nX_person_drug = modelrow(compiled, data, row_drug)\nΔ_wrong = X_person_drug - X_person_control\n\n# PROBLEM: This confounds treatment with age difference (60 vs 45)\n# and x difference (-1.5 vs 2.3)!","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Why this matters for marginal effects:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Discrete marginal effects measure ceteris paribus changes (holding everything else constant)\nCounterfactual contrasts implement this mathematically\nThis is the standard definition in econometrics and causal inference","category":"page"},{"location":"internals/contrast_mechanism/#Computing-Scalar-Effects-and-Gradients","page":"How Categorical Contrasts Work","title":"Computing Scalar Effects and Gradients","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"To get a scalar treatment effect, multiply by coefficients. For uncertainty quantification, also compute the parameter gradient:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"β = coef(model)\n\n# Discrete effect on linear predictor (η scale)\neffect_eta = dot(β, Δ)\n\n# Parameter gradient for linear scale (needed for standard errors)\n# For linear scale, the gradient IS the contrast vector\n∇β_eta = Δ  # ∂(effect_eta)/∂β = Δ\n\n# Standard error via delta method\nvcov_matrix = vcov(model)\nse_eta = sqrt(dot(∇β_eta, vcov_matrix, ∇β_eta))\n\n# Confidence interval\nci_lower_eta = effect_eta - 1.96 * se_eta\nci_upper_eta = effect_eta + 1.96 * se_eta\n\nprintln(\"Linear scale effect: $effect_eta ± $se_eta\")\nprintln(\"95% CI: [$ci_lower_eta, $ci_upper_eta]\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Response scale (for GLM models with link functions):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"using GLM\n\n# Compute linear predictors\nη_control = dot(β, X_control)\nη_drug = dot(β, X_drug)\n\n# Apply link function\nlink = GLM.LogitLink()  # Example: logistic regression\nμ_control = GLM.linkinv(link, η_control)\nμ_drug = GLM.linkinv(link, η_drug)\n\n# Discrete effect on response scale\neffect_mu = μ_drug - μ_control\n\n# Parameter gradient for response scale (chain rule)\n# ∇β = g'(η_drug) × X_drug - g'(η_control) × X_control\ng_prime_control = GLM.mueta(link, η_control)  # dμ/dη at control\ng_prime_drug = GLM.mueta(link, η_drug)        # dμ/dη at drug\n∇β_mu = g_prime_drug .* X_drug .- g_prime_control .* X_control\n\n# Standard error via delta method\nse_mu = sqrt(dot(∇β_mu, vcov_matrix, ∇β_mu))\n\n# Confidence interval\nci_lower_mu = effect_mu - 1.96 * se_mu\nci_upper_mu = effect_mu + 1.96 * se_mu\n\nprintln(\"Response scale effect: $effect_mu ± $se_mu\")\nprintln(\"95% CI: [$ci_lower_mu, $ci_upper_mu]\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Why gradients matter:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Enable uncertainty quantification (standard errors, confidence intervals)\nEssential for hypothesis testing\nRequired for proper statistical inference\nDelta method: SE = √(∇β' Σ ∇β) where Σ is the covariance matrix","category":"page"},{"location":"internals/contrast_mechanism/#Multiple-Rows-or-Levels","page":"How Categorical Contrasts Work","title":"Multiple Rows or Levels","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For multiple comparisons, use loops and include gradients for inference:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Compare all levels to reference (with uncertainty)\nreference_level = \"Control\"\nother_levels = [\"Drug_A\", \"Drug_B\"]\n\nfor level in other_levels\n    data_level = merge(data, (treatment = fill(level, n_rows),))\n    X_level = modelrow(compiled, data_level, row)\n    X_ref = modelrow(compiled, data_control, row)\n\n    Δ = X_level .- X_ref\n    effect = dot(β, Δ)\n\n    # Gradient and standard error\n    ∇β = Δ  # For linear scale\n    se = sqrt(dot(∇β, vcov_matrix, ∇β))\n\n    println(\"Effect of $level vs $reference_level: $effect ± $se\")\nend\n\n# Analyze multiple rows (with confidence intervals)\nrows_of_interest = [1, 10, 50]\nfor row in rows_of_interest\n    X_control_row = modelrow(compiled, data_control, row)\n    X_drug_row = modelrow(compiled, data_drug, row)\n    Δ_row = X_drug_row .- X_control_row\n\n    effect_row = dot(β, Δ_row)\n    se_row = sqrt(dot(Δ_row, vcov_matrix, Δ_row))\n    ci_lower = effect_row - 1.96 * se_row\n    ci_upper = effect_row + 1.96 * se_row\n\n    println(\"Row $row effect: $effect_row, 95% CI: [$ci_lower, $ci_upper]\")\nend","category":"page"},{"location":"internals/contrast_mechanism/#When-to-Use-This-Approach","page":"How Categorical Contrasts Work","title":"When to Use This Approach","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Good for:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Exploratory analysis (quick checks, prototyping)\nOne-off comparisons (single contrasts)\nSimple scripts where performance isn't critical\nTeaching/learning (simpler to understand)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Not ideal for:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Batch processing (computing 1000+ contrasts)\nPerformance-critical code (allocations add up)\nProduction pipelines (want zero-allocation guarantees)","category":"page"},{"location":"internals/contrast_mechanism/#Memory-Cost-Analysis","page":"How Categorical Contrasts Work","title":"Memory Cost Analysis","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For a dataset with 1000 rows and a typical model:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Per contrast computed:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"New treatment vector: ~8KB (1000 × Float64)\nModel row output: ~80 bytes (typical)\nIntermediate allocations: ~100 bytes\nTotal per contrast: ~8.2KB","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For 1000 contrasts: ~8.2MB allocated","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Compare to ContrastEvaluator: 0 bytes per contrast after setup.","category":"page"},{"location":"internals/contrast_mechanism/#Integration-with-Existing-Data-Workflows","page":"How Categorical Contrasts Work","title":"Integration with Existing Data Workflows","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"This approach works naturally with DataFrames manipulation:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"using DataFrames, Chain\n\n# Create counterfactual datasets using DataFrames operations\ndf_control = @chain df begin\n    transform(:treatment => (_ -> \"Control\") => :treatment)\nend\n\ndf_drug = @chain df begin\n    transform(:treatment => (_ -> \"Drug_A\") => :treatment)\nend\n\n# Convert to columntables and evaluate\ndata_control = Tables.columntable(df_control)\ndata_drug = Tables.columntable(df_drug)\n\nX_control = modelrow(compiled, data_control, row)\nX_drug = modelrow(compiled, data_drug, row)\nΔ = X_drug .- X_control","category":"page"},{"location":"internals/contrast_mechanism/#Complete-Example:-Logistic-Regression-with-Uncertainty","page":"How Categorical Contrasts Work","title":"Complete Example: Logistic Regression with Uncertainty","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For GLM models with link functions, compute both linear and response scale effects:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"using GLM, DataFrames, Tables\n\n# Fit logistic regression\ndf = DataFrame(\n    outcome = rand([0, 1], 100),\n    age = rand(18:80, 100),\n    treatment = rand([\"Control\", \"Drug\"], 100)\n)\nmodel = glm(@formula(outcome ~ age * treatment), df, Binomial(), LogitLink())\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\n\n# Counterfactual data\nn_rows = length(data.outcome)\ndata_control = merge(data, (treatment = fill(\"Control\", n_rows),))\ndata_drug = merge(data, (treatment = fill(\"Drug\", n_rows),))\n\n# Analyze specific individual\nrow = 1\nβ = coef(model)\nvcov_matrix = vcov(model)\nlink = LogitLink()\n\n# Evaluate model rows\nX_control = modelrow(compiled, data_control, row)\nX_drug = modelrow(compiled, data_drug, row)\nΔ = X_drug .- X_control\n\n# Linear scale (log-odds) with uncertainty\neffect_eta = dot(β, Δ)\n∇β_eta = Δ\nse_eta = sqrt(dot(∇β_eta, vcov_matrix, ∇β_eta))\nprintln(\"Log-odds effect: $effect_eta ± $se_eta\")\n\n# Response scale (probability) with uncertainty\nη_control = dot(β, X_control)\nη_drug = dot(β, X_drug)\nμ_control = GLM.linkinv(link, η_control)  # Probability if Control\nμ_drug = GLM.linkinv(link, η_drug)        # Probability if Drug\neffect_mu = μ_drug - μ_control\n\n# Gradient for response scale (chain rule)\ng_prime_control = GLM.mueta(link, η_control)\ng_prime_drug = GLM.mueta(link, η_drug)\n∇β_mu = g_prime_drug .* X_drug .- g_prime_control .* X_control\nse_mu = sqrt(dot(∇β_mu, vcov_matrix, ∇β_mu))\n\nprintln(\"Probability effect: $effect_mu ± $se_mu\")\nprintln(\"  P(outcome=1|Control) = $μ_control\")\nprintln(\"  P(outcome=1|Drug) = $μ_drug\")","category":"page"},{"location":"internals/contrast_mechanism/#Alternative:-Using-Dictionaries","page":"How Categorical Contrasts Work","title":"Alternative: Using Dictionaries","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For ad-hoc modifications without merge:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Create modified data manually\ndata_control = (\n    x = data.x,\n    y = data.y,\n    treatment = fill(\"Control\", length(data.y))  # Override one column\n)\n\ndata_drug = (\n    x = data.x,\n    y = data.y,\n    treatment = fill(\"Drug_A\", length(data.y))\n)\n\nX_control = modelrow(compiled, data_control, row)\nX_drug = modelrow(compiled, data_drug, row)\nΔ = X_drug .- X_control\n\n# With gradient\nβ = coef(model)\neffect = dot(β, Δ)\nse = sqrt(dot(Δ, vcov(model), Δ))","category":"page"},{"location":"internals/contrast_mechanism/#Summary:-Simple-vs-Zero-Allocation","page":"How Categorical Contrasts Work","title":"Summary: Simple vs Zero-Allocation","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Aspect Simple Approach ContrastEvaluator\nEase of use Very simple Requires setup\nCode clarity Clear intent More abstraction\nMemory per contrast ~8KB 0 bytes\nBest for 1-10 contrasts 100+ contrasts\nSetup cost None ~50μs + ~50KB\nLearning curve Minimal Moderate","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Recommendation: Start with the simple approach for exploration. Switch to ContrastEvaluator when:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"You need to compute 100+ contrasts\nPerformance/memory is critical\nBuilding production pipelines","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#CounterfactualVector-Mechanism","page":"How Categorical Contrasts Work","title":"CounterfactualVector Mechanism","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The ContrastEvaluator achieves the same counterfactual comparison as the simple approach, but with zero allocations. It uses CounterfactualVectors to efficiently substitute values for a single row without copying data.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Key insight: Like the simple approach, this compares the same row under different categorical levels. The only difference is performance optimization, not the analytical concept.","category":"page"},{"location":"internals/contrast_mechanism/#Core-Concept","page":"How Categorical Contrasts Work","title":"Core Concept","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"A CounterfactualVector wraps an original data column and intercepts access to a specific row, returning a replacement value instead of the original:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Original data column\ndata.treatment = [\"Control\", \"Drug_A\", \"Drug_B\", \"Control\", ...]\n\n# Create CounterfactualVector\ncf_vec = CategoricalCounterfactualVector(data.treatment, row=1, replacement=\"Drug_A\")\n\n# Behavior:\ncf_vec[1]  # → \"Drug_A\" (counterfactual - substituted value)\ncf_vec[2]  # → \"Drug_A\" (original value)\ncf_vec[3]  # → \"Drug_B\" (original value)\ncf_vec[4]  # → \"Control\" (original value)","category":"page"},{"location":"internals/contrast_mechanism/#Implementation","page":"How Categorical Contrasts Work","title":"Implementation","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"All CounterfactualVector types implement this interface:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"abstract type CounterfactualVector{T} <: AbstractVector{T} end\n\n# Generic getindex implementation\n@inline Base.getindex(v::CounterfactualVector, i::Int) =\n    (i == v.row ? v.replacement : v.base[i])","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Key insight: This is just a conditional branch—no array copying, no allocations.","category":"page"},{"location":"internals/contrast_mechanism/#Typed-Variants","page":"How Categorical Contrasts Work","title":"Typed Variants","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Different data types have specialized implementations:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# For numeric variables (Float64, Int64, etc.)\nmutable struct NumericCounterfactualVector{T<:Real} <: CounterfactualVector{T}\n    base::Vector{T}           # Original data\n    row::Int                  # Row index to override\n    replacement::T            # Replacement value\nend\n\n# For categorical variables\nmutable struct CategoricalCounterfactualVector{T,R} <: CounterfactualVector{CategoricalValue{T,R}}\n    base::CategoricalArray{T,1,R}\n    row::Int\n    replacement::CategoricalValue{T,R}\nend\n\n# For boolean variables\nmutable struct BoolCounterfactualVector <: CounterfactualVector{Bool}\n    base::Vector{Bool}\n    row::Int\n    replacement::Bool\nend","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Type stability: Each variant has concrete types, enabling compiler optimizations.","category":"page"},{"location":"internals/contrast_mechanism/#Mutable-Updates","page":"How Categorical Contrasts Work","title":"Mutable Updates","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The vectors are mutable so fields can be updated without allocations:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Update which row to override\ncf_vec.row = 5\n\n# Update the replacement value\ncf_vec.replacement = \"Drug_B\"\n\n# No allocations - just field assignments","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"This enables reusing the same CounterfactualVector for multiple contrasts.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#ContrastEvaluator-Initialization","page":"How Categorical Contrasts Work","title":"ContrastEvaluator Initialization","text":"","category":"section"},{"location":"internals/contrast_mechanism/#Construction-Process","page":"How Categorical Contrasts Work","title":"Construction Process","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"When you create a ContrastEvaluator, it builds the complete counterfactual infrastructure:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"evaluator = contrastevaluator(compiled, data, [:treatment, :education, :female])","category":"page"},{"location":"internals/contrast_mechanism/#Step-1:-Build-Internal-Counterfactual-Structure","page":"How Categorical Contrasts Work","title":"Step 1: Build Internal Counterfactual Structure","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The ContrastEvaluator internally creates CounterfactualVector wrappers for specified variables:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Internal implementation creates:\n# - A tuple of typed `CounterfactualVector` objects (one per variable)\n# - A `NamedTuple` that merges original data with `CounterfactualVector` wrappers","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Example structure:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Original data\ndata = (\n    x = [1.0, 2.0, 3.0, ...],\n    outcome = [0.5, 1.2, 0.8, ...],\n    treatment = [\"Control\", \"Drug_A\", \"Drug_B\", ...],\n    education = [\"HS\", \"College\", \"HS\", ...],\n    female = [0, 1, 1, 0, ...]\n)\n\n# Internal data_counterfactual structure\ndata_counterfactual = (\n    x = data.x,                                    # Original (not in vars)\n    outcome = data.outcome,                        # Original (not in vars)\n    treatment = counterfactuals[1],                # CategoricalCounterfactualVector\n    education = counterfactuals[2],                # CategoricalCounterfactualVector\n    female = counterfactuals[3]                    # NumericCounterfactualVector{Float64}\n)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Key insight: Variables not in vars use original columns; variables in vars are wrapped in CounterfactualVectors.","category":"page"},{"location":"internals/contrast_mechanism/#Step-2:-Pre-compute-Categorical-Level-Mappings","page":"How Categorical Contrasts Work","title":"Step 2: Pre-compute Categorical Level Mappings","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Lines 106-122 in contrast_evaluator.jl\ncategorical_level_maps = Dict{Symbol, Dict{String, CategoricalValue}}()\n\nfor (i, var) in enumerate(vars)\n    cf_vec = counterfactuals[i]\n    if cf_vec isa CategoricalCounterfactualVector\n        # Build String → CategoricalValue mapping\n        level_map = Dict{String, CategoricalValue}()\n        base_array = cf_vec.base\n\n        for level_str in levels(base_array)\n            # Find a CategoricalValue instance for this level\n            matching_idx = findfirst(x -> string(x) == level_str, base_array)\n            if matching_idx !== nothing\n                level_map[level_str] = base_array[matching_idx]\n            end\n        end\n\n        categorical_level_maps[var] = level_map\n    end\nend","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Purpose: Pre-computing these mappings avoids allocations during contrast evaluation. Converting strings like \"Control\" to CategoricalValue objects normally allocates, but looking up in a pre-built Dict does not.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Example:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"categorical_level_maps[:treatment] = Dict(\n    \"Control\" => CategoricalValue(\"Control\", pool),\n    \"Drug_A\" => CategoricalValue(\"Drug_A\", pool),\n    \"Drug_B\" => CategoricalValue(\"Drug_B\", pool)\n)","category":"page"},{"location":"internals/contrast_mechanism/#Step-3:-Detect-Binary-Variables","page":"How Categorical Contrasts Work","title":"Step 3: Detect Binary Variables","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Lines 124-141 in contrast_evaluator.jl\nbinary_vars = Set{Symbol}()\nbinary_coef_indices = Dict{Symbol, Int}()\n\nfor (i, var) in enumerate(vars)\n    cf_vec = counterfactuals[i]\n    col = getproperty(data, var)\n\n    if _is_truly_binary_variable(cf_vec, col)\n        binary_vars = union(binary_vars, [var])\n        # Find coefficient index for fast path optimization\n        coef_idx = _find_binary_coefficient_index(compiled, var)\n        if coef_idx !== nothing\n            binary_coef_indices[var] = coef_idx\n        end\n    end\nend","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Purpose: Binary variables (0/1, true/false) have a fast path—the contrast is simply ±1 at the coefficient position, skipping full model evaluation.","category":"page"},{"location":"internals/contrast_mechanism/#Step-4:-Allocate-Buffers","page":"How Categorical Contrasts Work","title":"Step 4: Allocate Buffers","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Lines 143-157 in contrast_evaluator.jl\nContrastEvaluator(\n    compiled,\n    vars,\n    data_counterfactual,\n    counterfactuals,\n    Vector{Float64}(undef, length(compiled)),    # y_from_buf\n    Vector{Float64}(undef, length(compiled)),    # y_to_buf\n    categorical_level_maps,\n    binary_vars,\n    binary_coef_indices,\n    Vector{Float64}(undef, length(compiled)),    # gradient_buffer\n    Vector{Float64}(undef, length(compiled)),    # xrow_from_buf\n    Vector{Float64}(undef, length(compiled)),    # xrow_to_buf\n    1                                            # row\n)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"One-time cost: All memory allocation happens during construction. Runtime evaluation reuses these buffers.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Contrast-Computation-Flow","page":"How Categorical Contrasts Work","title":"Contrast Computation Flow","text":"","category":"section"},{"location":"internals/contrast_mechanism/#Overview-2","page":"How Categorical Contrasts Work","title":"Overview","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Computing a contrast involves:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Update counterfactual to \"from\" level → evaluate → store result\nUpdate counterfactual to \"to\" level → evaluate → store result\nCompute difference","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Let's trace through an example step-by-step.","category":"page"},{"location":"internals/contrast_mechanism/#Example-Call","page":"How Categorical Contrasts Work","title":"Example Call","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"contrast_modelrow!(Δ, evaluator, row=1, :treatment, \"Control\", \"Drug\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"This computes: Δ = X(treatment=\"Drug\") - X(treatment=\"Control\") for row 1.","category":"page"},{"location":"internals/contrast_mechanism/#Step-1:-Update-Counterfactual-to-\"from\"-Level","page":"How Categorical Contrasts Work","title":"Step 1: Update Counterfactual to \"from\" Level","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Line 213 in contrast_evaluator.jl\nupdate_counterfactual_for_var!(\n    evaluator.counterfactuals,           # Tuple of CounterfactualVectors\n    evaluator.vars,                      # [:treatment, :education, :female]\n    :treatment,                          # Variable to modify\n    row,                                 # Row index = 1\n    \"Control\",                           # Baseline level\n    evaluator.categorical_level_maps     # Pre-computed mappings\n)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"What update_counterfactual_for_var! does (lines 385-400 in typed_overrides.jl):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# 1. Find the CounterfactualVector for :treatment\ncf_vec = get_counterfactual_for_var(counterfactuals, vars, :treatment)\n# → Returns counterfactuals[1] (CategoricalCounterfactualVector for :treatment)\n\n# 2. Update which row it's overriding\nupdate_counterfactual_row!(cf_vec, row)\n# → Sets cf_vec.row = 1\n\n# 3. Use pre-computed mapping to get CategoricalValue (zero allocations!)\nlevel_map = categorical_level_maps[:treatment]\nreplacement_str = string(\"Control\")  # → \"Control\"\ncat_val = level_map[replacement_str]  # Dict lookup - no allocation!\n# → Gets CategoricalValue(\"Control\") from pre-built map\n\n# 4. Update the replacement value (mutable field assignment)\nupdate_counterfactual_replacement!(cf_vec, cat_val)\n# → Sets cf_vec.replacement = CategoricalValue(\"Control\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Result: The CounterfactualVector for :treatment now behaves as:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"data_counterfactual.treatment[1]  # → \"Control\" (counterfactual)\ndata_counterfactual.treatment[2]  # → \"Drug_A\" (original)\ndata_counterfactual.treatment[3]  # → \"Drug_B\" (original)\n# ... all other rows return original values","category":"page"},{"location":"internals/contrast_mechanism/#Step-2:-Evaluate-Formula-with-\"from\"-Level","page":"How Categorical Contrasts Work","title":"Step 2: Evaluate Formula with \"from\" Level","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Line 214 in contrast_evaluator.jl\nevaluator.compiled(evaluator.y_from_buf, evaluator.data_counterfactual, row)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"What happens:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The compiled formula evaluates row 1 using data_counterfactual\nWhen it accesses data_counterfactual.treatment[1], it gets \"Control\" (the counterfactual)\nAll other variables use their original values (no substitution)\nResult: y_from_buf contains the model matrix row X₀ with treatment=\"Control\"","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Visualization:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Original data row 1:    treatment=\"Drug_A\", education=\"HS\", x=1.5\nCounterfactual row 1:   treatment=\"Control\", education=\"HS\", x=1.5\n                                    ↑\n                            substituted value","category":"page"},{"location":"internals/contrast_mechanism/#Step-3:-Update-Counterfactual-to-\"to\"-Level","page":"How Categorical Contrasts Work","title":"Step 3: Update Counterfactual to \"to\" Level","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Line 216 in contrast_evaluator.jl\nupdate_counterfactual_for_var!(\n    evaluator.counterfactuals,\n    evaluator.vars,\n    :treatment,\n    row,\n    \"Drug\",  # Now set to comparison level\n    evaluator.categorical_level_maps\n)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Same process as Step 1, but now:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"cf_vec.row = 1                                    # Same row\ncf_vec.replacement = CategoricalValue(\"Drug\")     # Different level","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Result: The same CounterfactualVector now returns \"Drug\" for row 1.","category":"page"},{"location":"internals/contrast_mechanism/#Step-4:-Evaluate-Formula-with-\"to\"-Level","page":"How Categorical Contrasts Work","title":"Step 4: Evaluate Formula with \"to\" Level","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Line 217 in contrast_evaluator.jl\nevaluator.compiled(evaluator.y_to_buf, evaluator.data_counterfactual, row)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Result: y_to_buf contains the model matrix row X₁ with treatment=\"Drug\"","category":"page"},{"location":"internals/contrast_mechanism/#Step-5:-Compute-Discrete-Effect","page":"How Categorical Contrasts Work","title":"Step 5: Compute Discrete Effect","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Line 219 in contrast_evaluator.jl\nΔ .= evaluator.y_to_buf .- evaluator.y_from_buf","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Result: Δ = X₁ - X₀ (the discrete effect vector)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"This is the contrast vector showing how each coefficient contributes to the treatment effect.","category":"page"},{"location":"internals/contrast_mechanism/#Complete-Flow-Diagram","page":"How Categorical Contrasts Work","title":"Complete Flow Diagram","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"┌─────────────────────────────────────────────────────────────────┐\n│ 1. Update CounterfactualVector: treatment[1] → \"Control\"       │\n│    - Mutable field assignment: cf_vec.replacement = \"Control\"   │\n│    - Uses pre-computed categorical mapping (0 allocations)      │\n└───────────────────────┬─────────────────────────────────────────┘\n                        ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ 2. Evaluate formula with data_counterfactual                    │\n│    - compiled(y_from_buf, data_counterfactual, row=1)          │\n│    - Formula accesses data_counterfactual.treatment[1]          │\n│    - CounterfactualVector returns \"Control\" (not original)      │\n│    - Result: y_from_buf = X₀ (model row with Control)          │\n└───────────────────────┬─────────────────────────────────────────┘\n                        ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ 3. Update CounterfactualVector: treatment[1] → \"Drug\"          │\n│    - Mutable field assignment: cf_vec.replacement = \"Drug\"      │\n│    - Same vector, just update replacement field (0 allocations) │\n└───────────────────────┬─────────────────────────────────────────┘\n                        ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ 4. Evaluate formula with data_counterfactual (again)            │\n│    - compiled(y_to_buf, data_counterfactual, row=1)            │\n│    - CounterfactualVector now returns \"Drug\"                    │\n│    - Result: y_to_buf = X₁ (model row with Drug)               │\n└───────────────────────┬─────────────────────────────────────────┘\n                        ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ 5. Compute difference                                           │\n│    - Δ .= y_to_buf .- y_from_buf                               │\n│    - Result: Δ = X₁ - X₀ (discrete effect)                     │\n└─────────────────────────────────────────────────────────────────┘","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Gradient-Computation","page":"How Categorical Contrasts Work","title":"Gradient Computation","text":"","category":"section"},{"location":"internals/contrast_mechanism/#Purpose","page":"How Categorical Contrasts Work","title":"Purpose","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Parameter gradients enable uncertainty quantification via the delta method:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Compute gradient ∇β where ∇β[i] = ∂(discrete_effect)/∂β[i]\ncontrast_gradient!(∇β, evaluator, row, :treatment, \"Control\", \"Drug\", β)\n\n# Delta method standard error\nse = sqrt(∇β' * vcov_matrix * ∇β)","category":"page"},{"location":"internals/contrast_mechanism/#Linear-Scale-Gradients","page":"How Categorical Contrasts Work","title":"Linear Scale Gradients","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For discrete effects on the linear predictor scale η = Xβ:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"discrete_effect = η₁ - η₀ = (X₁'β) - (X₀'β) = (X₁ - X₀)'β","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The gradient is simply:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"∇β = ΔX = X₁ - X₀","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Implementation (lines 786-796 in contrast_evaluator.jl):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Update to \"from\" level and evaluate\nupdate_counterfactual_for_var!(evaluator.counterfactuals, evaluator.vars, var, row, from, ...)\nevaluator.compiled(evaluator.xrow_from_buf, evaluator.data_counterfactual, row)\n# → xrow_from_buf = X₀\n\n# Update to \"to\" level and evaluate\nupdate_counterfactual_for_var!(evaluator.counterfactuals, evaluator.vars, var, row, to, ...)\nevaluator.compiled(evaluator.xrow_to_buf, evaluator.data_counterfactual, row)\n# → xrow_to_buf = X₁\n\n# Gradient is the contrast vector\n∇β .= xrow_to_buf .- xrow_from_buf  # ∇β = X₁ - X₀","category":"page"},{"location":"internals/contrast_mechanism/#Response-Scale-Gradients","page":"How Categorical Contrasts Work","title":"Response Scale Gradients","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"For discrete effects on the response scale μ = g⁻¹(η):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"discrete_effect = μ₁ - μ₀ = g⁻¹(η₁) - g⁻¹(η₀)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"By the chain rule:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"∇β = g'(η₁) × X₁ - g'(η₀) × X₀","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Where g'(η) = dμ/dη is the link function derivative.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Implementation (lines 825-842 in contrast_evaluator.jl):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Compute X₀ and η₀ = X₀'β\nupdate_counterfactual_for_var!(...)\nevaluator.compiled(evaluator.xrow_from_buf, evaluator.data_counterfactual, row)\nη₀ = dot(β, evaluator.xrow_from_buf)\n\n# Compute X₁ and η₁ = X₁'β\nupdate_counterfactual_for_var!(...)\nevaluator.compiled(evaluator.xrow_to_buf, evaluator.data_counterfactual, row)\nη₁ = dot(β, evaluator.xrow_to_buf)\n\n# Compute link function derivatives\ng_prime_η₀ = _dmu_deta(link, η₀)  # dμ/dη at η₀\ng_prime_η₁ = _dmu_deta(link, η₁)  # dμ/dη at η₁\n\n# Apply chain rule\n∇β .= g_prime_η₁ .* xrow_to_buf .- g_prime_η₀ .* xrow_from_buf","category":"page"},{"location":"internals/contrast_mechanism/#Supported-Link-Functions","page":"How Categorical Contrasts Work","title":"Supported Link Functions","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"All GLM link functions are supported:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"IdentityLink: g'(η) = 1\nLogLink: g'(η) = exp(η)\nLogitLink: g'(η) = exp(η) / (1 + exp(η))²\nProbitLink: g'(η) = φ(η) (standard normal PDF)\nCloglogLink, CauchitLink, InverseLink, SqrtLink, etc.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Performance-Characteristics","page":"How Categorical Contrasts Work","title":"Performance Characteristics","text":"","category":"section"},{"location":"internals/contrast_mechanism/#Zero-Allocations-Achieved-Through","page":"How Categorical Contrasts Work","title":"Zero Allocations Achieved Through","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Pre-allocated buffers\nAll output buffers allocated once during construction\nReused across all contrast computations\nBuffers: y_from_buf, y_to_buf, xrow_from_buf, xrow_to_buf, gradient_buffer\nMutable CounterfactualVectors\nUpdate fields in-place: cf_vec.row = new_row, cf_vec.replacement = new_value\nNo array copying or temporary allocations\nType-stable concrete types enable compiler optimizations\nPre-computed categorical mappings\nString → CategoricalValue lookups cached at construction\nDictionary lookups don't allocate (just pointer access)\nAvoids repeated level searches in CategoricalArray\nType specialization\nAll CounterfactualVector types are concrete (not abstract)\nCompiled formula is fully type-specialized\nNo runtime dispatch on hot paths","category":"page"},{"location":"internals/contrast_mechanism/#Memory-Efficiency-Comparison","page":"How Categorical Contrasts Work","title":"Memory Efficiency Comparison","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Traditional approach (allocates O(n) memory):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Copy entire dataset and modify\ndata_control = deepcopy(data)\ndata_control.treatment .= \"Control\"  # Allocate new column!\nX₀ = modelmatrix(formula, DataFrame(data_control))\n\ndata_drug = deepcopy(data)\ndata_drug.treatment .= \"Drug\"  # Another allocation!\nX₁ = modelmatrix(formula, DataFrame(data_drug))\n\nΔ = X₁[row, :] - X₀[row, :]","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Memory used: ~2n + O(modelmatrixsize)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"CounterfactualVector approach (O(1) memory):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Create evaluator once (one-time cost)\nevaluator = contrastevaluator(compiled, data, [:treatment])\nΔ = Vector{Float64}(undef, length(compiled))\n\n# Compute contrast (zero allocations)\ncontrast_modelrow!(Δ, evaluator, row, :treatment, \"Control\", \"Drug\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Memory used: ~32 bytes (for mutable field updates)","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Savings: >99.999% memory reduction for large datasets","category":"page"},{"location":"internals/contrast_mechanism/#Timing-Benchmarks","page":"How Categorical Contrasts Work","title":"Timing Benchmarks","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"From test suite (test/test_contrast_evaluator.jl):","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Construction (one-time cost)\n@benchmark contrastevaluator($compiled, $data, [:treatment, :education])\n# Typical: ~10-50μs, <50KB allocated\n\n# Contrast computation (repeated operations)\n@benchmark contrast_modelrow!($Δ, $evaluator, 1, :treatment, \"Control\", \"Drug\")\n# Typical: ~50-200ns, 0 bytes allocated\n\n# Gradient computation\n@benchmark contrast_gradient!($∇β, $evaluator, 1, :treatment, \"Control\", \"Drug\", $β)\n# Typical: ~100-300ns, 0 bytes allocated","category":"page"},{"location":"internals/contrast_mechanism/#Batch-Processing","page":"How Categorical Contrasts Work","title":"Batch Processing","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Processing multiple contrasts reuses the same buffers:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"evaluator = contrastevaluator(compiled, data, [:treatment])\nΔ = Vector{Float64}(undef, length(compiled))\n\n# Zero allocations for all iterations\nfor row in 1:1000\n    contrast_modelrow!(Δ, evaluator, row, :treatment, \"Control\", \"Drug\")\n    # Process Δ...\nend","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Performance: Constant memory usage regardless of number of contrasts.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Advanced-Topics","page":"How Categorical Contrasts Work","title":"Advanced Topics","text":"","category":"section"},{"location":"internals/contrast_mechanism/#Binary-Variable-Fast-Path","page":"How Categorical Contrasts Work","title":"Binary Variable Fast Path","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Binary variables (0/1, true/false) have optimized computation that skips formula evaluation:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# For binary variables, the contrast is simply ±1 at the coefficient position\nfunction _contrast_modelrow_binary_fast_path!(Δ, evaluator, var, from, to)\n    coef_idx = evaluator.binary_coef_indices[var]\n\n    # Zero out all coefficients\n    @inbounds for i in eachindex(Δ)\n        Δ[i] = 0.0\n    end\n\n    # Set single non-zero element\n    contrast_direction = _binary_contrast_direction(from, to)  # ±1.0\n    @inbounds Δ[coef_idx] = contrast_direction\n\n    return Δ\nend","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Speedup: ~10x faster than general path for binary variables.","category":"page"},{"location":"internals/contrast_mechanism/#Multiple-Variables","page":"How Categorical Contrasts Work","title":"Multiple Variables","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The same evaluator can process different variables:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"evaluator = contrastevaluator(compiled, data, [:treatment, :region, :education])\nΔ_treatment = Vector{Float64}(undef, length(compiled))\nΔ_region = Vector{Float64}(undef, length(compiled))\n\n# Different variables, same evaluator, same buffers\ncontrast_modelrow!(Δ_treatment, evaluator, 1, :treatment, \"Control\", \"Drug\")\ncontrast_modelrow!(Δ_region, evaluator, 1, :region, \"North\", \"South\")","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Memory: O(1) regardless of number of variables or contrasts.","category":"page"},{"location":"internals/contrast_mechanism/#Integration-with-Compiled-Formula","page":"How Categorical Contrasts Work","title":"Integration with Compiled Formula","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The compiled formula is completely unaware that it's using CounterfactualVectors:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Inside the compiled formula evaluation\nfunction (compiled::UnifiedCompiled)(output, data, row)\n    # Access column (might be CounterfactualVector)\n    treatment_val = data.treatment[row]  # Dispatches to getindex\n\n    # CounterfactualVector returns replacement value if row matches\n    # Otherwise returns original value\n    # Formula sees no difference!\nend","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Transparency: The AbstractVector interface makes CounterfactualVectors indistinguishable from regular vectors to the formula compiler.","category":"page"},{"location":"internals/contrast_mechanism/#Type-Stability-Validation","page":"How Categorical Contrasts Work","title":"Type Stability Validation","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"All CounterfactualVector types maintain concrete element types:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"# Numeric: Float64 in, Float64 out\ncf_numeric::NumericCounterfactualVector{Float64}\neltype(cf_numeric) === Float64  # ✓\n\n# Categorical: CategoricalValue in, CategoricalValue out\ncf_cat::CategoricalCounterfactualVector{String, UInt32}\neltype(cf_cat) === CategoricalValue{String, UInt32}  # ✓\n\n# Boolean: Bool in, Bool out\ncf_bool::BoolCounterfactualVector\neltype(cf_bool) === Bool  # ✓","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Result: No type instabilities, no runtime dispatch, full compiler optimization.","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"","category":"page"},{"location":"internals/contrast_mechanism/#Summary","page":"How Categorical Contrasts Work","title":"Summary","text":"","category":"section"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The categorical contrast system achieves zero-allocation performance through:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"CounterfactualVectors: Mutable wrappers that intercept single-row access\nPre-computed mappings: Categorical level lookups cached at construction\nBuffer reuse: All output arrays allocated once, reused for all contrasts\nType specialization: Concrete types throughout enable compiler optimization","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"The pattern:","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"Construct evaluator → Update counterfactual → Evaluate → Update counterfactual → Evaluate → Difference","category":"page"},{"location":"internals/contrast_mechanism/","page":"How Categorical Contrasts Work","title":"How Categorical Contrasts Work","text":"All with zero allocations after the one-time construction cost, enabling efficient batch processing of thousands of contrasts without memory overhead.","category":"page"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"This guide will walk you through the basics of using FormulaCompiler.jl for efficient model matrix evaluation.","category":"page"},{"location":"getting_started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"FormulaCompiler.jl is currently available from GitHub:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Pkg\nPkg.add(url=\"https://github.com/emfeltham/FormulaCompiler.jl\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Once installed, you can load the package:","category":"page"},{"location":"getting_started/#Workflow-Overview","page":"Getting Started","title":"Workflow Overview","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Here's how FormulaCompiler.jl works from start to finish:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"(Image: Diagram)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using FormulaCompiler","category":"page"},{"location":"getting_started/#Basic-Workflow","page":"Getting Started","title":"Basic Workflow","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The typical workflow with FormulaCompiler.jl involves three steps:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Fit your model using standard Julia statistical packages\nCompile the formula for optimized evaluation\nEvaluate rows with zero allocations","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's walk through a complete example:","category":"page"},{"location":"getting_started/#Step-1:-Fit-Your-Model","page":"Getting Started","title":"Step 1: Fit Your Model","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using FormulaCompiler, GLM, DataFrames, Tables, CategoricalArrays\n\n# Create some sample data\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    z = abs.(randn(1000)) .+ 0.1,\n    group = categorical(rand([\"A\", \"B\", \"C\"], 1000)),\n    treatment = rand(Bool, 1000)\n)\n\n# Fit a model using GLM.jl (or any compatible package)\nmodel = lm(@formula(y ~ x * group + log(z) + treatment), df)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Important: FormulaCompiler requires all categorical variables to use CategoricalArrays.jl. String variables in models are not supported. Always convert string columns to categorical format using categorical(column) before model fitting.","category":"page"},{"location":"getting_started/#Step-2:-Compile-the-Formula","page":"Getting Started","title":"Step 2: Compile the Formula","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Convert your data to column-table format for best performance:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"data = Tables.columntable(df)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Compile the formula:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"compiled = compile_formula(model, data)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The compiled formula contains all the information needed for zero-allocation evaluation.","category":"page"},{"location":"getting_started/#Step-3:-Evaluate-Rows","page":"Getting Started","title":"Step 3: Evaluate Rows","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Pre-allocate an output vector:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"row_vec = Vector{Float64}(undef, length(compiled))","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Now evaluate any row with zero allocations:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"compiled(row_vec, data, 1)    # Evaluate row 1\ncompiled(row_vec, data, 100)  # Evaluate row 100\ncompiled(row_vec, data, 500)  # Evaluate row 500","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Each call achieves zero allocations with good performance.","category":"page"},{"location":"getting_started/#Alternative-Interfaces","page":"Getting Started","title":"Alternative Interfaces","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"FormulaCompiler.jl provides several interfaces for different use cases:","category":"page"},{"location":"getting_started/#Convenient-Interface-(Allocating)","page":"Getting Started","title":"Convenient Interface (Allocating)","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"For quick prototyping or when allocation performance isn't critical:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Single row evaluation\nrow_values = modelrow(model, data, 1)\n\n# Multiple rows\nrow_indices = [1, 10, 50, 100]\nmatrix = modelrow(model, data, row_indices)","category":"page"},{"location":"getting_started/#Object-Based-Interface","page":"Getting Started","title":"Object-Based Interface","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Create a reusable evaluator object:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"evaluator = ModelRowEvaluator(model, df)\n\n# Zero-allocation evaluation\nresult = evaluator(1)           # Returns new vector\nevaluator(row_vec, 1)          # In-place evaluation","category":"page"},{"location":"getting_started/#Batch-Evaluation","page":"Getting Started","title":"Batch Evaluation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Evaluate multiple rows at once:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Pre-allocate matrix\nmatrix = Matrix{Float64}(undef, 10, length(compiled))\n\n# Evaluate rows 1-10 in batch\nfor i in 1:10\n    compiled(view(matrix, i, :), data, i)\nend","category":"page"},{"location":"getting_started/#How-Compilation-Works","page":"Getting Started","title":"How Compilation Works","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"FormulaCompiler.jl uses a unified compilation pipeline based on position mapping:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Decompose the formula into primitive operations (load, constant, unary, binary, contrast, copy)\nAllocate scratch and output positions for all intermediate and final values\nEmbed those positions as compile-time type parameters\nReturn a UnifiedCompiled object that evaluates rows with zero allocations","category":"page"},{"location":"getting_started/#Performance-Verification","page":"Getting Started","title":"Performance Verification","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"You can verify zero-allocation performance using BenchmarkTools.jl:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using BenchmarkTools\n\n# Benchmark the zero-allocation interface\n@benchmark $compiled($row_vec, $data, 1)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"You should see zero allocations and good evaluation performance. Absolute times vary by hardware and Julia version; focus on allocation behavior and relative trends. See the Benchmark Protocol for reproduction details:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"BenchmarkTools.Trial: Many samples with many evaluations.\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Compare this to the traditional approach:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"@benchmark modelmatrix($model)[1, :]","category":"page"},{"location":"getting_started/#Troubleshooting","page":"Getting Started","title":"Troubleshooting","text":"","category":"section"},{"location":"getting_started/#Common-Issues-and-Solutions","page":"Getting Started","title":"Common Issues and Solutions","text":"","category":"section"},{"location":"getting_started/#Compilation-Errors","page":"Getting Started","title":"Compilation Errors","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: MethodError during compile_formula","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Error: MethodError: no method matching compile_formula(::SomeUnsupportedModel, ::NamedTuple)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solution: Ensure you're using a supported model type (GLM, MixedModels) or check package compatibility.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: BoundsError or dimension mismatches","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Error: BoundsError: attempt to access 500-element Vector at index [1001]","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solution: Verify that your data contains the expected number of rows and that row_idx is within bounds.","category":"page"},{"location":"getting_started/#Performance-Issues","page":"Getting Started","title":"Performance Issues","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: Non-zero allocations detected","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# @benchmark shows non-zero memory allocations","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solutions:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Use Tables.columntable(df) instead of DataFrame directly\nEnsure output vector is pre-allocated with correct size\nCheck for type instabilities in your data (mixed types in columns)\nVerify all categorical variables use CategoricalArrays.jl","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: Slower than expected performance","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Evaluation takes longer than anticipated","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solutions:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let compilation warm up with a few calls before benchmarking\nUse the caching interface (modelrow! with cache=true) for repeated evaluations\nCheck for complex formulas that may benefit from simplification\nEnsure data is in optimal format (Tables.columntable)","category":"page"},{"location":"getting_started/#Data-Format-Issues","page":"Getting Started","title":"Data Format Issues","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: String variables in models","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Error: FormulaCompiler does not support raw string variables\ndf.category = [\"A\", \"B\", \"C\", \"A\", \"B\"]  # String vector\nmodel = lm(@formula(y ~ x + category), df)  # Will cause issues","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solution: Convert all categorical data to CategoricalArrays.jl format before model fitting:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Required: Convert strings to categorical\ndf.category = categorical(df.category)\nmodel = lm(@formula(y ~ x + category), df)  # Now works correctly","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: Categorical contrasts or unexpected behavior","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Error with categorical contrasts or unexpected contrast behavior","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solutions:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Ensure all categorical variables use CategoricalArrays.jl: categorical(column)\nVerify factor levels are consistent between training and evaluation data\nCheck contrast specifications in model fitting: contrasts = Dict(:var => EffectsCoding())","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: Missing values causing errors","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# Error: missing values not supported","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solution: Remove or impute missing values before model fitting and compilation.","category":"page"},{"location":"getting_started/#Memory-Issues","page":"Getting Started","title":"Memory Issues","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Problem: Large memory usage despite zero-allocation claims","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"# High memory usage in application","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Solutions:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Use direct data modification with merge() instead of creating full data copies\nReuse compiled formulas rather than recompiling\nClear model cache if accumulating many different compilations: clear_model_cache!()","category":"page"},{"location":"getting_started/#Performance-Validation","page":"Getting Started","title":"Performance Validation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Verify your setup achieves expected performance:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using BenchmarkTools\n\n# Check zero allocations\nresult = @benchmark $compiled($row_vec, $data, 1)\n@assert result.memory == 0 \"Expected zero allocations, got $(result.memory) bytes\"\n\n# Check cache effectiveness  \n@time modelrow!(row_vec, model, data, 1; cache=true)  # First call\n@time modelrow!(row_vec, model, data, 2; cache=true)  # Should be much faster","category":"page"},{"location":"getting_started/#Getting-Help","page":"Getting Started","title":"Getting Help","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"If you encounter issues not covered here:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Check the API Reference for detailed function documentation\nReview Examples for similar use cases\nExamine Advanced Features for complex scenarios\nConsult Performance Tips for optimization guidance","category":"page"},{"location":"getting_started/#Interface-Selection-Guide","page":"Getting Started","title":"Interface Selection Guide","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Choose the right interface for your needs:","category":"page"},{"location":"getting_started/#Use-compiled(output,-data,-row_idx)-when:","page":"Getting Started","title":"Use compiled(output, data, row_idx) when:","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Maximum performance is critical\nYou're in tight computational loops\nYou can manage pre-allocation\nZero allocations are required","category":"page"},{"location":"getting_started/#Use-modelrow!(output,-compiled,-data,-row_idx)-when:","page":"Getting Started","title":"Use modelrow!(output, compiled, data, row_idx) when:","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"You want explicit control over compilation\nYou need the same compiled formula across different data\nMemory management is important\nYou prefer functional over object-oriented style","category":"page"},{"location":"getting_started/#Use-modelrow(model,-data,-row_idx)-when:","page":"Getting Started","title":"Use modelrow(model, data, row_idx) when:","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Convenience outweighs performance\nYou're prototyping or exploring\nAllocation overhead is acceptable\nYou prefer simple, direct interfaces","category":"page"},{"location":"getting_started/#Use-ModelRowEvaluator(model,-data)-when:","page":"Getting Started","title":"Use ModelRowEvaluator(model, data) when:","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"You prefer object-oriented interfaces\nThe same model and data are used repeatedly\nYou need both allocating and non-allocating evaluation\nYou want encapsulated state management","category":"page"},{"location":"getting_started/#What's-Next?","page":"Getting Started","title":"What's Next?","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Now that you understand the basics, explore advanced topics:","category":"page"},{"location":"getting_started/#Immediate-Next-Steps","page":"Getting Started","title":"Immediate Next Steps","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Basic Usage Guide - Detailed interface documentation\nScenario Analysis - Counterfactual analysis and variable overrides\nPerformance Tips - Optimization strategies","category":"page"},{"location":"getting_started/#Advanced-Applications","page":"Getting Started","title":"Advanced Applications","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Examples - Real-world statistical computing patterns\nGLM Integration - Linear and generalized linear model workflows\nMixedModels Integration - Mixed-effects model support","category":"page"},{"location":"getting_started/#Reference-Documentation","page":"Getting Started","title":"Reference Documentation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"API Reference - Complete function documentation with examples\nArchitecture - Implementation details and design principles\nMathematical Foundation - Theoretical background and computational theory","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Real-world examples demonstrating FormulaCompiler.jl capabilities across multiple domains.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For fundamental usage patterns, see Basic Usage. For advanced computational techniques, see Advanced Features.","category":"page"},{"location":"examples/#Quick-Reference","page":"Examples","title":"Quick Reference","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Essential patterns for immediate use. All examples use synthetic data for simplicity and self-containment.","category":"page"},{"location":"examples/#Core-Compilation-Pattern","page":"Examples","title":"Core Compilation Pattern","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using FormulaCompiler, GLM, DataFrames, Tables\n\n# Basic setup\ndf = DataFrame(x = randn(100), y = randn(100), group = rand([\"A\", \"B\"], 100))\nmodel = lm(@formula(y ~ x * group), df)\ndata = Tables.columntable(df)\n\n# Compile and evaluate\ncompiled = compile_formula(model, data)\noutput = Vector{Float64}(undef, length(compiled))\ncompiled(output, data, 1)  # Zero allocations","category":"page"},{"location":"examples/#Performance-Validation","page":"Examples","title":"Performance Validation","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BenchmarkTools\n\n# Verify zero allocations\nresult = @benchmark $compiled($output, $data, 1)\n@assert result.memory == 0 \"Expected zero allocations\"","category":"page"},{"location":"examples/#Counterfactual-Analysis","page":"Examples","title":"Counterfactual Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Single policy scenario using direct data modification\nn_rows = length(data.x)\ndata_policy = merge(data, (x = fill(2.0, n_rows), group = fill(\"A\", n_rows)))\ncompiled(output, data_policy, 1)  # Evaluate with modified data\n\n# Multi-scenario analysis\nx_values = [-1.0, 0.0, 1.0]\ngroup_values = [\"A\", \"B\"]\nresults = Matrix{Float64}(undef, 6, length(compiled))  # 3×2 = 6 scenarios\n\nscenario_idx = 1\nfor x_val in x_values\n    for group_val in group_values\n        data_scenario = merge(data, (x = fill(x_val, n_rows), group = fill(group_val, n_rows)))\n        compiled(view(results, scenario_idx, :), data_scenario, 1)\n        scenario_idx += 1\n    end\nend","category":"page"},{"location":"examples/#Marginal-Effects","page":"Examples","title":"Marginal Effects","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Margins  # Provides marginal_effects_eta! and marginal_effects_mu!\n\n# Identify continuous variables and build evaluators\nvars = continuous_variables(compiled, data)  # [:x]\nde_ad = derivativeevaluator(:ad, compiled, data, vars)  # Automatic differentiation: higher accuracy (preferred)\nde_fd = derivativeevaluator(:fd, compiled, data, vars)  # Finite differences: explicit step control\nβ = coef(model)\n\n# Compute marginal effects\ng = Vector{Float64}(undef, length(vars))\nmarginal_effects_eta!(g, de_ad, β, 1)  # Zero allocations, higher accuracy\nmarginal_effects_eta!(g, de_fd, β, 1)  # Zero allocations, explicit step control","category":"page"},{"location":"examples/#Batch-Processing","page":"Examples","title":"Batch Processing","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Multiple rows at once\nn_rows = 50\nresults = Matrix{Float64}(undef, n_rows, length(compiled))\nfor i in 1:n_rows\n    compiled(view(results, i, :), data, i)  # Zero allocations\nend","category":"page"},{"location":"examples/#Domain-Applications","page":"Examples","title":"Domain Applications","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Real-world applications using authentic datasets from RDatasets.jl. These examples demonstrate FormulaCompiler.jl's capabilities with data structures practitioners encounter in their domains.","category":"page"},{"location":"examples/#Economics:-Labor-Market-Analysis","page":"Examples","title":"Economics: Labor Market Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Wage determination analysis using real Belgian wage data:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RDatasets, FormulaCompiler, GLM, Tables\n\n# Load real wage data from Belgian labor market\nwages = dataset(\"Ecdat\", \"Bwages\")  # 1472 observations\n# Columns: Wage (hourly wage), Educ (education years), Exper (experience), Sex\n\n# Convert categorical variable properly\nwages.Male = wages.Sex .== \"male\"\ndata = Tables.columntable(wages)\n\n# Wage determination model with gender interaction\nmodel = lm(@formula(log(Wage) ~ Educ * Male + Exper + I(Exper^2)), wages)\ncompiled = compile_formula(model, data)","category":"page"},{"location":"examples/#Policy-Analysis-with-Scenarios","page":"Examples","title":"Policy Analysis with Scenarios","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Analyze gender pay gap under different policy scenarios:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Define policy scenarios using direct data modification\nmean_educ = mean(wages.Educ)\nmean_exper = mean(wages.Exper)\nn_rows = length(data.Educ)\n\noutput = Vector{Float64}(undef, length(compiled))\nβ = coef(model)\n\n# Create scenario data\nscenarios = [\n    (\"status_quo\", data),\n    (\"equal_education\", merge(data, (Educ = fill(mean_educ, n_rows),))),\n    (\"equal_experience\", merge(data, (Exper = fill(mean_exper, n_rows),))),\n    (\"standardized_worker\", merge(data, (Educ = fill(mean_educ, n_rows), Exper = fill(mean_exper, n_rows))))\n]\n\n# Policy scenario analysis\nfor (scenario_name, scenario_data) in scenarios\n    # Sample analysis for first 100 workers\n    wages_predicted = Float64[]\n    for worker in 1:100\n        compiled(output, scenario_data, worker)\n        push!(wages_predicted, exp(dot(β, output)))  # Convert from log scale\n    end\n\n    mean_wage = mean(wages_predicted)\n    println(\"$(scenario_name): Mean predicted wage = \\$$(round(mean_wage, digits=2))\")\nend","category":"page"},{"location":"examples/#Marginal-Effects-on-Wages","page":"Examples","title":"Marginal Effects on Wages","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Compute returns to education and experience:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Margins  # Provides marginal_effects_eta!\n\n# Build derivative evaluator for continuous variables\ncontinuous_vars = [:Educ, :Exper]  # Education and experience are continuous\nde_fd = derivativeevaluator(:fd, compiled, data, continuous_vars)\n\n# Compute marginal effects for representative workers\ng_eta = Vector{Float64}(undef, length(continuous_vars))\n\n# Male worker with median characteristics\nmale_median_idx = findfirst(row -> row.Male && row.Educ ≈ median(wages.Educ), eachrow(wages))\nif !isnothing(male_median_idx)\n    marginal_effects_eta!(g_eta, de_fd, β, male_median_idx)\n    println(\"Male median worker - Returns to education: $(round(g_eta[1]*100, digits=2))%\")\n    println(\"Male median worker - Returns to experience: $(round(g_eta[2]*100, digits=2))%\")\nend","category":"page"},{"location":"examples/#Engineering:-Automotive-Performance-Analysis","page":"Examples","title":"Engineering: Automotive Performance Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Engine performance modeling using the classic mtcars dataset:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RDatasets, FormulaCompiler, GLM\n\n# Load automotive engineering data\nmtcars = dataset(\"datasets\", \"mtcars\")  # 32 classic cars\n# Key variables: MPG (fuel efficiency), HP (horsepower), WT (weight), Cyl (cylinders)\n\ndata = Tables.columntable(mtcars)\n\n# Fuel efficiency model with engine characteristics\nmodel = lm(@formula(MPG ~ HP * WT + Cyl + log(HP)), mtcars)\ncompiled = compile_formula(model, data)","category":"page"},{"location":"examples/#Engineering-Design-Scenarios","page":"Examples","title":"Engineering Design Scenarios","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Analyze fuel efficiency under different design specifications:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Engineering design analysis using direct data modification\nbase_hp = mean(mtcars.HP)\nbase_wt = mean(mtcars.WT)\nn_rows = length(data.HP)\n\n# Define design parameter combinations\nhp_values = [base_hp * 0.8, base_hp, base_hp * 1.2]      # -20%, baseline, +20% power\nwt_values = [base_wt * 0.9, base_wt, base_wt * 1.1]      # -10%, baseline, +10% weight\ncyl_values = [4, 6, 8]                                    # Engine configurations\n\n# Performance analysis across design space (3×3×3 = 27 scenarios)\noutput = Vector{Float64}(undef, length(compiled))\nβ = coef(model)\n\nscenario_results = Float64[]\nscenario_descriptions = String[]\nfor hp_val in hp_values, wt_val in wt_values, cyl_val in cyl_values\n    # Create scenario data\n    data_scenario = merge(data, (\n        HP = fill(hp_val, n_rows),\n        WT = fill(wt_val, n_rows),\n        Cyl = fill(cyl_val, n_rows)\n    ))\n\n    # Evaluate reference car design with these parameters\n    compiled(output, data_scenario, 1)\n    predicted_mpg = dot(β, output)\n    push!(scenario_results, predicted_mpg)\n\n    # Track scenario description\n    hp_change = round((hp_val / base_hp - 1) * 100, digits=1)\n    wt_change = round((wt_val / base_wt - 1) * 100, digits=1)\n    push!(scenario_descriptions, \"HP: $(hp_change)%, WT: $(wt_change)%, Cyl: $(cyl_val)\")\nend\n\nbest_scenario_idx = argmax(scenario_results)\nbest_mpg = scenario_results[best_scenario_idx]\nprintln(\"Best design scenario: $(scenario_descriptions[best_scenario_idx])\")\nprintln(\"Predicted MPG: $(round(best_mpg, digits=2))\")","category":"page"},{"location":"examples/#Performance-Sensitivity-Analysis","page":"Examples","title":"Performance Sensitivity Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Compute sensitivity to design parameters:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Margins  # Provides marginal_effects_eta!\n\n# Marginal effects on fuel efficiency\nengineering_vars = [:HP, :WT]  # Continuous engineering parameters\nde_fd = derivativeevaluator(:fd, compiled, data, engineering_vars)\n\ng = Vector{Float64}(undef, length(engineering_vars))\n\n# Analyze sensitivity for different vehicle classes\nfor (car_type, indices) in [(\"Sports cars\", findall(x -> x > 200, mtcars.HP)),\n                            (\"Economy cars\", findall(x -> x < 100, mtcars.HP))]\n    if !isempty(indices)\n        representative_idx = indices[1]\n        marginal_effects_eta!(g, de_fd, β, representative_idx)\n\n        println(\"$car_type sensitivity:\")\n        println(\"  MPG change per HP unit: $(round(g[1], digits=3))\")\n        println(\"  MPG change per 1000lb weight: $(round(g[2]*1000, digits=3))\")\n    end\nend","category":"page"},{"location":"examples/#Biostatistics:-Cancer-Survival-Analysis","page":"Examples","title":"Biostatistics: Cancer Survival Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Clinical outcome modeling using real lung cancer data:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RDatasets\n\n# Load NCCTG lung cancer clinical trial data\nlung = dataset(\"survival\", \"lung\")  # 228 patients\n# Variables: time (survival days), status (censoring), age, sex, ph.ecog (performance score)\n\n# Remove missing values for demonstration\nlung_complete = dropmissing(lung, [:age, :sex, :ph_ecog])\ndata = Tables.columntable(lung_complete)\n\n# Survival time model (using log transformation for demonstration)\n# In practice, would use survival analysis methods\nmodel = lm(@formula(log(time + 1) ~ age + sex + ph_ecog + age * sex), lung_complete)\ncompiled = compile_formula(model, data)","category":"page"},{"location":"examples/#Clinical-Scenarios","page":"Examples","title":"Clinical Scenarios","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Analyze survival outcomes under different patient profiles:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Clinical analysis using direct data modification\nn_rows = length(data.age)\noutput = Vector{Float64}(undef, length(compiled))\nβ = coef(model)\n\n# Define clinical scenarios\nclinical_scenarios = [\n    (\"young_male\", merge(data, (age = fill(50, n_rows), sex = fill(1, n_rows)))),\n    (\"old_male\", merge(data, (age = fill(70, n_rows), sex = fill(1, n_rows)))),\n    (\"young_female\", merge(data, (age = fill(50, n_rows), sex = fill(2, n_rows)))),\n    (\"old_female\", merge(data, (age = fill(70, n_rows), sex = fill(2, n_rows)))),\n    (\"high_performance\", merge(data, (ph_ecog = fill(0, n_rows),))),\n    (\"poor_performance\", merge(data, (ph_ecog = fill(2, n_rows),)))\n]\n\n# Clinical outcome analysis\nfor (profile_name, scenario_data) in clinical_scenarios\n    compiled(output, scenario_data, 1)\n    predicted_log_survival = dot(β, output)\n    predicted_days = exp(predicted_log_survival) - 1\n\n    println(\"$(profile_name): Predicted survival = $(round(predicted_days, digits=0)) days\")\nend","category":"page"},{"location":"examples/#Clinical-Risk-Factors","page":"Examples","title":"Clinical Risk Factors","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Quantify impact of patient characteristics on outcomes:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Margins  # Provides marginal_effects_eta!\n\n# Marginal effects for continuous clinical variables\nclinical_vars = [:age]  # Age is the main continuous predictor\nde_fd = derivativeevaluator(:fd, compiled, data, clinical_vars)\n\ng = Vector{Float64}(undef, length(clinical_vars))\n\n# Risk assessment for different patient groups\nfor (group, sex_val) in [(\"Male patients\", 1), (\"Female patients\", 2)]\n    group_indices = findall(x -> x == sex_val, lung_complete.sex)\n    if !isempty(group_indices)\n        representative_idx = group_indices[div(length(group_indices), 2)]  # Median patient\n        marginal_effects_eta!(g, de_fd, β, representative_idx)\n\n        daily_age_effect = g[1]  # Effect per year of age\n        yearly_effect = exp(daily_age_effect) - 1  # Convert from log scale\n\n        println(\"$group - Age effect: $(round(yearly_effect*100, digits=2))% per year\")\n    end\nend","category":"page"},{"location":"examples/#Social-Sciences:-Educational-Outcomes","page":"Examples","title":"Social Sciences: Educational Outcomes","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"University admission analysis using UC Berkeley data:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Load UC Berkeley admission data (famous dataset for Simpson's paradox)\nucb = dataset(\"datasets\", \"UCBAdmissions\")\n# This is aggregate data, so we'll expand it for modeling\n\n# Create individual-level data from aggregate counts\nindividual_data = DataFrame()\nfor row in eachrow(ucb)\n    n_cases = Int(row.Freq)\n    individual_cases = DataFrame(\n        Admitted = fill(row.Admit == \"Admitted\", n_cases),\n        Gender = fill(row.Gender, n_cases), \n        Department = fill(row.Dept, n_cases)\n    )\n    individual_data = vcat(individual_data, individual_cases)\nend\n\n# Convert to appropriate types\nindividual_data.Male = individual_data.Gender .== \"Male\"\ndata = Tables.columntable(individual_data)\n\n# Admission probability model\nmodel = glm(@formula(Admitted ~ Male * Department), individual_data, Binomial(), LogitLink())\ncompiled = compile_formula(model, data)","category":"page"},{"location":"examples/#Educational-Policy-Analysis","page":"Examples","title":"Educational Policy Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Analyze admission scenarios across departments:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Policy analysis using direct data modification\nn_rows = length(data.Male)\noutput = Vector{Float64}(undef, length(compiled))\nβ = coef(model)\n\n# Define policy scenarios\npolicy_scenarios = [\n    (\"gender_blind\", merge(data, (Male = fill(true, n_rows),))),\n    (\"gender_blind_female\", merge(data, (Male = fill(false, n_rows),))),\n    (\"dept_a_focus\", merge(data, (Department = fill(\"A\", n_rows),))),\n    (\"dept_f_focus\", merge(data, (Department = fill(\"F\", n_rows),)))\n]\n\n# Policy impact analysis\nfor (policy_name, scenario_data) in policy_scenarios\n    admission_probs = Float64[]\n\n    # Sample 100 cases for analysis\n    sample_size = min(100, n_rows)\n    for i in 1:sample_size\n        compiled(output, scenario_data, i)\n        linear_pred = dot(β, output)\n        prob = 1 / (1 + exp(-linear_pred))  # Logistic transformation\n        push!(admission_probs, prob)\n    end\n\n    mean_prob = mean(admission_probs)\n    println(\"$(policy_name): Mean admission probability = $(round(mean_prob*100, digits=1))%\")\nend","category":"page"},{"location":"examples/#Advanced-Computational-Patterns","page":"Examples","title":"Advanced Computational Patterns","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"High-performance applications combining multiple FormulaCompiler.jl features with authentic datasets.","category":"page"},{"location":"examples/#Large-Scale-Monte-Carlo-Simulation","page":"Examples","title":"Large-Scale Monte Carlo Simulation","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Bootstrap confidence intervals for economic policy effects:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RDatasets, Statistics, Random\n\n# Use wage data for bootstrap analysis\nwages = dataset(\"Ecdat\", \"Bwages\")\nwages.Male = wages.Sex .== \"male\"\nn_obs = nrow(wages)\n\n# Policy model\nbase_model = lm(@formula(log(Wage) ~ Educ * Male + Exper), wages)\nbase_data = Tables.columntable(wages)\ncompiled = compile_formula(base_model, base_data)\n\n# Bootstrap function for policy effect estimation\nfunction bootstrap_policy_effect(n_bootstrap=1000)\n    Random.seed!(123)  # Reproducible results\n    \n    policy_effects = Float64[]\n    output = Vector{Float64}(undef, length(compiled))\n    \n    for b in 1:n_bootstrap\n        # Bootstrap sample\n        boot_indices = rand(1:n_obs, n_obs)\n\n        # Create policy scenario\n        n_rows = length(base_data.Educ)\n        policy_data = merge(base_data, (Educ = fill(mean(wages.Educ), n_rows),))\n\n        # Compute policy effect for bootstrap sample\n        status_quo_wages = Float64[]\n        policy_wages = Float64[]\n\n        for idx in boot_indices[1:100]  # Sample subset for speed\n            # Status quo\n            compiled(output, base_data, idx)\n            push!(status_quo_wages, exp(dot(coef(base_model), output)))\n\n            # Policy scenario\n            compiled(output, policy_data, idx)\n            push!(policy_wages, exp(dot(coef(base_model), output)))\n        end\n\n        # Policy effect (proportional change)\n        effect = mean(policy_wages) / mean(status_quo_wages) - 1\n        push!(policy_effects, effect)\n    end\n    \n    return policy_effects\nend\n\n# Run bootstrap analysis\nprintln(\"Running bootstrap analysis...\")\npolicy_effects = bootstrap_policy_effect(500)\n\n# Results\nmean_effect = mean(policy_effects)\nci_lower = quantile(policy_effects, 0.025)\nci_upper = quantile(policy_effects, 0.975)\n\nprintln(\"Policy effect: $(round(mean_effect*100, digits=2))%\")\nprintln(\"95% CI: [$(round(ci_lower*100, digits=2))%, $(round(ci_upper*100, digits=2))%]\")","category":"page"},{"location":"examples/#Cross-Validation-with-Real-Data","page":"Examples","title":"Cross-Validation with Real Data","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Model validation using automotive performance data:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Random\n\n# Load and prepare mtcars data\nmtcars = dataset(\"datasets\", \"mtcars\")\nn_cars = nrow(mtcars)\ndata = Tables.columntable(mtcars)\n\nfunction cross_validate_performance(k_folds=5)\n    Random.seed!(456)\n    fold_indices = rand(1:k_folds, n_cars)\n    \n    fold_errors = Float64[]\n    output = Vector{Float64}(undef, 0)  # Will resize based on model\n    \n    for fold in 1:k_folds\n        # Split data\n        train_idx = findall(x -> x != fold, fold_indices)\n        test_idx = findall(x -> x == fold, fold_indices)\n        \n        # Fit model on training data\n        train_data = mtcars[train_idx, :]\n        model = lm(@formula(MPG ~ HP + WT + Cyl), train_data)\n        \n        # Compile for test evaluation\n        compiled = compile_formula(model, data)\n        if isempty(output)\n            output = Vector{Float64}(undef, length(compiled))\n        end\n        β = coef(model)\n        \n        # Predict on test set\n        test_errors = Float64[]\n        for test_car in test_idx\n            compiled(output, data, test_car)\n            predicted = dot(β, output)\n            actual = mtcars.MPG[test_car]\n            push!(test_errors, (predicted - actual)^2)\n        end\n        \n        push!(fold_errors, mean(test_errors))\n    end\n    \n    return sqrt(mean(fold_errors))  # RMSE\nend\n\n# Run cross-validation\ncv_rmse = cross_validate_performance(5)\nprintln(\"Cross-validation RMSE: $(round(cv_rmse, digits=2)) MPG\")","category":"page"},{"location":"examples/#Parallel-Scenario-Analysis","page":"Examples","title":"Parallel Scenario Analysis","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Distributed policy analysis across multiple cores:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Distributed, SharedArrays\n\n# For demonstration - would typically use addprocs() to add workers\n# addprocs(2)\n\n# @everywhere using FormulaCompiler, RDatasets, GLM, Tables\n\nfunction parallel_policy_analysis()\n    wages = dataset(\"Ecdat\", \"Bwages\")\n    wages.Male = wages.Sex .== \"male\"\n    data = Tables.columntable(wages)\n    \n    model = lm(@formula(log(Wage) ~ Educ * Male + Exper), wages)\n    compiled = compile_formula(model, data)\n    \n    # Define policy grid parameters\n    educ_levels = [10, 12, 14, 16, 18, 20]        # Education levels\n    exper_levels = [0, 5, 10, 15, 20, 25]         # Experience levels\n    male_levels = [false, true]                    # Gender\n\n    n_rows = length(data.Educ)\n    n_scenarios = length(educ_levels) * length(exper_levels) * length(male_levels)  # 6×6×2 = 72\n    n_workers = min(100, n_rows)  # Sample size for analysis\n\n    # Results storage\n    results = SharedArray{Float64}(n_scenarios)\n\n    # Parallel computation would go here\n    # @distributed for scenario_idx in 1:n_scenarios\n    scenario_idx = 1\n    for educ_val in educ_levels, exper_val in exper_levels, male_val in male_levels\n        # Create scenario data\n        scenario_data = merge(data, (\n            Educ = fill(educ_val, n_rows),\n            Exper = fill(exper_val, n_rows),\n            Male = fill(male_val, n_rows)\n        ))\n\n        output = Vector{Float64}(undef, length(compiled))\n        β = coef(model)\n\n        wage_predictions = Float64[]\n        for worker in 1:n_workers\n            compiled(output, scenario_data, worker)\n            wage_pred = exp(dot(β, output))\n            push!(wage_predictions, wage_pred)\n        end\n\n        results[scenario_idx] = mean(wage_predictions)\n        scenario_idx += 1\n    end\n\n    return results, educ_levels, exper_levels, male_levels  # Return results and grid parameters\nend\n\n# Run parallel analysis\nprintln(\"Running comprehensive policy analysis...\")\nresults, educ_levels, exper_levels, male_levels = parallel_policy_analysis()\n\n# Find optimal policy\nbest_idx = argmax(results)\nbest_wage = results[best_idx]\n\n# Decode scenario index to parameters\nn_exper = length(exper_levels)\nn_male = length(male_levels)\neduc_idx = div(best_idx - 1, n_exper * n_male) + 1\nexper_idx = div(mod(best_idx - 1, n_exper * n_male), n_male) + 1\nmale_idx = mod(best_idx - 1, n_male) + 1\n\nprintln(\"Optimal policy scenario:\")\nprintln(\"  Education: $(educ_levels[educ_idx]) years\")\nprintln(\"  Experience: $(exper_levels[exper_idx]) years\")\nprintln(\"  Gender: $(male_levels[male_idx] ? \"Male\" : \"Female\")\")\nprintln(\"  Mean predicted wage: \\$$(round(best_wage, digits=2))\")","category":"page"},{"location":"examples/#Performance-Notes","page":"Examples","title":"Performance Notes","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"All examples demonstrate FormulaCompiler.jl's key performance characteristics:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Zero-allocation core evaluation: compiled(output, data, row) calls allocate zero bytes\nMemory-efficient scenarios: Override system uses constant memory regardless of data size\nBackend selection: Choose between automatic differentiation (:ad, higher accuracy) and finite differences (:fd, explicit control) using derivativeevaluator(:ad/:fd, ...)\nScalable patterns: Performance remains constant regardless of dataset size","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For detailed performance optimization techniques, see the Performance Guide.","category":"page"},{"location":"examples/#Further-Reading","page":"Examples","title":"Further Reading","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Basic Usage - Fundamental patterns and validation techniques\nScenario Analysis - Comprehensive coverage of the override system\nAdvanced Features - Derivative computation and high-performance patterns\nAPI Reference - Complete function documentation","category":"page"},{"location":"integration/mixed_models/#MixedModels.jl-Integration","page":"MixedModels.jl","title":"MixedModels.jl Integration","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"FormulaCompiler.jl integrates with MixedModels.jl by automatically extracting fixed effects from mixed-effects models, enabling zero-allocation evaluation of the fixed-effects portion.","category":"page"},{"location":"integration/mixed_models/#Overview","page":"MixedModels.jl","title":"Overview","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Mixed models contain both fixed and random effects. FormulaCompiler.jl focuses on the fixed effects portion, which is often needed for:","category":"page"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Marginal effects calculation\nPrediction with population-level effects\nBootstrap inference on fixed effects\nPolicy analysis scenarios","category":"page"},{"location":"integration/mixed_models/#Basic-Integration","page":"MixedModels.jl","title":"Basic Integration","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"using MixedModels, FormulaCompiler, DataFrames, Tables\n\n# Example dataset\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    treatment = rand(Bool, 1000),\n    group = rand(1:10, 1000),\n    cluster = rand(1:50, 1000)\n)\n\n# Fit mixed model\nmixed_model = fit(MixedModel, @formula(y ~ x + treatment + (1|group) + (1+x|cluster)), df)\n\n# FormulaCompiler automatically extracts fixed effects: y ~ x + treatment\ncompiled = compile_formula(mixed_model, Tables.columntable(df))","category":"page"},{"location":"integration/mixed_models/#Fixed-Effects-Extraction","page":"MixedModels.jl","title":"Fixed Effects Extraction","text":"","category":"section"},{"location":"integration/mixed_models/#Automatic-Extraction","page":"MixedModels.jl","title":"Automatic Extraction","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"# Mixed model with various random effects structures\nmixed_model = fit(MixedModel, @formula(y ~ x * treatment + age + (1|group) + (x|cluster)), df)\n\n# Fixed effects formula: y ~ x * treatment + age\nfixed_formula = fixed_effects_form(mixed_model)\nprintln(\"Fixed effects: \", fixed_formula)\n\n# Compile fixed effects only\ncompiled = compile_formula(mixed_model, data)","category":"page"},{"location":"integration/mixed_models/#Manual-Fixed-Effects","page":"MixedModels.jl","title":"Manual Fixed Effects","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"# If you need more control, extract manually\nfixed_form = mixed_model.formula.rhs.terms[1]  # Gets fixed effects terms\nmanual_model = lm(FormulaTerm(mixed_model.formula.lhs, fixed_form), df)\ncompiled_manual = compile_formula(manual_model, data)","category":"page"},{"location":"integration/mixed_models/#Use-Cases","page":"MixedModels.jl","title":"Use Cases","text":"","category":"section"},{"location":"integration/mixed_models/#Population-Level-Predictions","page":"MixedModels.jl","title":"Population-Level Predictions","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"function population_predictions(mixed_model, data, scenarios)\n    # Compile fixed effects\n    compiled = compile_formula(mixed_model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    results = Dict{String, Vector{Float64}}()\n    \n    for (scenario_name, scenario) in scenarios\n        n_obs = Tables.rowcount(scenario.data)\n        predictions = Vector{Float64}(undef, n_obs)\n        \n        for i in 1:n_obs\n            compiled(row_vec, scenario.data, i)\n            # This gives the fixed effects linear predictor\n            predictions[i] = dot(fixef(mixed_model), row_vec)\n        end\n        \n        results[scenario_name] = predictions\n    end\n    \n    return results\nend\n\n# Example usage with data modification\nn_rows = length(data.treatment)\n\n# Baseline scenario\ndata_control = merge(data, (treatment = fill(false, n_rows),))  # No treatment\nbaseline_predictions = population_predictions_single(mixed_model, data_control, \"baseline\")\n\n# Treatment scenario\ndata_treated = merge(data, (treatment = fill(true, n_rows),))  # Treatment\ntreatment_predictions = population_predictions_single(mixed_model, data_treated, \"treatment\")","category":"page"},{"location":"integration/mixed_models/#Marginal-Effects-for-Fixed-Effects","page":"MixedModels.jl","title":"Marginal Effects for Fixed Effects","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"function marginal_effects_mixed(mixed_model, data, variable)\n    compiled = compile_formula(mixed_model, data)\n    fixed_coefs = fixef(mixed_model)\n    \n    # Create perturbed data\n    delta = 0.01\n    original_values = data[variable]\n    perturbed_values = original_values .+ delta\n    perturbed_data = (; data..., variable => perturbed_values)\n    \n    row_vec_orig = Vector{Float64}(undef, length(compiled))\n    row_vec_pert = Vector{Float64}(undef, length(compiled))\n    \n    n_obs = Tables.rowcount(data)\n    marginal_effects = Vector{Float64}(undef, n_obs)\n    \n    for i in 1:n_obs\n        compiled(row_vec_orig, data, i)\n        compiled(row_vec_pert, perturbed_data, i)\n        \n        pred_orig = dot(fixed_coefs, row_vec_orig)\n        pred_pert = dot(fixed_coefs, row_vec_pert)\n        \n        marginal_effects[i] = (pred_pert - pred_orig) / delta\n    end\n    \n    return marginal_effects\nend","category":"page"},{"location":"integration/mixed_models/#Performance-Comparison","page":"MixedModels.jl","title":"Performance Comparison","text":"","category":"section"},{"location":"integration/mixed_models/#Comparison-with-modelmatrix","page":"MixedModels.jl","title":"Comparison with modelmatrix","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"using BenchmarkTools\n\n# Setup mixed model\nmixed_model = fit(MixedModel, @formula(y ~ x + treatment + (1|group)), df)\ndata = Tables.columntable(df)\n\n# Traditional approach: extract full model matrix\nfunction traditional_mixed_row(model, row_idx)\n    # Get fixed effects design matrix\n    X = modelmatrix(model.optsum.lm)  # Linear model component\n    return X[row_idx, :]\nend\n\n# FormulaCompiler approach\ncompiled = compile_formula(mixed_model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\nfunction fc_mixed_row(compiled, data, row_vec, row_idx)\n    compiled(row_vec, data, row_idx)\n    return row_vec\nend\n\n# Benchmark\nprintln(\"Traditional mixed model row extraction:\")\n@benchmark traditional_mixed_row($mixed_model, 1)\n\nprintln(\"FormulaCompiler mixed model row extraction:\")\n@benchmark fc_mixed_row($compiled, $data, $row_vec, 1)","category":"page"},{"location":"integration/mixed_models/#Advanced-Examples","page":"MixedModels.jl","title":"Advanced Examples","text":"","category":"section"},{"location":"integration/mixed_models/#Bootstrap-Fixed-Effects","page":"MixedModels.jl","title":"Bootstrap Fixed Effects","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"function bootstrap_fixed_effects(mixed_model, data, n_bootstrap=1000)\n    compiled = compile_formula(mixed_model, data)\n    n_obs = Tables.rowcount(data)\n    n_coefs = length(compiled)\n    \n    # Get response variable\n    y_var = Symbol(mixed_model.formula.lhs)\n    y = data[y_var]\n    \n    bootstrap_coefs = Matrix{Float64}(undef, n_bootstrap, n_coefs)\n    row_vec = Vector{Float64}(undef, n_coefs)\n    \n    for boot in 1:n_bootstrap\n        # Bootstrap sample\n        sample_idx = rand(1:n_obs, n_obs)\n        \n        # Build design matrix for bootstrap sample\n        X_boot = Matrix{Float64}(undef, n_obs, n_coefs)\n        y_boot = Vector{Float64}(undef, n_obs)\n        \n        for (i, idx) in enumerate(sample_idx)\n            compiled(row_vec, data, idx)\n            X_boot[i, :] .= row_vec\n            y_boot[i] = y[idx]\n        end\n        \n        # Estimate fixed effects (OLS approximation)\n        bootstrap_coefs[boot, :] = X_boot \\ y_boot\n    end\n    \n    return bootstrap_coefs\nend\n\n# Usage\nboot_coefs = bootstrap_fixed_effects(mixed_model, data, 1000)\n\n# Confidence intervals\nusing Statistics\nconf_intervals = [\n    (quantile(boot_coefs[:, j], 0.025), quantile(boot_coefs[:, j], 0.975))\n    for j in 1:size(boot_coefs, 2)\n]","category":"page"},{"location":"integration/mixed_models/#Policy-Scenario-Analysis","page":"MixedModels.jl","title":"Policy Scenario Analysis","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"function analyze_policy_scenarios(mixed_model, base_data)\n    compiled = compile_formula(mixed_model, base_data)\n    fixed_coefs = fixef(mixed_model)\n    \n    # Define policy scenarios using data modification\n    n_obs = Tables.rowcount(base_data)\n\n    policy_configs = [\n        (\"baseline\", false, nothing, nothing),          # No treatment, original x and support\n        (\"universal_treatment\", true, nothing, nothing), # Treatment, original x and support\n        (\"targeted_treatment\", true, quantile(base_data.x, 0.75), nothing), # Treatment + top 25% x\n        (\"enhanced_policy\", true, mean(base_data.x), 1.0)  # Treatment + mean x + support\n    ]\n\n    results = Dict{String, NamedTuple}()\n    row_vec = Vector{Float64}(undef, length(compiled))\n\n    for (name, treatment_val, x_val, support_val) in policy_configs\n        # Create modified data for this policy\n        modified_data = base_data  # Start with baseline\n\n        if name != \"baseline\"\n            # Build modification dictionary\n            mods = Dict{Symbol, Any}()\n            mods[:treatment] = fill(treatment_val, n_obs)\n\n            if x_val !== nothing\n                mods[:x] = fill(x_val, n_obs)\n            end\n\n            if support_val !== nothing\n                mods[:additional_support] = fill(support_val, n_obs)\n            end\n\n            modified_data = merge(base_data, NamedTuple(mods))\n        end\n\n        predictions = Vector{Float64}(undef, n_obs)\n\n        for i in 1:n_obs\n            compiled(row_vec, modified_data, i)\n            predictions[i] = dot(fixed_coefs, row_vec)\n        end\n        \n        results[name] = (\n            mean_outcome = mean(predictions),\n            std_outcome = std(predictions),\n            quantiles = [quantile(predictions, q) for q in [0.25, 0.5, 0.75]]\n        )\n    end\n    \n    return results\nend\n\n# Run analysis\npolicy_results = analyze_policy_scenarios(mixed_model, data)\n\n# Display results\nfor (policy, stats) in policy_results\n    println(\"Policy: $policy\")\n    println(\"  Mean outcome: $(round(stats.mean_outcome, digits=3))\")\n    println(\"  Std outcome: $(round(stats.std_outcome, digits=3))\")\n    println(\"  Quartiles: $(round.(stats.quantiles, digits=3))\")\n    println()\nend","category":"page"},{"location":"integration/mixed_models/#Integration-Notes","page":"MixedModels.jl","title":"Integration Notes","text":"","category":"section"},{"location":"integration/mixed_models/#What's-Included","page":"MixedModels.jl","title":"What's Included","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Fixed effects terms only\nInteraction terms involving fixed effects\nFunctions applied to fixed effects predictors","category":"page"},{"location":"integration/mixed_models/#What's-Excluded","page":"MixedModels.jl","title":"What's Excluded","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Random effects terms (1|group), (x|group)\nRandom intercepts and slopes\nCross-level interactions involving random effects","category":"page"},{"location":"integration/mixed_models/#Validation","page":"MixedModels.jl","title":"Validation","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"function validate_mixed_model_integration(mixed_model, data)\n    compiled = compile_formula(mixed_model, data)\n    \n    # Extract fixed effects design matrix from MixedModels.jl\n    mm_fixed = modelmatrix(mixed_model.optsum.lm)\n    \n    # Compare with FormulaCompiler\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    for i in 1:min(10, size(mm_fixed, 1))\n        compiled(row_vec, data, i)\n        original_row = mm_fixed[i, :]\n        \n        if !isapprox(row_vec, original_row, rtol=1e-12)\n            @warn \"Mismatch in row $i\"\n            return false\n        end\n    end\n    \n    println(\"✓ FormulaCompiler matches MixedModels.jl fixed effects matrix\")\n    return true\nend","category":"page"},{"location":"integration/mixed_models/#Best-Practices","page":"MixedModels.jl","title":"Best Practices","text":"","category":"section"},{"location":"integration/mixed_models/#When-to-Use-FormulaCompiler-with-Mixed-Models","page":"MixedModels.jl","title":"When to Use FormulaCompiler with Mixed Models","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Supported patterns:","category":"page"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Population-level predictions\nFixed effects marginal effects\nPolicy scenario analysis\nBootstrap inference on fixed effects","category":"page"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Not suitable for:","category":"page"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"Predictions requiring random effects (BLUPs)\nIndividual-level predictions in clustered data\nRandom effects inference\nCross-level interaction effects","category":"page"},{"location":"integration/mixed_models/#Performance-Considerations","page":"MixedModels.jl","title":"Performance Considerations","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"# For repeated evaluations, compile once\nmixed_model = fit(MixedModel, @formula(y ~ x + (1|group)), df)\ncompiled = compile_formula(mixed_model, data)  # Do this once\n\n# Then evaluate many times\nrow_vec = Vector{Float64}(undef, length(compiled))\nfor scenario in many_scenarios\n    for individual in many_individuals\n        compiled(row_vec, scenario.data, individual)\n        # Process fixed effects prediction...\n    end\nend","category":"page"},{"location":"integration/mixed_models/#Memory-Efficiency","page":"MixedModels.jl","title":"Memory Efficiency","text":"","category":"section"},{"location":"integration/mixed_models/","page":"MixedModels.jl","title":"MixedModels.jl","text":"# Mixed models can be large - use data modification for memory efficiency\nlarge_mixed_model = fit(MixedModel, complex_formula, large_df)\nbase_data = Tables.columntable(large_df)\n\n# Instead of creating many copies of large_df\n# Use merge() to override just the variables of interest\nn_rows = length(base_data.key_variable)\nmodified_data = merge(base_data, (key_variable = fill(new_value, n_rows),))\n\n# Evaluate with minimal memory overhead\ncompiled = compile_formula(large_mixed_model, base_data)\n# ... use compiled with modified_data","category":"page"},{"location":"guide/performance/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"This guide covers best practices for achieving maximum performance with FormulaCompiler.jl.","category":"page"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"For basic performance patterns, see Basic Usage. For advanced optimization techniques, see Advanced Features.","category":"page"},{"location":"guide/performance/#Core-Performance-Principles","page":"Performance Tips","title":"Core Performance Principles","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"FormulaCompiler.jl achieves zero-allocation performance through:","category":"page"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"Compile-time specialization: Move expensive computations to compile time\nType stability: Ensure all operations are type-predictable\nMemory reuse: Pre-allocate and reuse output vectors\nEfficient data structures: Use column tables for optimal access patterns\nLow-allocation automatic differentiation: Preallocation and specialization minimize AD memory overhead","category":"page"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"Automatic Differentiation: FormulaCompiler.jl provides ForwardDiff-based derivatives with small, bounded allocations per call, and a finite-difference backend with zero allocations. Choose the backend per workload and accuracy needs.","category":"page"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"For a detailed understanding of how compile-time specialization is implemented, including the use of metaprogramming for complex formulas and derivative computation, see Metaprogramming.","category":"page"},{"location":"guide/performance/#Runtime-Execution-Flow","page":"Performance Tips","title":"Runtime Execution Flow","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"Here's what happens during each evaluation:","category":"page"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"(Image: Diagram)","category":"page"},{"location":"guide/performance/#Pre-compilation-Best-Practices","page":"Performance Tips","title":"Pre-compilation Best Practices","text":"","category":"section"},{"location":"guide/performance/#Compile-Once,-Use-Many-Times","page":"Performance Tips","title":"Compile Once, Use Many Times","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# Good: Compile once\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Use many times (zero allocations)\nfor i in 1:1000\n    compiled(row_vec, data, i % nrow(data) + 1)\n    # Process result...\nend\n\n# Bad: Compile every time\nfor i in 1:1000\n    result = modelrow(model, data, i % nrow(data) + 1)  # Compiles and allocates\nend","category":"page"},{"location":"guide/performance/#Data-Format-Optimization","page":"Performance Tips","title":"Data Format Optimization","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"using Tables, DataFrames\n\ndf = DataFrame(x = randn(10000), y = randn(10000))\n\n# Best: Column table format (convert once)\ndata = Tables.columntable(df)  # Convert once\ncompiled = compile_formula(model, data)\n\n# Benchmark the effect of data format\nusing BenchmarkTools\n\n@benchmark $compiled($row_vec, $data, 1)        # Preferred path","category":"page"},{"location":"guide/performance/#Memory-Management","page":"Performance Tips","title":"Memory Management","text":"","category":"section"},{"location":"guide/performance/#Pre-allocation-Strategies","page":"Performance Tips","title":"Pre-allocation Strategies","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# Pre-allocate output vectors\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# For batch processing\nn_rows = 1000\nbatch_matrix = Matrix{Float64}(undef, n_rows, length(compiled))\n\n# Reuse across operations\nfor batch_start in 1:n_rows:total_rows\n    batch_end = min(batch_start + n_rows - 1, total_rows)\n\n    # Evaluate each row in the batch\n    for i in batch_start:batch_end\n        idx = i - batch_start + 1\n        compiled(view(batch_matrix, idx, :), data, i)\n    end\nend","category":"page"},{"location":"guide/performance/#Memory-Layout-Optimization","page":"Performance Tips","title":"Memory Layout Optimization","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# For repeated operations on the same rows\nfunction optimized_repeated_evaluation(compiled, data, row_indices, n_repetitions)\n    n_rows = length(row_indices)\n    n_cols = length(compiled)\n    \n    # Pre-allocate everything\n    results = Array{Float64, 3}(undef, n_repetitions, n_rows, n_cols)\n    row_vec = Vector{Float64}(undef, n_cols)\n    \n    for rep in 1:n_repetitions\n        for (i, row_idx) in enumerate(row_indices)\n            compiled(row_vec, data, row_idx)\n            results[rep, i, :] .= row_vec\n        end\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/performance/#Benchmarking-and-Profiling","page":"Performance Tips","title":"Benchmarking and Profiling","text":"","category":"section"},{"location":"guide/performance/#Basic-Performance-Testing","page":"Performance Tips","title":"Basic Performance Testing","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"using BenchmarkTools\n\nfunction benchmark_formula_compilation(model, data)\n    # Benchmark compilation\n    compilation_time = @benchmark compile_formula($model, $data)\n    \n    # Benchmark evaluation\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    evaluation_time = @benchmark $compiled($row_vec, $data, 1)\n    \n    return (compilation = compilation_time, evaluation = evaluation_time)\nend\n\n# Run benchmark\nresults = benchmark_formula_compilation(model, data)\nprintln(\"Compilation: \", results.compilation)\nprintln(\"Evaluation: \", results.evaluation)","category":"page"},{"location":"guide/performance/#Allocation-Detection","page":"Performance Tips","title":"Allocation Detection","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"function check_zero_allocations(compiled, data, n_tests=1000)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Warm up\n    compiled(row_vec, data, 1)\n    \n    # Test for allocations\n    allocs_before = Base.gc_alloc_count()\n    \n    for i in 1:n_tests\n        compiled(row_vec, data, i % nrow(data) + 1)\n    end\n    \n    allocs_after = Base.gc_alloc_count()\n    \n    if allocs_after > allocs_before\n        @warn \"Detected $(allocs_after - allocs_before) allocations in $n_tests evaluations\"\n    else\n        println(\"✓ Zero allocations confirmed for $n_tests evaluations\")\n    end\nend\n\ncheck_zero_allocations(compiled, data)","category":"page"},{"location":"guide/performance/#Performance-Profiling","page":"Performance Tips","title":"Performance Profiling","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"using Profile, ProfileView\n\nfunction profile_performance(compiled, data, n_evaluations=100_000)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Profile execution\n    Profile.clear()\n    @profile begin\n        for i in 1:n_evaluations\n            compiled(row_vec, data, i % nrow(data) + 1)\n        end\n    end\n    \n    # Analyze results\n    ProfileView.view()  # Opens interactive profile viewer\nend","category":"page"},{"location":"guide/performance/#Formula-Specific-Optimizations","page":"Performance Tips","title":"Formula-Specific Optimizations","text":"","category":"section"},{"location":"guide/performance/#Simple-vs-Complex-Formulas","page":"Performance Tips","title":"Simple vs Complex Formulas","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# Simple formulas are fastest\nsimple_model = lm(@formula(y ~ x + z), df)\nsimple_compiled = compile_formula(simple_model, data)\n\n# Complex formulas still achieve zero allocation but are slower\ncomplex_model = lm(@formula(y ~ x * group * treatment + log(z) + sqrt(abs(w))), df)\ncomplex_compiled = compile_formula(complex_model, data)\n\n# Benchmark both\n@benchmark $simple_compiled($row_vec, $data, 1)\n@benchmark $complex_compiled($row_vec, $data, 1)","category":"page"},{"location":"guide/performance/#Categorical-Variable-Optimization","page":"Performance Tips","title":"Categorical Variable Optimization","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"using CategoricalArrays\n\n# Ordered categoricals can be more efficient\ndf.ordered_group = categorical(df.group, ordered=true)\n\n# Use efficient contrast coding\ncontrasts_dict = Dict(:group => DummyCoding())\nmodel_with_contrasts = lm(@formula(y ~ x + group), df, contrasts=contrasts_dict)","category":"page"},{"location":"guide/performance/#Function-Optimization-Tips","page":"Performance Tips","title":"Function Optimization Tips","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# Some functions are more efficient than others\nfast_functions = [\n    @formula(y ~ log(x)),      # Fast\n    @formula(y ~ exp(x)),      # Fast\n    @formula(y ~ sqrt(x)),     # Fast\n    @formula(y ~ x^2),         # Fast\n    @formula(y ~ abs(x))       # Fast\n]\n\nslower_functions = [\n    @formula(y ~ sin(x)),      # Slower\n    @formula(y ~ cos(x)),      # Slower\n    @formula(y ~ x^3.5)        # Slower (non-integer powers)\n]","category":"page"},{"location":"guide/performance/#Large-Dataset-Strategies","page":"Performance Tips","title":"Large Dataset Strategies","text":"","category":"section"},{"location":"guide/performance/#Chunked-Processing","page":"Performance Tips","title":"Chunked Processing","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"function process_large_dataset_efficiently(model, data, chunk_size=10_000)\n    compiled = compile_formula(model, data)\n    n_rows = Tables.rowcount(data)\n    n_cols = length(compiled)\n    \n    # Pre-allocate chunk matrix\n    chunk_matrix = Matrix{Float64}(undef, chunk_size, n_cols)\n    \n    results = Vector{Matrix{Float64}}()\n    \n    for start_idx in 1:chunk_size:n_rows\n        end_idx = min(start_idx + chunk_size - 1, n_rows)\n        actual_chunk_size = end_idx - start_idx + 1\n\n        # Zero-allocation batch evaluation\n        for (chunk_row, data_row) in enumerate(start_idx:end_idx)\n            compiled(view(chunk_matrix, chunk_row, :), data, data_row)\n        end\n\n        # Store results (this allocates, but unavoidable for storage)\n        chunk_view = view(chunk_matrix, 1:actual_chunk_size, :)\n        push!(results, copy(chunk_view))\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/performance/#Parallel-Processing","page":"Performance Tips","title":"Parallel Processing","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"using Distributed\n\n@everywhere using FormulaCompiler\n\nfunction parallel_formula_evaluation(model, data, row_indices)\n    # Compile on each worker\n    compiled = compile_formula(model, data)\n    \n    # Distributed evaluation\n    results = @distributed (vcat) for row_idx in row_indices\n        row_vec = Vector{Float64}(undef, length(compiled))\n        compiled(row_vec, data, row_idx)\n        row_vec'  # Return as row matrix\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/performance/#Optimization-Anti-patterns","page":"Performance Tips","title":"Optimization Anti-patterns","text":"","category":"section"},{"location":"guide/performance/#What-NOT-to-Do","page":"Performance Tips","title":"What NOT to Do","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# DON'T: Recompile in loops\nfor i in 1:1000\n    result = modelrow(model, data, i)  # Recompiles every time!\nend\n\n# DON'T: Pass DataFrames directly to compiled evaluators in tight loops\n#        Convert once to a column table outside the loop\n\n# DON'T: Forget to pre-allocate\nresults = []\nfor i in 1:1000\n    compiled(row_vec, data, i)\n    push!(results, copy(row_vec))  # Allocates and copies!\nend\n\n# DON'T: Create unnecessary temporary arrays\nfor i in 1:1000\n    compiled(row_vec, data, i)\n    result = row_vec .+ 1.0  # Allocates new array!\nend","category":"page"},{"location":"guide/performance/#Better-Alternatives","page":"Performance Tips","title":"Better Alternatives","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"# DO: Compile once, pre-allocate, reuse\ncompiled = compile_formula(model, data)\ndata_table = Tables.columntable(df)\nrow_vec = Vector{Float64}(undef, length(compiled))\nresults = Matrix{Float64}(undef, 1000, length(compiled))\n\nfor i in 1:1000\n    compiled(row_vec, data_table, i)\n    results[i, :] .= row_vec  # In-place assignment\nend\n\n# DO: Use broadcasting for transformations\nresults .+= 1.0  # In-place broadcasting","category":"page"},{"location":"guide/performance/#Performance-Monitoring","page":"Performance Tips","title":"Performance Monitoring","text":"","category":"section"},{"location":"guide/performance/#Continuous-Performance-Testing","page":"Performance Tips","title":"Continuous Performance Testing","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"function performance_regression_test(model, data, target_time_ns=200)\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    # Warm up\n    compiled(row_vec, data, 1)\n    \n    # Time single evaluation\n    time_ns = @elapsed begin\n        for _ in 1:100\n            compiled(row_vec, data, 1)\n        end\n    end * 1e9 / 100  # Convert to ns per evaluation\n    \n    # Absolute times vary by hardware and Julia version; tune target_time_ns accordingly.\n    if time_ns > target_time_ns\n        @warn \"Performance regression detected: $(round(time_ns))ns > $(target_time_ns)ns\"\n    else\n        println(\"✓ Performance target met: $(round(time_ns))ns ≤ $(target_time_ns)ns\")\n    end\n    \n    return time_ns\nend","category":"page"},{"location":"guide/performance/#Memory-Usage-Monitoring","page":"Performance Tips","title":"Memory Usage Monitoring","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"function memory_usage_test(model, data)\n    # Measure compilation memory\n    compilation_memory = @allocated compile_formula(model, data)\n    \n    # Measure evaluation memory\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    \n    evaluation_memory = @allocated compiled(row_vec, data, 1)\n    \n    println(\"Compilation memory: $(compilation_memory) bytes\")\n    println(\"Evaluation memory: $(evaluation_memory) bytes\")\n    \n    if evaluation_memory > 0\n        @warn \"Non-zero allocation in evaluation: $(evaluation_memory) bytes\"\n    end\n    \n    return (compilation = compilation_memory, evaluation = evaluation_memory)\nend","category":"page"},{"location":"guide/performance/#Real-world-Performance-Examples","page":"Performance Tips","title":"Real-world Performance Examples","text":"","category":"section"},{"location":"guide/performance/#Monte-Carlo-Simulation","page":"Performance Tips","title":"Monte Carlo Simulation","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"function efficient_monte_carlo(model, data, n_simulations=1_000_000)\n    compiled = compile_formula(model, data)\n    row_vec = Vector{Float64}(undef, length(compiled))\n    results = Vector{Float64}(undef, n_simulations)\n    \n    # Pre-compute random indices\n    row_indices = rand(1:nrow(data), n_simulations)\n    \n    @time begin\n        for i in 1:n_simulations\n            compiled(row_vec, data, row_indices[i])\n            results[i] = some_statistic(row_vec)  # Your analysis function\n        end\n    end\n    \n    return results\nend","category":"page"},{"location":"guide/performance/#Bootstrap-Resampling","page":"Performance Tips","title":"Bootstrap Resampling","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"function efficient_bootstrap(model, data, n_bootstrap=1000)\n    compiled = compile_formula(model, data)\n    n_rows = nrow(data)\n    n_cols = length(compiled)\n    \n    bootstrap_results = Matrix{Float64}(undef, n_bootstrap, n_cols)\n    row_vec = Vector{Float64}(undef, n_cols)\n    \n    for boot in 1:n_bootstrap\n        # Generate bootstrap sample indices\n        sample_indices = rand(1:n_rows, n_rows)\n        \n        # Compute bootstrap statistic\n        for (i, row_idx) in enumerate(sample_indices)\n            compiled(row_vec, data, row_idx)\n            if i == 1\n                bootstrap_results[boot, :] .= row_vec\n            else\n                bootstrap_results[boot, :] .+= row_vec\n            end\n        end\n        \n        bootstrap_results[boot, :] ./= n_rows  # Average\n    end\n    \n    return bootstrap_results\nend","category":"page"},{"location":"guide/performance/#Summary","page":"Performance Tips","title":"Summary","text":"","category":"section"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"Key performance guidelines:","category":"page"},{"location":"guide/performance/","page":"Performance Tips","title":"Performance Tips","text":"Compile once: Never recompile formulas in loops\nPre-allocate: Create output vectors once and reuse\nUse column tables: Convert DataFrames to Tables.columntable format\nProfile regularly: Monitor for performance regressions\nBatch when possible: Use modelrow! for multiple rows","category":"page"},{"location":"#FormulaCompiler.jl","page":"Home","title":"FormulaCompiler.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"FormulaCompiler implements a type-stable counterfactual vector system providing variable substitution with O(1) memory overhead without data duplication. This is particularly useful for policy analysis and treatment effect evaluation.","category":"page"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Memory efficiency: Per-row evaluation with zero allocations\nComputational performance: Improvements over traditional modelmatrix() approaches for single-row evaluations  \nComprehensive compatibility: Supports all valid StatsModels.jl formulas, including complex interactions and mathematical functions\nCategorical mixtures: Compile-time support for weighted categorical specifications for marginal effects\nScenario analysis: Memory-efficient variable override system for counterfactual analysis\nUnified architecture: Single compilation pipeline accommodates diverse formula structures\nEcosystem integration: Compatible with GLM.jl, MixedModels.jl, and StandardizedPredictors.jl\nDual-backend derivatives: Memory-efficient finite differences and ForwardDiff automatic differentiation options (ForwarDiff is the strongly preferred default option)","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url = \"https://github.com/emfeltham/FormulaCompiler.jl\")","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Workflow)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Figure: Basic FormulaCompiler.jl workflow","category":"page"},{"location":"","page":"Home","title":"Home","text":"using FormulaCompiler, GLM, DataFrames, Tables\n\n# Fit your model normally\ndf = DataFrame(\n    y = randn(1000),\n    x = randn(1000),\n    z = abs.(randn(1000)) .+ 0.1,\n    group = categorical(rand([\"A\", \"B\", \"C\"], 1000))\n)\n\nmodel = lm(@formula(y ~ x * group + log(z)), df)\n\n# Compile once for efficient repeated evaluation  \ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n# Memory-efficient evaluation suitable for repeated calls\ncompiled(row_vec, data, 1)  # Zero allocations after warmup","category":"page"},{"location":"#Performance-Comparison","page":"Home","title":"Performance Comparison","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Performance results across all tested formula types:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using BenchmarkTools\n\n# Traditional approach (creates full model matrix)\n@benchmark modelmatrix(model)[1, :]\n# Traditional approach with allocation overhead\n\n# FormulaCompiler (zero-allocation single row)\ndata = Tables.columntable(df)\ncompiled = compile_formula(model, data)\nrow_vec = Vector{Float64}(undef, length(compiled))\n\n@benchmark compiled(row_vec, data, 1)\n# FormulaCompiler approach with zero allocations\n","category":"page"},{"location":"","page":"Home","title":"Home","text":"Zero Allocations (verified in test suite):","category":"page"},{"location":"","page":"Home","title":"Home","text":"Core row evaluation (compiled(row,data,i))\nScenario evaluation (CounterfactualVector)\nFD Jacobian\nAD Jacobian","category":"page"},{"location":"#Allocation-Characteristics","page":"Home","title":"Allocation Characteristics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"FormulaCompiler.jl provides different allocation guarantees depending on the operation:","category":"page"},{"location":"#Core-Model-Evaluation","page":"Home","title":"Core Model Evaluation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Zero allocations: modelrow!() and direct compiled() calls are 0 bytes after warmup\nPerformance: Fast per-row evaluation across all formula complexities\nValidated: Test cases confirm zero-allocation performance","category":"page"},{"location":"#Derivative-Operations","page":"Home","title":"Derivative Operations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"FormulaCompiler.jl provides computational primitives for derivatives with dual backend support:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Backend Type Allocations Performance Accuracy Recommendation\nAutomatic Differentiation ADEvaluator 0 bytes Fast Machine precision Strongly preferred default\nFinite Differences FDEvaluator 0 bytes Fast ~1e-8 -","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Build evaluator with automatic differentiation (strongly recommended)\nde = derivativeevaluator(:ad, compiled, data, vars)  # Automatic differentiation\n\n# Compute Jacobian with zero allocations\nJ = Matrix{Float64}(undef, length(compiled), length(vars))\nderivative_modelrow!(J, de, row)  # 0 bytes, machine precision\n\n# For marginal effects, use Margins.jl\nusing Margins\ng = Vector{Float64}(undef, length(vars))\nmarginal_effects_eta!(g, de, beta, row)  # Marginal effects on η","category":"page"},{"location":"#Use-Cases","page":"Home","title":"Use Cases","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Monte Carlo simulations with large data and many model evaluations\nBootstrap resampling: Repeated matrix construction\nMarginal effects: cf. Margins.jl which is built on FormulaCompiler.jl","category":"page"},{"location":"#Next-Steps","page":"Home","title":"Next Steps","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Read the Getting Started guide for a detailed walkthrough\nExplore Advanced Features for scenario analysis and memory optimization\nLearn about Categorical Mixtures for marginal effects computation\nSee StandardizedPredictors Integration for comprehensive z-score standardization workflows\nCheck out Examples for real-world use cases\nReview the Mathematical Foundation for comprehensive theory and implementation details\nReview the API Reference for complete function documentation\nReproduce results with the Benchmark Protocol","category":"page"}]
}
