<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Mathematical Foundation · FormulaCompiler.jl</title><meta name="title" content="Mathematical Foundation · FormulaCompiler.jl"/><meta property="og:title" content="Mathematical Foundation · FormulaCompiler.jl"/><meta property="twitter:title" content="Mathematical Foundation · FormulaCompiler.jl"/><meta name="description" content="Documentation for FormulaCompiler.jl."/><meta property="og:description" content="Documentation for FormulaCompiler.jl."/><meta property="twitter:description" content="Documentation for FormulaCompiler.jl."/><meta property="og:url" content="https://emfeltham.github.io/FormulaCompiler.jl/mathematical_foundation/"/><meta property="twitter:url" content="https://emfeltham.github.io/FormulaCompiler.jl/mathematical_foundation/"/><link rel="canonical" href="https://emfeltham.github.io/FormulaCompiler.jl/mathematical_foundation/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><script src="../assets/mermaid.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">FormulaCompiler.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../guide/basic_usage/">Basic Usage</a></li><li><a class="tocitem" href="../guide/advanced_features/">Advanced Features</a></li><li><a class="tocitem" href="../guide/categorical_mixtures/">Categorical Mixtures</a></li><li><a class="tocitem" href="../guide/scenarios/">Scenario Analysis</a></li><li><a class="tocitem" href="../guide/performance/">Performance Tips</a></li></ul></li><li><span class="tocitem">Ecosystem Integration</span><ul><li><a class="tocitem" href="../integration/glm/">GLM.jl</a></li><li><a class="tocitem" href="../integration/mixed_models/">MixedModels.jl</a></li><li><a class="tocitem" href="../integration/standardized_predictors/">StandardizedPredictors.jl</a></li></ul></li><li class="is-active"><a class="tocitem" href>Mathematical Foundation</a><ul class="internal"><li><a class="tocitem" href="#Table-of-Contents"><span>Table of Contents</span></a></li><li><a class="tocitem" href="#Statistical-Model-Representation"><span>Statistical Model Representation</span></a></li><li><a class="tocitem" href="#Formula-Compilation-Mathematics"><span>Formula Compilation Mathematics</span></a></li><li><a class="tocitem" href="#Position-Mapping"><span>Position Mapping</span></a></li><li><a class="tocitem" href="#Derivative-Computation"><span>Derivative Computation</span></a></li><li><a class="tocitem" href="#Marginal-Effects"><span>Marginal Effects</span></a></li><li><a class="tocitem" href="#Variance-Estimation-and-Standard-Errors"><span>Variance Estimation and Standard Errors</span></a></li><li><a class="tocitem" href="#Computational-Efficiency"><span>Computational Efficiency</span></a></li><li><a class="tocitem" href="#Implementation-Notes"><span>Implementation Notes</span></a></li></ul></li><li><a class="tocitem" href="../architecture/">Architecture</a></li><li><a class="tocitem" href="../metaprogramming/">Metaprogramming</a></li><li><a class="tocitem" href="../api/">API Reference</a></li><li><a class="tocitem" href="../examples/">Examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Mathematical Foundation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Mathematical Foundation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/emfeltham/FormulaCompiler.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/emfeltham/FormulaCompiler.jl/blob/main/docs/src/mathematical_foundation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Mathematical-and-Statistical-Foundation"><a class="docs-heading-anchor" href="#Mathematical-and-Statistical-Foundation">Mathematical and Statistical Foundation</a><a id="Mathematical-and-Statistical-Foundation-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-and-Statistical-Foundation" title="Permalink"></a></h1><p>This document provides a comprehensive walkthrough of the mathematical and statistical concepts underlying FormulaCompiler.jl, from basic formula representation to advanced derivative computations and variance estimation.</p><h2 id="Table-of-Contents"><a class="docs-heading-anchor" href="#Table-of-Contents">Table of Contents</a><a id="Table-of-Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Table-of-Contents" title="Permalink"></a></h2><ol><li><a href="#statistical-model-representation">Statistical Model Representation</a></li><li><a href="#formula-compilation-mathematics">Formula Compilation Mathematics</a></li><li><a href="#position-mapping-theory">Position Mapping Theory</a></li><li><a href="#derivative-computation">Derivative Computation</a></li><li><a href="#marginal-effects-theory">Marginal Effects Theory</a></li><li><a href="#variance-estimation-and-standard-errors">Variance Estimation and Standard Errors</a></li><li><a href="#computational-efficiency-theory">Computational Efficiency Theory</a></li></ol><h2 id="Statistical-Model-Representation"><a class="docs-heading-anchor" href="#Statistical-Model-Representation">Statistical Model Representation</a><a id="Statistical-Model-Representation-1"></a><a class="docs-heading-anchor-permalink" href="#Statistical-Model-Representation" title="Permalink"></a></h2><h3 id="Linear-Models"><a class="docs-heading-anchor" href="#Linear-Models">Linear Models</a><a id="Linear-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Models" title="Permalink"></a></h3><p>FormulaCompiler.jl operates on statistical models of the form:</p><p class="math-container">\[\mathbb{E}[y_i] = \mathbf{x}_i^T \boldsymbol{\beta}\]</p><p>where:</p><ul><li><p class="math-container">\[y_i\]</p>is the response for observation <span>$i$</span></li><li><p class="math-container">\[\mathbf{x}_i \in \mathbb{R}^p\]</p>is the model matrix row (predictor vector)</li><li><p class="math-container">\[\boldsymbol{\beta} \in \mathbb{R}^p\]</p>is the parameter vector</li></ul><h3 id="Generalized-Linear-Models"><a class="docs-heading-anchor" href="#Generalized-Linear-Models">Generalized Linear Models</a><a id="Generalized-Linear-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Generalized-Linear-Models" title="Permalink"></a></h3><p>For GLMs, we have:</p><p class="math-container">\[\mathbb{E}[y_i] = \mu_i = g^{-1}(\eta_i)\]</p><p class="math-container">\[\eta_i = \mathbf{x}_i^T \boldsymbol{\beta}\]</p><p>where:</p><ul><li><p class="math-container">\[\eta_i\]</p>is the linear predictor</li><li><p class="math-container">\[g(\cdot)\]</p>is the link function</li><li><p class="math-container">\[\mu_i\]</p>is the expected response</li></ul><h3 id="Mixed-Effects-Models"><a class="docs-heading-anchor" href="#Mixed-Effects-Models">Mixed Effects Models</a><a id="Mixed-Effects-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Mixed-Effects-Models" title="Permalink"></a></h3><p>For linear mixed models:</p><p class="math-container">\[\mathbb{E}[y_i] = \mathbf{x}_i^T \boldsymbol{\beta} + \mathbf{z}_i^T \mathbf{b}\]</p><p>where FormulaCompiler extracts only the fixed effects component <span>$\mathbf{x}_i^T \boldsymbol{\beta}$</span>.</p><h2 id="Formula-Compilation-Mathematics"><a class="docs-heading-anchor" href="#Formula-Compilation-Mathematics">Formula Compilation Mathematics</a><a id="Formula-Compilation-Mathematics-1"></a><a class="docs-heading-anchor-permalink" href="#Formula-Compilation-Mathematics" title="Permalink"></a></h2><p>FormulaCompiler.jl transforms statistical formulas through a systematic compilation process:</p><p><img src="../assets/src_architecture_diagram_7.svg" alt="Compilation Pipeline"/></p><p><em>Figure 1: The compilation pipeline transforms statistical formulas into position-mapped, type-specialized evaluators through systematic decomposition and analysis.</em></p><h3 id="Term-Decomposition"><a class="docs-heading-anchor" href="#Term-Decomposition">Term Decomposition</a><a id="Term-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Term-Decomposition" title="Permalink"></a></h3><p>A statistical formula like <code>y ~ x + z + x*group</code> is decomposed into atomic operations:</p><p class="math-container">\[\mathbf{x}_i = \begin{bmatrix}
1 \\
x_i \\
z_i \\
x_i \cdot \mathbf{1}(\text{group}_i = \text{B}) \\
x_i \cdot \mathbf{1}(\text{group}_i = \text{C})
\end{bmatrix}\]</p><h3 id="Categorical-Variables"><a class="docs-heading-anchor" href="#Categorical-Variables">Categorical Variables</a><a id="Categorical-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Categorical-Variables" title="Permalink"></a></h3><p>For a categorical variable with <span>$K$</span> levels using treatment contrast:</p><p class="math-container">\[\text{ContrastMatrix} = \begin{bmatrix}
0 &amp; 0 &amp; \cdots &amp; 0 \\
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1
\end{bmatrix} \in \mathbb{R}^{K \times (K-1)}\]</p><h3 id="Function-Application"><a class="docs-heading-anchor" href="#Function-Application">Function Application</a><a id="Function-Application-1"></a><a class="docs-heading-anchor-permalink" href="#Function-Application" title="Permalink"></a></h3><p>For transformed variables like <code>log(x)</code>:</p><p class="math-container">\[\text{FunctionOp}: x_i \mapsto f(x_i)\]</p><p>where <span>$f$</span> is applied element-wise with appropriate domain checking.</p><h2 id="Position-Mapping"><a class="docs-heading-anchor" href="#Position-Mapping">Position Mapping</a><a id="Position-Mapping-1"></a><a class="docs-heading-anchor-permalink" href="#Position-Mapping" title="Permalink"></a></h2><h3 id="Core-Concept"><a class="docs-heading-anchor" href="#Core-Concept">Core Concept</a><a id="Core-Concept-1"></a><a class="docs-heading-anchor-permalink" href="#Core-Concept" title="Permalink"></a></h3><p>The key innovation is mapping each formula term to a fixed position in the output vector at compile time:</p><p class="math-container">\[\text{Term}_j \rightarrow \text{Position}_j \in \{1, 2, \ldots, p\}\]</p><p>This provides:</p><p class="math-container">\[\mathbf{x}_i[j] = \text{Evaluate}(\text{Term}_j, \text{data}, i)\]</p><h3 id="Type-Specialization"><a class="docs-heading-anchor" href="#Type-Specialization">Type Specialization</a><a id="Type-Specialization-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Specialization" title="Permalink"></a></h3><p>Each operation is embedded in Julia&#39;s type system:</p><pre><code class="language-julia hljs">struct LoadOp{Col} end           # Load column Col
struct FunctionOp{Col, F} end    # Apply function F to column Col
struct InteractionOp{A, B} end   # Multiply terms A and B</code></pre><p>The compiler generates specialized code for each specific formula.</p><h3 id="Scratch-Space-Management"><a class="docs-heading-anchor" href="#Scratch-Space-Management">Scratch Space Management</a><a id="Scratch-Space-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Scratch-Space-Management" title="Permalink"></a></h3><p>Intermediate results use a compile-time allocated scratch space:</p><p class="math-container">\[\text{Scratch} \in \mathbb{R}^s \quad \text{where } s = \text{max intermediate width}\]</p><h2 id="Derivative-Computation"><a class="docs-heading-anchor" href="#Derivative-Computation">Derivative Computation</a><a id="Derivative-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Derivative-Computation" title="Permalink"></a></h2><h3 id="Jacobian-Matrix"><a class="docs-heading-anchor" href="#Jacobian-Matrix">Jacobian Matrix</a><a id="Jacobian-Matrix-1"></a><a class="docs-heading-anchor-permalink" href="#Jacobian-Matrix" title="Permalink"></a></h3><p>For derivatives with respect to variables <span>$\mathbf{v} = [v_1, \ldots, v_k]^T$</span>:</p><p class="math-container">\[\mathbf{J} = \frac{\partial \mathbf{x}}{\partial \mathbf{v}^T} = \begin{bmatrix}
\frac{\partial x_1}{\partial v_1} &amp; \frac{\partial x_1}{\partial v_2} &amp; \cdots &amp; \frac{\partial x_1}{\partial v_k} \\
\frac{\partial x_2}{\partial v_1} &amp; \frac{\partial x_2}{\partial v_2} &amp; \cdots &amp; \frac{\partial x_2}{\partial v_k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial x_p}{\partial v_1} &amp; \frac{\partial x_p}{\partial v_2} &amp; \cdots &amp; \frac{\partial x_p}{\partial v_k}
\end{bmatrix} \in \mathbb{R}^{p \times k}\]</p><h3 id="Automatic-Differentiation"><a class="docs-heading-anchor" href="#Automatic-Differentiation">Automatic Differentiation</a><a id="Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation" title="Permalink"></a></h3><p>FormulaCompiler uses ForwardDiff.jl for automatic differentiation:</p><p class="math-container">\[x_j = f_j(v_1, \ldots, v_k) \Rightarrow \frac{\partial x_j}{\partial v_i} = f_j&#39;(v_i)\]</p><p>Dual numbers compute derivatives exactly:</p><p class="math-container">\[f(a + b\varepsilon) = f(a) + bf&#39;(a)\varepsilon\]</p><h4 id="Low-Allocation-Automatic-Differentiation"><a class="docs-heading-anchor" href="#Low-Allocation-Automatic-Differentiation">Low-Allocation Automatic Differentiation</a><a id="Low-Allocation-Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Low-Allocation-Automatic-Differentiation" title="Permalink"></a></h4><p>A fundamental challenge in statistical automatic differentiation is the type conversion bottleneck between statistical data (typically <code>Float64</code>) and dual numbers required for AD computation. Traditional approaches convert <code>Float64</code> to <code>Dual</code> on every data access, creating allocation overhead that scales with formula complexity.</p><p>FormulaCompiler implements a <strong>pre-conversion strategy</strong> that minimizes runtime allocations:</p><p><strong>Phase 1: Construction-Time Pre-Conversion</strong></p><p>During evaluator construction, all relevant data columns are pre-converted from <code>Float64</code> to the target dual type:</p><p class="math-container">\[\text{data}_{\text{Float64}} \xrightarrow{\text{construction}} \text{data}_{\text{Dual}} \quad \text{(amortized cost)}\]</p><p>For <span>$k$</span> differentiation variables, data is converted to <code>Dual{Tag,Float64,k}</code> carrying the original value plus space for <span>$k$</span> partial derivatives.</p><p><strong>Phase 2: Type-Homogeneous Evaluation</strong></p><p>During derivative computation, the evaluation chain maintains type homogeneity throughout:</p><p class="math-container">\[\begin{align}
\text{Seed:} \quad v_i &amp;\leftarrow \text{Dual}(v_i, \mathbf{e}_i) \quad \text{where } \mathbf{e}_i \text{ is unit vector}\\
\text{Evaluate:} \quad \mathbf{x} &amp;= f(\mathbf{v}_{\text{dual}}) \quad \text{(no conversions)}\\
\text{Extract:} \quad J_{j,i} &amp;= \text{partials}(\mathbf{x}_j)_i
\end{align}\]</p><p><strong>Manual Dual Path</strong></p><p>Rather than using ForwardDiff&#39;s <code>jacobian!</code> and <code>gradient!</code> drivers (which contain allocation overhead for generality), FormulaCompiler implements a manual dual evaluation path:</p><ol><li><strong>Direct seeding</strong>: Identity partials injected without driver overhead</li><li><strong>In-place updates</strong>: Cached dual data structures modified without rebuilding  </li><li><strong>Single evaluation</strong>: Compiled formula executed once on dual-typed data</li><li><strong>Direct extraction</strong>: Partial derivatives read from dual results via simple loops</li></ol><p>This achieves the mathematical correctness of ForwardDiff with custom zero-allocation orchestration.</p><p><strong>Computational Complexity and Allocations</strong></p><p>The pre-conversion strategy transforms the memory allocation pattern:</p><ul><li><strong>Traditional AD</strong>: <span>$O(\text{accesses} \times \text{conversions})$</span> runtime allocations</li><li><strong>Low-allocation AD</strong>: <span>$O(\text{data size})$</span> construction cost; runtime allocations are typically small and environment‑dependent</li></ul><p>For typical statistical formulas accessing data 10–20 times per evaluation, this approach removes repeated conversion costs and reduces runtime allocations to small, bounded overheads while providing practical speedups.</p><h3 id="Finite-Differences"><a class="docs-heading-anchor" href="#Finite-Differences">Finite Differences</a><a id="Finite-Differences-1"></a><a class="docs-heading-anchor-permalink" href="#Finite-Differences" title="Permalink"></a></h3><p>For the finite difference backend (central differences):</p><p class="math-container">\[\frac{\partial x_j}{\partial v_i} \approx \frac{f_j(v_i + h) - f_j(v_i - h)}{2h}\]</p><p>Step size:</p><p class="math-container">\[h = \epsilon^{1/3} \cdot \max(1, |v_i|)\]</p><p>Justification: The central-difference truncation error is <span>$O(h^2)$</span> while floating-point rounding contributes <span>$O(\epsilon / h)$</span>. Balancing these terms yields an <span>$h$</span> proportional to <span>$\epsilon^{1/3}$</span> (scaled by the variable magnitude), which is a standard, robust choice in double precision.</p><h3 id="Single-Column-Extraction"><a class="docs-heading-anchor" href="#Single-Column-Extraction">Single-Column Extraction</a><a id="Single-Column-Extraction-1"></a><a class="docs-heading-anchor-permalink" href="#Single-Column-Extraction" title="Permalink"></a></h3><p>For computational efficiency, we can compute individual Jacobian columns:</p><p class="math-container">\[\mathbf{J}_{\cdot,k} = \frac{\partial \mathbf{x}}{\partial v_k} \in \mathbb{R}^p\]</p><p>This avoids computing the full Jacobian when only one column is needed.</p><h2 id="Marginal-Effects"><a class="docs-heading-anchor" href="#Marginal-Effects">Marginal Effects</a><a id="Marginal-Effects-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-Effects" title="Permalink"></a></h2><h3 id="Definition"><a class="docs-heading-anchor" href="#Definition">Definition</a><a id="Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Definition" title="Permalink"></a></h3><p>A marginal effect measures the change in the expected response due to a small change in a predictor:</p><p class="math-container">\[\text{ME}_{v_k} = \frac{\partial \mathbb{E}[y]}{\partial v_k}\]</p><h3 id="Linear-Predictor-Case-(η)"><a class="docs-heading-anchor" href="#Linear-Predictor-Case-(η)">Linear Predictor Case (η)</a><a id="Linear-Predictor-Case-(η)-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Predictor-Case-(η)" title="Permalink"></a></h3><p>For the linear predictor <span>$\eta = \mathbf{x}^T \boldsymbol{\beta}$</span>:</p><p class="math-container">\[\frac{\partial \eta}{\partial v_k} = \frac{\partial (\mathbf{x}^T \boldsymbol{\beta})}{\partial v_k} = \left(\frac{\partial \mathbf{x}}{\partial v_k}\right)^T \boldsymbol{\beta} = \mathbf{J}_{\cdot,k}^T \boldsymbol{\beta}\]</p><h3 id="Mean-Response-Case-(μ)"><a class="docs-heading-anchor" href="#Mean-Response-Case-(μ)">Mean Response Case (μ)</a><a id="Mean-Response-Case-(μ)-1"></a><a class="docs-heading-anchor-permalink" href="#Mean-Response-Case-(μ)" title="Permalink"></a></h3><p>For GLMs where <span>$\mu = g^{-1}(\eta)$</span>:</p><p class="math-container">\[\frac{\partial \mu}{\partial v_k} = \frac{d\mu}{d\eta} \frac{\partial \eta}{\partial v_k} = g&#39;(\eta) \cdot \mathbf{J}_{\cdot,k}^T \boldsymbol{\beta}\]</p><p>where <span>$g&#39;(\eta) = \frac{d\mu}{d\eta}$</span> is the derivative of the inverse link function.</p><h3 id="Average-Marginal-Effects"><a class="docs-heading-anchor" href="#Average-Marginal-Effects">Average Marginal Effects</a><a id="Average-Marginal-Effects-1"></a><a class="docs-heading-anchor-permalink" href="#Average-Marginal-Effects" title="Permalink"></a></h3><p>Average marginal effects (AME) average the marginal effect across observations:</p><p class="math-container">\[\text{AME}_{v_k} = \frac{1}{n} \sum_{i=1}^n \frac{\partial \mathbb{E}[y_i]}{\partial v_k}\]</p><h2 id="Variance-Estimation-and-Standard-Errors"><a class="docs-heading-anchor" href="#Variance-Estimation-and-Standard-Errors">Variance Estimation and Standard Errors</a><a id="Variance-Estimation-and-Standard-Errors-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-Estimation-and-Standard-Errors" title="Permalink"></a></h2><h3 id="Delta-Method"><a class="docs-heading-anchor" href="#Delta-Method">Delta Method</a><a id="Delta-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Delta-Method" title="Permalink"></a></h3><p>The delta method provides standard errors for smooth functions of estimated parameters. For a function <span>$m(\boldsymbol{\beta})$</span>:</p><p class="math-container">\[\text{Var}(m(\hat{\boldsymbol{\beta}})) \approx \mathbf{g}^T \boldsymbol{\Sigma} \mathbf{g}\]</p><p>where:</p><ul><li><p class="math-container">\[\mathbf{g} = \frac{\partial m}{\partial \boldsymbol{\beta}}\]</p>is the gradient</li><li><p class="math-container">\[\boldsymbol{\Sigma} = \text{Var}(\hat{\boldsymbol{\beta}})\]</p>is the parameter covariance matrix</li></ul><h3 id="Standard-Error-Computation"><a class="docs-heading-anchor" href="#Standard-Error-Computation">Standard Error Computation</a><a id="Standard-Error-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-Error-Computation" title="Permalink"></a></h3><p class="math-container">\[\text{SE}(m(\hat{\boldsymbol{\beta}})) = \sqrt{\mathbf{g}^T \boldsymbol{\Sigma} \mathbf{g}}\]</p><h3 id="Marginal-Effect-Standard-Errors"><a class="docs-heading-anchor" href="#Marginal-Effect-Standard-Errors">Marginal Effect Standard Errors</a><a id="Marginal-Effect-Standard-Errors-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-Effect-Standard-Errors" title="Permalink"></a></h3><h4 id="Linear-Predictor-Case"><a class="docs-heading-anchor" href="#Linear-Predictor-Case">Linear Predictor Case</a><a id="Linear-Predictor-Case-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Predictor-Case" title="Permalink"></a></h4><p>For marginal effects on <span>$\eta$</span>:</p><p class="math-container">\[m = \mathbf{J}_{\cdot,k}^T \boldsymbol{\beta} \Rightarrow \mathbf{g} = \frac{\partial m}{\partial \boldsymbol{\beta}} = \mathbf{J}_{\cdot,k}\]</p><p>Therefore:</p><p class="math-container">\[\text{SE}(\text{ME}_{\eta,k}) = \sqrt{\mathbf{J}_{\cdot,k}^T \boldsymbol{\Sigma} \mathbf{J}_{\cdot,k}}\]</p><h4 id="Mean-Response-Case"><a class="docs-heading-anchor" href="#Mean-Response-Case">Mean Response Case</a><a id="Mean-Response-Case-1"></a><a class="docs-heading-anchor-permalink" href="#Mean-Response-Case" title="Permalink"></a></h4><p>For marginal effects on <span>$\mu$</span> with link function <span>$g$</span>:</p><p class="math-container">\[m = g&#39;(\eta) \cdot \mathbf{J}_{\cdot,k}^T \boldsymbol{\beta}\]</p><p>The gradient is:</p><p class="math-container">\[\mathbf{g} = \frac{\partial m}{\partial \boldsymbol{\beta}} = g&#39;(\eta) \mathbf{J}_{\cdot,k} + (\mathbf{J}_{\cdot,k}^T \boldsymbol{\beta}) g&#39;&#39;(\eta) \mathbf{x}\]</p><p>where <span>$\mathbf{x}$</span> is the model matrix row and <span>$g&#39;&#39;(\eta)$</span> is the second derivative.</p><h4 id="Average-Marginal-Effects-2"><a class="docs-heading-anchor" href="#Average-Marginal-Effects-2">Average Marginal Effects</a><a class="docs-heading-anchor-permalink" href="#Average-Marginal-Effects-2" title="Permalink"></a></h4><p>For AME, the gradient is the average of individual gradients:</p><p class="math-container">\[\mathbf{g}_{\text{AME}} = \frac{1}{n} \sum_{i=1}^n \mathbf{g}_i\]</p><p>By linearity of expectation:</p><p class="math-container">\[\text{Var}(\text{AME}) = \mathbf{g}_{\text{AME}}^T \boldsymbol{\Sigma} \mathbf{g}_{\text{AME}}\]</p><h3 id="Link-Function-Derivatives"><a class="docs-heading-anchor" href="#Link-Function-Derivatives">Link Function Derivatives</a><a id="Link-Function-Derivatives-1"></a><a class="docs-heading-anchor-permalink" href="#Link-Function-Derivatives" title="Permalink"></a></h3><p>Common link functions and their derivatives:</p><table><tr><th style="text-align: right">Link</th><th style="text-align: right"><span>$g(\mu)$</span></th><th style="text-align: right"><span>$g^{-1}(\eta)$</span></th><th style="text-align: right"><span>$\frac{d\mu}{d\eta}$</span></th><th style="text-align: right"><span>$\frac{d^2\mu}{d\eta^2}$</span></th></tr><tr><td style="text-align: right">Identity</td><td style="text-align: right"><span>$\mu$</span></td><td style="text-align: right"><span>$\eta$</span></td><td style="text-align: right"><span>$1$</span></td><td style="text-align: right"><span>$0$</span></td></tr><tr><td style="text-align: right">Log</td><td style="text-align: right"><span>$\log(\mu)$</span></td><td style="text-align: right"><span>$\exp(\eta)$</span></td><td style="text-align: right"><span>$\exp(\eta)$</span></td><td style="text-align: right"><span>$\exp(\eta)$</span></td></tr><tr><td style="text-align: right">Logit</td><td style="text-align: right"><span>$\log\!\left(\tfrac{\mu}{1-\mu}\right)$</span></td><td style="text-align: right"><span>$\mu = \sigma(\eta)$</span></td><td style="text-align: right"><span>$\mu(1-\mu)$</span></td><td style="text-align: right"><span>$\mu(1-\mu)(1-2\mu)$</span></td></tr><tr><td style="text-align: right">Probit</td><td style="text-align: right"><span>$\Phi^{-1}(\mu)$</span></td><td style="text-align: right"><span>$\mu = \Phi(\eta)$</span></td><td style="text-align: right"><span>$\phi(\eta)$</span></td><td style="text-align: right"><span>$-\eta\,\phi(\eta)$</span></td></tr><tr><td style="text-align: right">Cloglog</td><td style="text-align: right"><span>$\log(-\log(1-\mu))$</span></td><td style="text-align: right"><span>$\mu = 1 - e^{-e^{\eta}}$</span></td><td style="text-align: right"><span>$e^{\eta - e^{\eta}}$</span></td><td style="text-align: right"><span>$e^{\eta - e^{\eta}}(1 - e^{\eta})$</span></td></tr><tr><td style="text-align: right">Cauchit</td><td style="text-align: right"><span>$\tan(\pi(\mu - 1/2))$</span></td><td style="text-align: right"><span>$\mu = \tfrac{1}{2} + \tfrac{1}{\pi} \arctan(\eta)$</span></td><td style="text-align: right"><span>$\tfrac{1}{\pi} \cdot \tfrac{1}{1+\eta^2}$</span></td><td style="text-align: right"><span>$-\tfrac{2\eta}{\pi} \cdot \tfrac{1}{(1+\eta^2)^2}$</span></td></tr><tr><td style="text-align: right">Inverse</td><td style="text-align: right"><span>$\mu^{-1}$</span></td><td style="text-align: right"><span>$\mu = \eta^{-1}$</span></td><td style="text-align: right"><span>$-\eta^{-2}$</span></td><td style="text-align: right"><span>$2\eta^{-3}$</span></td></tr><tr><td style="text-align: right">Sqrt</td><td style="text-align: right"><span>$2\sqrt{\mu}$</span></td><td style="text-align: right"><span>$\mu = (\tfrac{\eta}{2})^2$</span></td><td style="text-align: right"><span>$\tfrac{\eta}{2}$</span></td><td style="text-align: right"><span>$\tfrac{1}{2}$</span></td></tr><tr><td style="text-align: right">InverseSquare</td><td style="text-align: right"><span>$\mu^{-2}$</span></td><td style="text-align: right"><span>$\mu = \eta^{-1/2}$</span></td><td style="text-align: right"><span>$-\tfrac{1}{2} \eta^{-3/2}$</span></td><td style="text-align: right"><span>$\tfrac{3}{4} \eta^{-5/2}$</span></td></tr></table><p>Notes:</p><ul><li>For Logit, <span>$\mu = \sigma(\eta) = 1/(1+e^{-\eta})$</span> and <span>$\phi, \Phi$</span> denote standard Normal PDF/CDF for Probit.</li><li>Carefully handle domain constraints when evaluating links (e.g., <span>$\mu \in (0,1)$</span> for binary GLMs).</li></ul><h2 id="Computational-Efficiency"><a class="docs-heading-anchor" href="#Computational-Efficiency">Computational Efficiency</a><a id="Computational-Efficiency-1"></a><a class="docs-heading-anchor-permalink" href="#Computational-Efficiency" title="Permalink"></a></h2><h3 id="Zero-Allocation-Design"><a class="docs-heading-anchor" href="#Zero-Allocation-Design">Zero-Allocation Design</a><a id="Zero-Allocation-Design-1"></a><a class="docs-heading-anchor-permalink" href="#Zero-Allocation-Design" title="Permalink"></a></h3><p>The key to zero-allocation performance is eliminating runtime memory allocation:</p><ol><li><strong>Compile-time type specialization</strong>: All operations encoded in types</li><li><strong>Fixed memory layout</strong>: Pre-allocated buffers reused across calls</li><li><strong>Stack allocation</strong>: Small temporary values on the stack</li><li><strong>In-place operations</strong>: Modify existing arrays rather than creating new ones</li></ol><h3 id="Position-Mapping-Efficiency"><a class="docs-heading-anchor" href="#Position-Mapping-Efficiency">Position Mapping Efficiency</a><a id="Position-Mapping-Efficiency-1"></a><a class="docs-heading-anchor-permalink" href="#Position-Mapping-Efficiency" title="Permalink"></a></h3><p>Traditional approach:</p><p class="math-container">\[O(p \cdot \text{complexity}(\text{formula}))\]</p><p>Position mapping approach:</p><p class="math-container">\[O(p) \text{ with compile-time } O(\text{complexity}(\text{formula}))\]</p><h3 id="Memory-Complexity"><a class="docs-heading-anchor" href="#Memory-Complexity">Memory Complexity</a><a id="Memory-Complexity-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Complexity" title="Permalink"></a></h3><ul><li><strong>Traditional</strong>: <span>$O(np)$</span> for full model matrix</li><li><strong>FormulaCompiler</strong>: <span>$O(p)$</span> per row evaluation</li><li><strong>Scenarios</strong>: <span>$O(1)$</span> via <code>CounterfactualVector</code> regardless of <span>$n$</span></li></ul><h3 id="Derivative-Efficiency"><a class="docs-heading-anchor" href="#Derivative-Efficiency">Derivative Efficiency</a><a id="Derivative-Efficiency-1"></a><a class="docs-heading-anchor-permalink" href="#Derivative-Efficiency" title="Permalink"></a></h3><ul><li><strong>Full Jacobian</strong>: <span>$O(pk)$</span> computation and storage</li><li><strong>Single column</strong>: <span>$O(p)$</span> computation and storage  </li><li><strong>AME accumulation</strong>: <span>$O(np)$</span> time, <span>$O(p)$</span> space</li></ul><h3 id="Backend-Selection"><a class="docs-heading-anchor" href="#Backend-Selection">Backend Selection</a><a id="Backend-Selection-1"></a><a class="docs-heading-anchor-permalink" href="#Backend-Selection" title="Permalink"></a></h3><table><tr><th style="text-align: right">Backend</th><th style="text-align: right">Speed</th><th style="text-align: right">Memory</th><th style="text-align: right">Accuracy</th><th style="text-align: right">Recommendation</th></tr><tr><td style="text-align: right"><code>:ad</code> (Automatic Differentiation)</td><td style="text-align: right">Faster</td><td style="text-align: right">0 bytes</td><td style="text-align: right">Machine precision</td><td style="text-align: right"><strong>Strongly preferred - always use this</strong></td></tr><tr><td style="text-align: right"><code>:fd</code> (Finite Differences)</td><td style="text-align: right">Slower (~22% slower)</td><td style="text-align: right">0 bytes</td><td style="text-align: right">≈1e-8</td><td style="text-align: right">Legacy support only</td></tr></table><div class="admonition is-warning" id="Use-Automatic-Differentiation-ec05a20335708f68"><header class="admonition-header">Use Automatic Differentiation<a class="admonition-anchor" href="#Use-Automatic-Differentiation-ec05a20335708f68" title="Permalink"></a></header><div class="admonition-body"><p><strong>Always use <code>:ad</code> backend</strong> (<code>derivativeevaluator(:ad, ...)</code> or <code>backend=:ad</code>).</p><p>Advantages of <code>:ad</code>:</p><ul><li><strong>Faster</strong>: ~22% faster than finite differences</li><li><strong>More accurate</strong>: Machine precision vs ~1e-8 for FD</li><li><strong>Zero allocations</strong>: Same as FD</li></ul><p>The <code>:fd</code> backend exists only for legacy compatibility. <strong>There are no practical advantages to using it.</strong></p></div></div><h2 id="Implementation-Notes"><a class="docs-heading-anchor" href="#Implementation-Notes">Implementation Notes</a><a id="Implementation-Notes-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-Notes" title="Permalink"></a></h2><h3 id="Type-Stability"><a class="docs-heading-anchor" href="#Type-Stability">Type Stability</a><a id="Type-Stability-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Stability" title="Permalink"></a></h3><p>All functions maintain type stability:</p><pre><code class="language-julia hljs">f(x::Float64)::Float64  # Compiler can optimize aggressively</code></pre><h3 id="Generated-Functions"><a class="docs-heading-anchor" href="#Generated-Functions">Generated Functions</a><a id="Generated-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Generated-Functions" title="Permalink"></a></h3><p>Critical paths use <code>@generated</code> functions to move computation to compile time:</p><pre><code class="language-julia hljs">@generated function evaluate(compiled::UnifiedCompiled{T,Ops}, ...)
    # Generate specialized code based on Ops type parameter
    return quote
        # Unrolled, type-stable operations
    end
end</code></pre><h3 id="Numerical-Stability"><a class="docs-heading-anchor" href="#Numerical-Stability">Numerical Stability</a><a id="Numerical-Stability-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-Stability" title="Permalink"></a></h3><ul><li><strong>Finite differences</strong>: Adaptive step size based on magnitude</li><li><strong>Link functions</strong>: Numerical safeguards for extreme values  </li><li><strong>Matrix operations</strong>: Use stable BLAS routines</li></ul><p>This mathematical foundation enables FormulaCompiler.jl to achieve both computational efficiency and statistical accuracy, making it suitable as a foundation for advanced statistical computing applications.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../integration/standardized_predictors/">« StandardizedPredictors.jl</a><a class="docs-footer-nextpage" href="../architecture/">Architecture »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Wednesday 14 January 2026 02:12">Wednesday 14 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
